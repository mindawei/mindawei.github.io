<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[多机使用Hexo博客]]></title>
    <url>%2F2018%2F05%2F01%2F%E5%A4%9A%E6%9C%BA%E4%BD%BF%E7%94%A8Hexo%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[记录一下 hexo 博客迁移到另一台电脑上的操作。 问题描述之前博客使用 Hexo ，本地写完后，使用 hexo g -d 命令后，就直接在 public 生成站点，将网站内容部署到 github 上，但是原始文件没有上传，这样无法再多台机器上一起使用该博客。 解决参考参考 《使用hexo，如果换了电脑怎么更新博客？》。 解决思路如下： 使用 master 和 hexo 两个分支。 master 分支用来保存生成的网站内容。 hexo 分支保存原始的代码。 具体操作 创建新分支 hexo，可参考 《创建Git新分支步骤》。 将 hexo 博客的源文件提交到新分支 hexo 上。 然后在 github 上项目上设置默认的分支为你新建的分支（这里新分支为 hexo）。 然后在新的电脑上拷贝这个项目的代码（拷贝默认的 hexo 分支）。 在 hexo 分支上开发，然后提交代码到默认的 hexo 分支：git add .、git commit -m &quot;...&quot;、git push origin hexo。 修改 _config.yml 中的 deploy 参数，分支应为 master。 使用 hexo g -d 将网站更新到 master 分支上。 Next 主题缺失问题按上面操作后，会发现 hexo 博客还是跑不起来，网上查找原因后发现 next 主题文件夹为空。如下： 《hexo本地测试运行重启后页面空白,提示 : WARN No layout: index.html?》 这个问题的解决一下子找不到了。。。基本思路是，拉一个 next 的主题下来，然后使用子模块的设置 submodule，将 next 主题独立到一个仓库中。 由于本质上是利用 github 来做一个云端的存储，所以我直接新建了一个项目，把这个 next 主题传了上去，如果有更改，就进行更新，其实是差不多的。用的时候，直接拷贝下来放入 next 文件夹中即可。 可能之前尝试使用子模块的操作，启动 hexo 报了这个错误：1git submodule: already exists in the index 这个解决可以参考：《git submodule: already exists in the index》。]]></content>
      <categories>
        <category>环境</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac快捷键]]></title>
    <url>%2F2018%2F05%2F01%2FMac%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[本文是对苹果电脑上的一些快捷键的记录。 按钮说明： command 简记为 cmd delete 简记为 del control 简记为 ctl option 简记为 opt 空格 记为 space 关机键 记为 off Mac系统切换 按钮 功能 cmd + tab 在应用之间切换 cmd + shift + tab 在应用之间切换，反向 通用 按钮 功能 cmd + N 新建 cmd + O 打开 cmd + S 保存 cmd + A 全选 cmd + shift + S 另存为 cmd + W 关闭 cmd + Q 退出 cmd + F 搜索 截屏 按钮 功能 cmd + shift + 3 截取整个屏幕 cmd + shift + 4 截取选择区域 cmd + shift + 4 + space 截取整个应用界面 文件管理器 按钮 功能 space 快速查看文件 cmd + I 显示文件简介 cmd + C 复制 cmd + V 粘贴 cmd + del 删除 cmd + shift + del 清空回收站 系统 按钮 功能 ctl + shift + off 关闭显示器 cmd + opt + off 睡眠 cmd + opt + esc 强制退出程序 cmd + ctl + off 重启 cmd + space 切换输入法 谷歌浏览器Chrome for Mac键盘快捷键！来自Google Chrome官网！ 按钮 功能 cmd + + 放大 cmd + - 缩小 cmd + T 新标签页 cmd + N 新窗口 cmd + R 刷新 cmd + W 关闭当前标签页 cmd + ～ 切换应用窗口 cmd + shift + N 隐身打开新窗口 cmd + O 打开计算机中的文件 cmd + 链接 从新标签页中打开链接 shift + 链接 从新窗口中打开链接 cmd + opt + 左右箭头 切换标签页 cmd + shift + W 关闭当前窗口 cmd + shift + T 重新打开上次关闭的标签，最多记住10个 cmd + [ 标签页的上一页历史 cmd + ] 标签页的下一页历史 cmd + M 最小化窗口 cmd + H 隐藏窗口 cmd + Q 关闭浏览器 cmd + ctl + F 最大化当前标签 cmd + shift + B 打开和关闭书签栏 cmd + opt + B 打开书签管理器 cmd + , 打开偏好设置 cmd + Y 打开历史记录 cmd + shift + J 打开下载内容 cmd + shift + del 打开清楚浏览数据对话框 输入网址时 + tab 进行提示补全 cmd + L 选中网址 opt + 左右箭头 可以跳跃单词 opt + shift + 左右箭头 选中下一个单词 cmd + del 删除地址栏中光标前的关键字 cmd + opt + I 打开开发者工具 cmd + D 将当前网页保存为书签 cmd + shift + D 将所有打开的网页保存到书签 space 向下滚动网页 cmd + opt + F 使用谷歌搜索 终端Mac Terminal 常用快捷键 Bash shell 按钮 功能 ctl + A 跳到行首 ctl + E 跳到行尾 opt + 左右箭头 左右移动一个单词位 ctl + K 从光标处删除到行尾 ctl + U 从光标处删除到行首 ctl + W 从光标处删除到字首 ctl + Y 粘贴最后一次被删除的单词 ctl + R 逆向搜索命令历史 ctl + G 从历史搜索模式退出 ctl + P 历史中的上一条命令 ctl + N 历史中的下一条命令 // TODO VIM]]></content>
      <categories>
        <category>基础</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 的安装和使用]]></title>
    <url>%2F2018%2F05%2F01%2FRedis-%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[本文是安装和使用 Redis 时的一个简单记录，主要参考了 Redis 教程。 安装与启动参考 Redis 安装 mac 下安装也可以使用 homebrew，homebrew 是 mac 的包管理器。1、执行 brew install redis2、启动 redis，可以使用后台服务启动 brew services start redis。或者直接启动：redis-server /usr/local/etc/redis.conf。 设置参考 Redis 配置 打开配置文件 /usr/local/etc/redis.conf 进行配置。 requirepass 字段配置密码。 相关操作客户端启动1.默认启动redis-cli 启动客户端，按照默认配置连接 Redis（127.0.0.1:6379）。 2.指定地址和端口号redis-cli -h 127.0.0.1 -p 6379 关闭服务端参考 mac下redis安装、设置、启动停止 1.强行关闭强行终止redis进程可能会导致数据丢失，因为redis可能正在将内存数据同步到硬盘中。12ps axu|grep redis ## 查找redis-server的PIDkill -9 PID 2.命令关闭向redis发送SHUTDOWN命令，即 redis-cli SHUTDOWN。Redis收到命令后，服务端会断开所有客户端的连接，然后根据配置执行持久化，最后退出。 123456789101112131415161718# 启动redis-server，后台线程AT8775:redis shoren$ redis-server /usr/local/etc/redis.conf 12105:C 29 Apr 22:16:14.570 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo12105:C 29 Apr 22:16:14.571 # Redis version=4.0.9, bits=64, commit=00000000, modified=0, pid=12105, just started12105:C 29 Apr 22:16:14.571 # Configuration loaded## 启动成功AT8775:redis shoren$ ps axu|grep redismindw 12108 0.0 0.0 2432804 1940 s002 S+ 10:16下午 0:00.00 grep redismindw 12106 0.0 0.0 2458976 2248 ?? Ss 10:16下午 0:00.02 redis-server 127.0.0.1:6379## 关闭服务器mindwdeMacBook-Pro:~ mindw$ redis-cli127.0.0.1:6379&gt; AUTH 你设置的密码OK127.0.0.1:6379&gt; shutdownmindwdeMacBook-Pro:~ mindw$ ps axu|grep redismindw 12122 0.0 0.0 2432804 1940 s002 S+ 10:19下午 0:00.00 grep redis 客户端操作 Redis 服务器参考 Redis 服务器]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Guava学习之ListenableFuture]]></title>
    <url>%2F2018%2F03%2F20%2FGuava%E5%AD%A6%E4%B9%A0%E4%B9%8BListenableFuture%2F</url>
    <content type="text"><![CDATA[本文是对 Guava 中 ListenableFuture 的学习介绍。欢迎加入学习项目： LearningGuava。 以下参考: 官方文档 处理并发是一个很困难的问题，但是我们可以通过使用功能强大的抽象来简化这个工作。为了简化这个问题，Guava 提供了 ListenableFuture，它继承了 JDK 中的 Future 接口。 我们强烈建议：在你的代码中，使用 ListenableFuture 来替代 Future，因为 很多 Future 相关的方法需要它。 一开始就使用 ListenableFuture 会省事很多。 这样工具方法提供者就不需要针对 Future 和 ListenableFuture 都提供方法。 接口Future 代表了异步执行的结果：一个可能还没有产生结果的执行过程。 Future 可以正在被执行，但是会保证返回一个结果。 ListenableFuture 可以使你注册回调函数，使得在结果计算完成的时候可以回调你的函数。如果结果已经算好，那么将会立即回调。这个简单的功能使得可以完成很多 Future 支持不了的操作。 ListenableFuture 添加的基本函数是 addListener(Runnable, Executor)。通过这个函数，当 Future 中的结果执行完成时，传入的 Runnable 会在传入的 Executor 中执行。 添加回调函数使用者偏向于使用 Futures.addCallback(ListenableFuture&lt;V&gt;, FutureCallback&lt;V&gt;, Executor) , 或者当需要注册轻量级的回调的时候，可以使用默认为 MoreExecutors.directExecutor() 的版本。 FutureCallback&lt;V&gt; 实现了两个方法: onSuccess(V) ：当 future 执行成功时候的反应。 onFailure(Throwable)：当 future 执行失败时候的反应。 创建与 JDK 中 通过 ExecutorService.submit(Callable) 来初始化一个异步的任务相似，Guava 提供了一个 ListeningExecutorService 接口，这个接口可以返回一个 ListenableFuture（ExecutorService 只是返回一个普通的 Future）。如果需要将一个 ExecutorService 转换为 ListeningExecutorService，可以使用 MoreExecutors.listeningDecorator(ExecutorService)。一个使用示例如下：123456789101112131415ListeningExecutorService service = MoreExecutors.listeningDecorator(Executors.newFixedThreadPool(10));ListenableFuture&lt;Explosion&gt; explosion = service.submit(new Callable&lt;Explosion&gt;() &#123; public Explosion call() &#123; return pushBigRedButton(); &#125;&#125;);Futures.addCallback(explosion, new FutureCallback&lt;Explosion&gt;() &#123; // we want this handler to run immediately after we push the big red button! public void onSuccess(Explosion explosion) &#123; walkAwayFrom(explosion); &#125; public void onFailure(Throwable thrown) &#123; battleArchNemesis(); // escaped the explosion! &#125;&#125;); 如果你想从一个基于 FutureTask 的 API 转换过来，Guava 提供了 ListenableFutureTask.create(Callable&lt;V&gt;) 和 ListenableFutureTask.create(Runnable, V)。和 JDK 不一样，ListenableFutureTask 并不意味着可以直接扩展。 如果你更喜欢可以设置 future 值的抽象，而不是实现一个方法来计算结果，那么可以考虑直接扩展 AbstractFuture&lt;V&gt; 或者 SettableFuture。 如果你一定要将一个基于 Future 的 API 转换为基于 ListenableFuture 的话，你不得不采用硬编码的方式 JdkFutureAdapters.listenInPoolThread(Future) 来实现从 Future 到 ListenableFuture 的转换。所以，尽可能地使用 ListenableFuture。 应用使用 ListenableFuture 一个最重要的原因就是：可以基于他实现负责的异步执行链。如下所示： 123456789ListenableFuture&lt;RowKey&gt; rowKeyFuture = indexService.lookUp(query);AsyncFunction&lt;RowKey, QueryResult&gt; queryFunction = new AsyncFunction&lt;RowKey, QueryResult&gt;() &#123; public ListenableFuture&lt;QueryResult&gt; apply(RowKey rowKey) &#123; return dataService.read(rowKey); &#125; &#125;;ListenableFuture&lt;QueryResult&gt; queryFuture = Futures.transformAsync(rowKeyFuture, queryFunction, queryExecutor); 很多不能被 Future 支持的方法可以通过 ListenableFuture 被高效地支持。不同的操作可能被不同的执行器执行，而且一个 ListenableFuture 可以有多个响应操作。 当 ListenableFuture 有多个后续操作的时候，这样的操作称为：“扇出”。当它依赖多个输入 future 同时完成时，称作“扇入”。可以参考 Futures.allAsList的实现。 方法 描述 参考 transformAsync(ListenableFuture&lt;A&gt;, AsyncFunction&lt;A, B&gt;, Executor) 返回新的 ListenableFuture，它是给定 AsyncFunction 结合的结果 transformAsync(ListenableFuture&lt;A&gt;, AsyncFunction&lt;A, B&gt;) transform(ListenableFuture&lt;A&gt;, Function&lt;A, B&gt;, Executor) 返回新的 ListenableFuture,它是给定 Function 结合的结果 transform(ListenableFuture&lt;A&gt;, Function&lt;A, B&gt;) allAsList(Iterable&lt;ListenableFuture&lt;V&gt;&gt;) 返回一个 ListenableFuture,它的值是一个输入 futures 的值的按序列表，任何一个 future 的失败都会导致最后结果的失败 allAsList(ListenableFuture&lt;V&gt;...) successfulAsList(Iterable&lt;ListenableFuture&lt;V&gt;&gt;) 返回一个 ListenableFuture,它的值是一个输入 futures 的成功执行值的按序列表，对于取消或者失败的任务，对应的值是 null successfulAsList(ListenableFuture&lt;V&gt;...) AsyncFunction&lt;A, B&gt; 提供了一个方法：ListenableFuture&lt;B&gt; apply(A input)。可以被用来异步转换一个值。 123456List&lt;ListenableFuture&lt;QueryResult&gt;&gt; queries;// The queries go to all different data centers, but we want to wait until they&apos;re all done or failed.ListenableFuture&lt;List&lt;QueryResult&gt;&gt; successfulQueries = Futures.successfulAsList(queries);Futures.addCallback(successfulQueries, callbackOnSuccessfulQueries); 避免嵌套 Future在使用通用接口返回 Future 的代码中，很有可能会嵌套 Future。例如：123456executorService.submit(new Callable&lt;ListenableFuture&lt;Foo&gt;() &#123; @Override public ListenableFuture&lt;Foo&gt; call() &#123; return otherExecutorService.submit(otherCallable); &#125;&#125;); 上述代码将会返回：ListenableFuture&lt;ListenableFuture&lt;Foo&gt;&gt;。这样的代码是不正确的，因为外层 future 的取消操作不能传递到内层的 future。此外，一个常犯的错误是：使用 get() 或者 listener 来检测其它 future 的失败。为了避免这样的情况，Guava 所有处理 future 的方法（以及一些来自 JDK 的代码）具有安全解决嵌套的版本。 CheckedFutureGuava 也提供 CheckedFuture&lt;V, X extends Exception&gt; 接口。 CheckedFuture 是这样的一个 ListenableFuture：具有多个可以抛出受保护异常的 get 方法。这使得创建一个执行逻辑可能抛出异常的 future 变得容易。使用 Futures.makeChecked(ListenableFuture&lt;V&gt;, Function&lt;Exception, X&gt;)可以将 ListenableFuture 转换为 CheckedFuture。]]></content>
      <categories>
        <category>Guava</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Guava</tag>
        <tag>Concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Guava学习之CharMatcher]]></title>
    <url>%2F2018%2F03%2F17%2FGuava%E5%AD%A6%E4%B9%A0%E4%B9%8BCharMatcher%2F</url>
    <content type="text"><![CDATA[本文是对 Guava 中 CharMatcher 的学习介绍。欢迎加入学习项目： LearningGuava。 以下参考： 官方文档。 Guava 是个风火轮之基础工具(3)。 概览之前，Guava 中的 StringUtil 在无节制地增长，具有很多方法，如： allAscii collapse collapseControlChars collapseWhitespace lastIndexNotOf numSharedChars removeChars removeCrLf retainAllChars strip stripAndCollapse stripNonDigits 这些函数本质上是以下两个方面的乘积（M x N 种情况）： 何如定义一个“匹配”的字符？ （M 种情况） 对“匹配”的字符进行怎样的操作？ （N 种情况） 为了解决这样的爆炸式增长，Guava 提供了 CharMatcher。一个 CharMacher 实例本身，界定了一个匹配字符的集合，而 CharMacher 实例的方法，解决了要对匹配字符做什么的问题。然后我们就可以用最小化的 API 来处理字符匹配和字符操作，把 M×N 的复杂度下降到了 M+N。 直观地说，你可以把 CharMatcher 看做是一些特别字符串的表示，例如：数字、空格等。而事实上，CharMatcher 只是一个针对字符串的布尔断言（它实现了 Predicate&lt;Character&gt;），但考虑到“所有空白字符串”、“所有小写单词”等相关需求是很普遍的，Guava 还是为字符串提供了专门的语法和 API。 CharMatcher 的功能主要在于对特定类或字符串执行这些操作：trimming、collapsing、removing、retaining 等。 使用示例创建 CharMatcher很多需求都可以被 CharMatcher 的工厂方法满足： any() none() whitespace() breakingWhitespace() invisible() digit() javaLetter() javaDigit() javaLetterOrDigit() javaIsoControl() javaLowerCase() javaUpperCase() ascii() singleWidth() 其它一些常用的获得一个 CharMatcher 的方法包括： 方法 描述 anyOf(CharSequence) 表明你想匹配的所有字符，例如：CharMatcher.anyOf(&quot;aeiou&quot;) 可以匹配小写元音字母。 is(char) 表明你想匹配的一个确定的字符。 inRange(char, char) 表明你想匹配的一个字符范围，例如：CharMatcher.inRange(&#39;a&#39;, &#39;z&#39;)。 此外，CharMatcher 还有这些方法：negate()、and(CharMatcher)、or(CharMatcher)。这些方法可以为 CharMatcher 提供方便的布尔运算。 使用 CharMatcherCharMatcher 提供了很多方法来对匹配的字符序列 CharSequence 进行操作。以下只是列出了一些常用方法。 方法 描述 collapseFrom(CharSequence, char) 将一组连续匹配的字符串替换为一个指定的字符。例如：WHITESPACE.collapseFrom(string, &#39; &#39;) 可以将连续的空字符串替换为单个字符。 matchesAllOf(CharSequence) 测试字符序列是否全部匹配。例如：ASCII.matchesAllOf(string) 可以测试字符是否全部是 ASCII。 removeFrom(CharSequence) 将匹配的字符序列移除 retainFrom(CharSequence) 将没有匹配的字符序列移除 trimFrom(CharSequence) 去除开头和结尾匹配的部分 replaceFrom(CharSequence, CharSequence) 将匹配的字符替换为给定的序列 方法分类根据函数的返回值和名称将这些方法分为三类。 第一类是判定型函数，判断 CharMacher 和入参字符串的匹配关系。123CharMatcher.is(&apos;a&apos;).matchesAllOf(&quot;aaa&quot;);//trueCharMatcher.is(&apos;a&apos;).matchesAnyOf(&quot;aba&quot;);//trueCharMatcher.is(&apos;a&apos;).matchesNoneOf(&quot;aba&quot;);//true 第二类是计数型函数，查找入参字符串中第一次、最后一次出现目标字符的位置，或者目标字符出现的次数，比如 indexIn，lastIndexIn 和 countIn。12CharMatcher.is(&apos;a&apos;).countIn(&quot;aaa&quot;); // 3CharMatcher.is(&apos;a&apos;).indexIn(&quot;java&quot;); // 1 第三类就是对匹配字符的操作。包括 removeFrom、retainFrom、replaceFrom、trimFrom、collapseFrom 等。123CharMatcher.is(&apos;a&apos;).retainFrom(&quot;bazaar&quot;); // &quot;aaa&quot;CharMatcher.is(&apos;a&apos;).removeFrom(&quot;bazaar&quot;); // &quot;bzr&quot;CharMatcher.anyOf(&quot;ab&quot;).trimFrom(&quot;abacatbab&quot;); // &quot;cat&quot; 源码分析源码有很多行，主要的逻辑是这样的： CharMatcher 是个抽象类，内部有一些私有的实现类，通过一些工厂函数 is、anyOf 等工厂函数创建对应的实例（固定的是单例，变化的会创建一个具体实例）。 不同的实例主要实现的是 CharMatcher 中的 matches 方法，这样就实现了不同策略的匹配器。 基于上述匹配方法 matches，可以进行统计工作（countIn等）、查找工作（indexIn等）、修改工作（trimFrom）等。 这样的设计最基础的工作就是：把匹配部分进行抽象。此外，在具体实现过程中也有较多的优化，就不一一列出来了。]]></content>
      <categories>
        <category>Guava</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Guava</tag>
        <tag>String</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Guava学习之Splitter]]></title>
    <url>%2F2018%2F03%2F17%2FGuava%E5%AD%A6%E4%B9%A0%E4%B9%8BSplitter%2F</url>
    <content type="text"><![CDATA[本文是对 Guava 中 Splitter 的学习介绍。欢迎加入学习项目： LearningGuava。 使用示例以下参考：官方文档。 Splitter概述Java 中关于分词的工具类会有一些古怪的行为。例如：String.split 函数会悄悄地丢弃尾部分割符，而 StringTokenizer 处理5个空格字符串，结果将会什么都没有。 问题：&quot;,a,,b,&quot;.split(&quot;,&quot;) 的结果是什么？ “”, “a”, “”, “b”, “” null, “a”, null, “b”, null “a”, null, “b” “a”, “b” 以上都不是 正确答案是：5 以上都不是，应该是 &quot;&quot;, &quot;a&quot;, &quot;&quot;, &quot;b&quot;。只有尾随的空字符串被跳过。这样的结果很令人费解。 Splitter 可以让你使用一种非常简单流畅的模式来控制这些令人困惑的行为。1234Splitter.on(&apos;,&apos;) .trimResults() .omitEmptyStrings() .split(&quot;foo,bar,, qux&quot;); 以上代码将会返回 Iterable&lt;String&gt; ，包含 “foo”、 “bar”、 “qux”。一个 Splitter 可以通过这些来进行划分：Pattern、char、 String、CharMatcher。 如果你希望返回的是 List 的话，可以使用这样的代码 Lists.newArrayList(splitter.split(string))。 工厂函数 方法 描述 例子 Splitter.on(char) 基于特定字符划分 Splitter.on(&#39;;&#39;) Splitter.on(CharMatcher) 基于某些类别划分 Splitter.on(&#39;;&#39;) Splitter.on(String) 基于字符串划分 Splitter.on(CharMatcher.BREAKING_WHITESPACE)Splitter.on(CharMatcher.anyOf(&quot;;,.&quot;)) Splitter.on(Pattern)Splitter.onPattern(String) 基于正则表达式划分 Splitter.on(&quot;, &quot;) Splitter.fixedLength(int) 按指定长度划分，最后部分可以小于指定长度但不能为空 Splitter.fixedLength(3) 修改器 方法 描述 例子 omitEmptyStrings() 移去结果中的空字符串 Splitter.on(&#39;,&#39;).omitEmptyStrings().split(&quot;a,,c,d&quot;) 返回 &quot;a&quot;, &quot;c&quot;, &quot;d&quot; trimResults() 将结果中的空格删除，等价于trimResults(CharMatcher.WHITESPACE) Splitter.on(&#39;,&#39;).trimResults().split(&quot;a, b, c, d&quot;) 返回 &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot; trimResults(CharMatcher) 移除匹配字符 Splitter.on(&#39;,&#39;).trimResults(CharMatcher.is(&#39;_&#39;)).split(&quot;_a ,_b_ ,c__&quot;) 返回 &quot;a &quot;, &quot;b_ &quot;, &quot;c&quot; limit(int) 达到指定数目后停止字符串的划分 Splitter.on(&#39;,&#39;).limit(3).split(&quot;a,b,c,d&quot;) 返回 &quot;a&quot;, &quot;b&quot;, &quot;c,d&quot; Splitter.MapSplitter以下参考：Guava 是个风火轮之基础工具(2)。 通过 Splitter 的 withKeyValueSeparator 方法可以获得 Joiner.MapJoiner 对象。 MapSpliter 只有一个公共方法，如下所示。可以看到返回的对象是 Map&lt;String, String&gt;。1public Map&lt;String, String&gt; split(CharSequence sequence) 以下代码将返回这样的 Map: {&quot;1&quot;:&quot;2&quot;, &quot;3&quot;:&quot;4&quot;}。1Splitter.on(&quot;#&quot;).withKeyValueSeparator(&quot;:&quot;).split(&quot;1:2#3:4&quot;); 需要注意的是，MapSplitter 对键值对格式有着严格的校验，下例会抛出 java.lang.IllegalArgumentException 异常。1Splitter.on(&quot;#&quot;).withKeyValueSeparator(&quot;:&quot;).split(&quot;1:2#3:4:5&quot;); 因此，如果希望使用 MapSplitter 来拆分 KV 结构的字符串，需要保证键-值分隔符和键值对之间的分隔符不会称为键或值的一部分。也许是出于类似方面的考虑，MapSplitter 被加上了 @Beta 注解（未来不保证兼容，甚至可能会移除）。所以一般推荐使用 JSON 而不是 MapJoiner + MapSplitter。 源码分析以下参考：Guava 是个风火轮之基础工具(2)。 Splitter 的实现中有十分明显的策略模式和模板模式，有各种神乎其技的方法覆盖，还有 Guava 久负盛名的迭代技巧和惰性计算。 成员变量Splitter 类有 4 个成员变量: CharMatcher trimmer：用于描述删除拆分结果的前后指定字符的策略。 boolean omitEmptyStrings：用于控制是否删除拆分结果中的空字符串。 Strategy strategy：用于帮助实现策略模式。 int limit：用于控制拆分的结果个数。 策略模式Splitter 可以根据字符、字符串、正则、长度还有 Guava 自己的字符匹配器 CharMatcher 来拆分字符串，基本上每种匹配模式的查找方法都不太一样，但是字符拆分的基本框架又是不变的，所以策略模式正好合用。 策略接口的定义很简单，就是传入一个 Splitter 和一个待拆分的字符串，返回一个迭代器。123private interface Strategy &#123; Iterator&lt;String&gt; iterator(Splitter splitter, CharSequence toSplit);&#125; 每个工厂函数创建最后都需要去调用基本的私有构造函数。这个创建过程中，主要是提供一个可以创建 Iterator&lt;String&gt; 的 Strategy。1private Splitter(Strategy strategy, boolean omitEmptyStrings, CharMatcher trimmer, int limit)； 以 Splitter on(final CharMatcher separatorMatcher) 创建函数为例，这里返回的是 SplittingIterator (它是个抽象类，继承了 AbstractIterator，而 AbstractIterator 继承了 Iterator）。1234567891011121314151617181920public static Splitter on(final CharMatcher separatorMatcher) &#123; checkNotNull(separatorMatcher); return new Splitter( new Strategy() &#123; @Override public SplittingIterator iterator(Splitter splitter, final CharSequence toSplit) &#123; return new SplittingIterator(splitter, toSplit) &#123; @Override int separatorStart(int start) &#123; return separatorMatcher.indexIn(toSplit, start); &#125; @Override int separatorEnd(int separatorPosition) &#123; return separatorPosition + 1; &#125; &#125;; &#125; &#125;);&#125; SplittingIterator 需要覆盖实现 separatorStart 和 separatorEnd 两个方法才能实例化。这两个方法也是 SplittingIterator 用到的模板模式的重要组成。 惰性迭代器与模板模式惰性计算目的是要最小化计算机要做的工作，即把计算推迟到不得不算的时候进行。Java中的惰性计算可以参考《你应该更新的 Java 知识之惰性求值：Supplier 和 Guava》。 Guava 中的迭代器使用了惰性计算的技巧，它不是一开始就算好结果放在列表或集合中，而是在调用 hasNext 方法判断迭代是否结束时才去计算下一个元素。 AbstractIterator为了看懂 Guava 的惰性迭代器实现，我们要从 AbstractIterator 开始。 AbstractIterator 使用私有的枚举变量 state 来记录当前的迭代进度，比如是否找到了下一个元素，迭代是否结束等。AbstractIterator 有一个抽象方法 computeNext，负责计算下一个元素。由于 state 是私有变量，而迭代是否结束只有在调用 computeNext 的过程中才知道，于是提供了一个保护的 endOfData 方法，允许子类将 state 设置为 State.DONE。123456private enum State &#123; READY, NOT_READY, DONE, FAILED,&#125; AbstractIterator 实现了迭代器最重要的两个方法，hasNext 和 next。 hasNext 很容易理解，一上来先判断迭代器当前状态，如果已经结束，就返回 false；如果已经找到下一个元素，就返回 true，不然就试着找找下一个元素。123456789101112@Overridepublic final boolean hasNext() &#123; checkState(state != State.FAILED); switch (state) &#123; case READY: return true; case DONE: return false; default: &#125; return tryToComputeNext();&#125; next 则是先判断是否还有下一个元素，属于防御式编程，先对自己做保护；然后把状态复原到还没找到下一个元素，然后返回结果。至于为什么要把 next 置为 null，可能是帮助 JVM 回收对象。12345678910@Override public final T next() &#123; if (!hasNext()) &#123; throw new NoSuchElementException(); &#125; state = State.NOT_READY; T result = next; next = null; return result; &#125; tryToComputeNext 可以认为是对模板方法 computeNext 的包装调用，首先把状态置为失败，然后才调用 computeNext。这样一来，如果计算下一个元素的过程中发生 RuntimeException，整个迭代器的状态就是 State.FAILED，一旦收到任何调用都会抛出异常。123456789private boolean tryToComputeNext() &#123; state = State.FAILED; // 暂时悲观 next = computeNext(); if (state != State.DONE) &#123; state = State.READY; return true; &#125; return false; &#125; AbstractIterator 的代码就这些，我们现在知道了它的子类需要覆盖实现 computeNext 方法，然后在迭代结束时调用 endOfData。接下来看看 SplittingIterator 的实现。 SplittingIteratorSplittingIterator 还是一个抽象类，虽然实现了 computeNext 方法，但是它又定义了两个虚函数: separatorStart： 返回分隔符在指定下标之后第一次出现的下标 separatorEnd： 返回分隔符在指定下标后面第一个不包含分隔符的下标。 之前的策略模式中我们可以看到，这两个函数在不同的策略中有各自不同的覆盖实现，在 SplittingIterator 中，这两个函数就是模板函数。 接下来看看 SplittingIterator 的核心函数 computeNext，这个函数一直在维护的两个内部全局变量: offset 和 limit。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172@Override protected String computeNext() &#123; // 返回的字符串介于上一个分隔符和下一个分隔符之间。 // nextStart 是返回子串的起始位置，offset 是下次开启寻找分隔符的地方。 int nextStart = offset; while (offset != -1) &#123; int start = nextStart; int end;// 找 offset 之后第一个分隔符出现的位置 int separatorPosition = separatorStart(offset); if (separatorPosition == -1) &#123; // 处理没找到的情况 end = toSplit.length(); offset = -1; &#125; else &#123; // 处理找到的情况 end = separatorPosition; offset = separatorEnd(separatorPosition); &#125;// 处理的是第一个字符就是分隔符的特殊情况 if (offset == nextStart) &#123; // 发生情况：空字符串 或者 整个字符串都没有匹配。 // offset 需要增加来寻找这个位置之后的分隔符， // 但是没有改变接下来返回字符串的 start 的位置， // 所以此时它们二者相同。 offset++; if (offset &gt; toSplit.length()) &#123; offset = -1; &#125; continue; &#125;// 根据 trimmer 来对找到的元素做前处理，比如去除空白符之类的。 while (start &lt; end &amp;&amp; trimmer.matches(toSplit.charAt(start))) &#123; start++; &#125;// 根据 trimmer 来对找到的元素做后处理，比如去除空白符之类的。 while (end &gt; start &amp;&amp; trimmer.matches(toSplit.charAt(end - 1))) &#123; end--; &#125;// 根据需要去除那些是空字符串的元素，trim完之后变成空字符串的也会被去除。 if (omitEmptyStrings &amp;&amp; start == end) &#123; // Don&apos;t include the (unused) separator in next split string. nextStart = offset; continue; &#125;// 判断 limit， if (limit == 1) &#123; // The limit has been reached, return the rest of the string as the // final item. This is tested after empty string removal so that // empty Strings do not count towards the limit. end = toSplit.length(); // 调整 end 指针的位置标记 offset 为 -1，下一次再调用 computeNext // 的时候就发现 offset 已经是 -1 了，然后就返回 endOfData 表示迭代结束。 offset = -1; // Since we may have changed the end, we need to trim it again. while (end &gt; start &amp;&amp; trimmer.matches(toSplit.charAt(end - 1))) &#123; end--; &#125; &#125; else &#123; // 还没到 limit 的极限，就让 limit 自减 limit--; &#125; return toSplit.subSequence(start, end).toString(); &#125; return endOfData(); &#125;&#125;]]></content>
      <categories>
        <category>Guava</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Guava</tag>
        <tag>String</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Guava学习之Joiner]]></title>
    <url>%2F2018%2F03%2F17%2FGuava%E5%AD%A6%E4%B9%A0%E4%B9%8BJoiner%2F</url>
    <content type="text"><![CDATA[本文是对 Guava 中 Joiner 的学习介绍。欢迎加入学习项目： LearningGuava。 使用示例以下参考：官方文档。 开发过程中，用分隔符连接字符串序列可能是一个比较繁琐的过程，但本不应该如此。Joiner 可以简化这个操作。 如果序列中包含 null 值，那么可以使用 Joiner 跳过 null 值：123// 跳过 null 值result = Joiner.on(&quot;; &quot;).skipNulls().join(&quot;Harry&quot;, null, &quot;Ron&quot;, &quot;Hermione&quot;);Assert.assertEquals(result, &quot;Harry; Ron; Hermione&quot;); 也可以通过 useForNull(String) 来将 null 值替换为指定的字符串。123// 替换 null 值result = Joiner.on(&quot;; &quot;).useForNull(&quot;null&quot;).join(&quot;Harry&quot;, null, &quot;Ron&quot;, &quot;Hermione&quot;);Assert.assertEquals(result, &quot;Harry; null; Ron; Hermione&quot;); 同样可以在对象上使用 Joiner,最终会调用对象的 toString() 方法。123// 使用在对象上，会调用对象的 toString() 函数result = Joiner.on(&quot;,&quot;).join(Arrays.asList(1, 5, 7));Assert.assertEquals(result, &quot;1,5,7&quot;); 对于 Map ,可以使用这样的代码：1234// MapJoiner 的使用，将 map 转换为字符串Map map = ImmutableMap.of(&quot;k1&quot;, &quot;v1&quot;, &quot;k2&quot;, &quot;v2&quot;);result = Joiner.on(&quot;; &quot;).withKeyValueSeparator(&quot;=&quot;).join(map);Assert.assertEquals(result, &quot;k1=v1; k2=v2&quot;); 源码分析以下参考：Guava 是个风火轮之基础工具(1)。 初始化方法Joiner 的构造方法被设置成了私有，需要通过静态的 on(String separator) 或者 on(char separator) 函数初始化。 拼接基本函数Joiner 了中最为核心的函数就是 &lt;A extends Appendable&gt; A appendTo(A appendable, Iterator&lt;?&gt; parts)。作为全功能函数，其它所有的字符串拼接最终都会调用这个函数。 1234567891011public &lt;A extends Appendable&gt; A appendTo(A appendable, Iterator&lt;?&gt; parts) throws IOException &#123; checkNotNull(appendable); if (parts.hasNext()) &#123; appendable.append(toString(parts.next())); while (parts.hasNext()) &#123; appendable.append(separator); appendable.append(toString(parts.next())); &#125; &#125; return appendable;&#125; 这段代码的分析如下： 这里的 Appendable 源码中传入的是实现该接口的 StringBuilder。 因为是公共方法，无法保证 appendable 值不为空，所以要先检查该值是否为空。 if ... while ... 的结构确保末尾不会添加多余的分隔符。 通过本地 toString 方法，而不是直接调用对象的 toString 方法，这种做法提供了空指针保护。 不可能发生的异常在源码中，有个地方的处理值得关注一下：12345678public StringBuilder appendTo(StringBuilder builder, Iterator&lt;? extends Entry&lt;?, ?&gt;&gt; entries) &#123; try &#123; appendTo((Appendable) builder, entries); &#125; catch (IOException impossible) &#123; throw new AssertionError(impossible); &#125; return builder; &#125; 这里之所以 IOException 的变量名取名为 impossible 是因为：虽然 Appendable 接口的 append 方法会抛出 IOException，但是传入的 StringBuilder 在实现的时候并不会抛出改异常，所以为了适应这个接口，这里不得不捕捉异常。这样捕捉后的断言处理也就可以理解了。 巧妙的可变长参数转换有一个添加的重载函数如下所示：12345public final &lt;A extends Appendable&gt; A appendTo( A appendable, @NullableDecl Object first, @NullableDecl Object second, Object... rest) throws IOException &#123; return appendTo(appendable, iterable(first, second, rest)); &#125; 其中 iterable 函数将参数变为一个可以迭代的序列，该函数如下所示。12345678910111213141516171819202122private static Iterable&lt;Object&gt; iterable( final Object first, final Object second, final Object[] rest) &#123; checkNotNull(rest); return new AbstractList&lt;Object&gt;() &#123; @Override public int size() &#123; return rest.length + 2; &#125; @Override public Object get(int index) &#123; switch (index) &#123; case 0: return first; case 1: return second; default: return rest[index - 2]; &#125; &#125; &#125;; &#125; 通过实现 AbstractList 的方式，巧妙地复用了编译器生成的数组，减少了对象创建的开销。这样的实现需要对迭代器有深入的了解，因为要确保实现能够满足迭代器接口各个函数的语义。 Joiner 二次创建因为 Joiner 创建后就是不可更改的了，所以为了实现 useForNull 和 skipNulls 等语义，源码会再次创建一个匿名类，并覆盖相应的方法。 useForNull 函数汇中为了防止重复调用 useForNull 和 skipNulls，还特意覆盖了这两个方法，一旦调用就抛出运行时异常。为什么不能重复调用 useForNull ？因为覆盖了 toString 方法，而覆盖实现中需要调用覆盖前的 toString。12345678910111213141516171819public Joiner useForNull(final String nullText) &#123; checkNotNull(nullText); return new Joiner(this) &#123; @Override CharSequence toString(@NullableDecl Object part) &#123; return (part == null) ? nullText : Joiner.this.toString(part); &#125; @Override public Joiner useForNull(String nullText) &#123; throw new UnsupportedOperationException(&quot;already specified useForNull&quot;); &#125; @Override public Joiner skipNulls() &#123; throw new UnsupportedOperationException(&quot;already specified useForNull&quot;); &#125; &#125;;&#125; skipNulls 函数实现如下所示。个人比较奇怪的是 skipNulls 中为什么不禁止重复调用 skipNulls 函数。12345678910111213141516171819202122232425262728293031323334public Joiner skipNulls() &#123; return new Joiner(this) &#123; @Override public &lt;A extends Appendable&gt; A appendTo(A appendable, Iterator&lt;?&gt; parts) throws IOException &#123; checkNotNull(appendable, &quot;appendable&quot;); checkNotNull(parts, &quot;parts&quot;); while (parts.hasNext()) &#123; Object part = parts.next(); if (part != null) &#123; appendable.append(Joiner.this.toString(part)); break; &#125; &#125; while (parts.hasNext()) &#123; Object part = parts.next(); if (part != null) &#123; appendable.append(separator); appendable.append(Joiner.this.toString(part)); &#125; &#125; return appendable; &#125; @Override public Joiner useForNull(String nullText) &#123; throw new UnsupportedOperationException(&quot;already specified skipNulls&quot;); &#125; @Override public MapJoiner withKeyValueSeparator(String kvs) &#123; throw new UnsupportedOperationException(&quot;can&apos;t use .skipNulls() with maps&quot;); &#125; &#125;;&#125;]]></content>
      <categories>
        <category>Guava</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Guava</tag>
        <tag>String</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebSocket介绍]]></title>
    <url>%2F2018%2F03%2F14%2FWebSocket%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[本文是对 WebSocket 变化的介绍，是对以下资料的摘录： 维基：WebSocket 《WebSocket 教程》 RFC 6455：The WebSocket Protocol WebSocket 概览WebSocket 是一个计算机间的通信协议，它能够在单个 TCP 链接上构建一个双工的交流通道。WebSocket 协议的标准是由 IETE 在 2011年的 RFC 6455 中制定的。 WebSocket 是一个与 HTTP 并不相同的 TCP 的协议。WebSocket 和 HTTP 协议都是在7层网络模型（OSI model）中的，并且都依赖第4层的 TCP 协议。尽管两者并不相同，但 RFC 6455 中声明 “WebSocket 是可以工作在 HTTP协议 的80和443端口之上的，并且能够支持 HTTP 代理和中介”，这使得 WebSocket 可以兼容 HTTP 协议。为了实现这个兼容目标，WebSocket 的握手（handshake）使用了 HTTP 的 Upgrade 头部，从而实现从 HTTP 协议转换为 WebSocket 协议的目标。 WebSocket 能够建立客户端和服务器间的双向通信，目前很多浏览器都已经支持该协议了。同样，服务端也需要提供相应的支持。 WebSocket 协议标志是 ws（WebSocket）和 wss（WebSocket Secure）。 为什么需要 WebSocket由于 HTTP 是客户端发起的单向请求，对于聊天室这样需要服务端推送信息的场景就不是很适合。当然，客户端可以通过“轮询”的方式来了解服务端的信息，但是这样的效率比较低，比较浪费资源（因为必须不停连接，或者 HTTP 连接始终打开）。 和 HTTP 不同，WebSocket 是一个全双工协议，属于服务器推送技术的一种。在 WebSocket 之前，在80端口可以通过 Comet 通道实现全双工。但是由于 TCP 握手和 HTTP 头部的开销，对于数据量不大的信息来说，这样的机制不是很高效。WebSocket 协议的目标就是解决这些问题并且提供相应的安全保障。 握手协议WebSocket 建立连接的过程如下： 客户端发送 WebSocket 握手请求（和 HTTP 一样, 每行要以 \r\n 结尾，最后要有一个额外的空行）。 12345678GET /chat HTTP/1.1Host: server.example.comUpgrade: websocketConnection: UpgradeSec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw==Sec-WebSocket-Protocol: chat, superchatSec-WebSocket-Version: 13Origin: http://example.com 服务端回应握手请求。 12345HTTP/1.1 101 Switching ProtocolsUpgrade: websocketConnection: UpgradeSec-WebSocket-Accept: HSmrc0sMlYUkAGmm5OPpG2HaGWk=Sec-WebSocket-Protocol: chat 可以看到，客户端发送的请求头部除了 Upgrade 外，还有 Sec-WebSocket-Key 字段，它是包含base64编码的随机字节，服务端需要在 WebSocket-Accept 字段中返回这个键的hash值。这是为了防止缓存代理重发之前的 WebSocket 会话。 通过类 HTTP 形式的握手形式，可以使得服务端在同一个端口处理 HTTP 或者 WebSocket 协议。一旦 WebSocket 握手完成，通信马上变换成一个与 HTTP 协议不同的双向通道。 此外，从安全的角度来说，提供 Origin 标签是很有必要的，可以避免跨站点的 WebSocket 劫持攻击。 数据格式全双工的通道建立之后，传输的数据将会以尽可能小的格式进行封装：一个小的头部，紧跟着的是有效数据载体 payload)。WebSocket 传输的内容被称为“消息”，这个消息可以被划分成多个数据帧。这样在只有一部分初始数据（完整数据还未准备好）的时候就可以提前发送数据了。通过扩展，可以同时多路复用多个数据流（这样可以避免大负载数据对 socket 的独占使用）。 FIN（1 bit）表明消息是否是最后一帧。第一条消息也可能是最后一帧。 RSV1, RSV2, RSV3（每个都是1位）必须是0，除非扩展定义了非0值的意义。如果收到非0值，并且没有具体的定义，那么接收端必须使连接失败。 Opcode（4位）声明 “Payload data” 的含义。如果收到一个未知编码，那么接收端必须使连接失败。目前有以下这些值： %x0 denotes a continuation frame，表明是一个持续帧。 %x1 denotes a text frame，表明是一个文本帧。 %x2 denotes a binary frame，表明是一个二进制帧。 %x3-7 are reserved for further non-control frames，为未来的非控制帧保留。 %x8 denotes a connection close，定义一个连接结束。 %x9 denotes a ping，表示 ping 操作。 %xA denotes a pong，表示 pong 操作。 %xB-F are reserved for further control frames，为未来的控制帧保留。 Mask（1 bit）定义 “Payload data” 是否是隐秘的。如果设置为1，那么 masking-key 中会提供一个值，并且可以根据 5.3节 取消对应的标志。所有客户端发送到服务端的帧都需要把这位设置为1。 Payload length（7位 或 7+16位 或 7+64位）表示 “Payload data” 的长度。分为这几种情况： 如果是 0-125，那么就是实际长度。 如果是 126，那么接下来的2个字节作为一个16位的无符号整数，表示实际的长度。 如果是 127，那么接下来的8个字节作为一个64位的无符号整数，表示实际的长度。 其中多字节表示的长度在网络中必须按序排列。值得注意的是，在所有例子中，长度必须按最短的表示方式表示。Payload 数据的长度是由 “Extension data” （扩展数据）和 “Extension data”（应用数据）组成的，当扩展数据的长度为0时，payload 数据的长度就是应用数据的长度。 Masking-key（0位或者4位）所有从客户端发送到服务端的数据帧都需要有一个32位的 Masking-key。当 mask 位被设置为1的时候，这个域存在；当 mask 位被设置为0的时候，这个域不存在。可以看 5.3节 来进一步了解。 Payload data（x+y位）由 “Extension data”（扩展数据）和 “Application data”（应用数据）组成。 Extension data（x位）：扩展数据默认是0位，除非实现了一个扩展协议。每一个扩展的协议必须说明扩展数据的长度、长度是如何计算的、以及在握手阶段扩展是如何约定的。如果该部分数据存在，那么将会被记录到总的 payload 长度中。 Application data（y位）：应用数据在扩展数据之后，应用数据的长度等于 payload 的长度减去扩展数据的长度。 其它资料进一步了解可以参考这些文档： w3cschool HTML5 WebSocket WebSocket - Web APIs | MDN websocket.org WebSocket 的实现比较 WebSocket 是什么原理？为什么可以实现持久连接？ 推荐一款非常特别的 WebSocket 服务器：Websocketd。它的最大特点，就是后台脚本不限语言，标准输入（stdin）就是 WebSocket 的输入，标准输出（stdout）就是 WebSocket 的输出。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>WebSocket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK版本变化]]></title>
    <url>%2F2018%2F03%2F13%2FJDK%E7%89%88%E6%9C%AC%E5%8F%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[记录Java版本的更新历史，主要是对以下文章的结合： 《openjdk 文档》 《Java - JCP、JSR等名词介绍》 《从java1到java9每个版本都有什么新特性？》 《Java 9正式发布》 《JDK 10 本周将进入候选发布阶段，新特性抢先看》 《Java 老矣，尚能饭否？》 文章 Github 地址：JDKHistory。 一些术语 JCP 是 Java Community Process（Java社区进程）的简称，社会各界Java组成的社区，规划和领导Java的发展。 JEP 是 JDK Enhancement Proposals （Java 增强提案）的简称，JDK的版本变化将从这些提案中选取。 JSR 是 Java Specification Requests（Java规范请求）的简称，是 JCP 成员向委员会提交的 Java 发展议案，经过一系列流程后，如果通过会成为 JEP，最终会体现在未来的Java中。 TCK 是 Technology Compatibility Kit（技术兼容性测试）的简称， 如果一个平台型程序想要宣称自己兼容Java，就必须通过TCK测试 JDK 11JDK 11 目前出现了4个JEP，计划于 2018 年 9 月发布。 JEP 309: 动态类文件常量。 JEP 318: 低开销垃圾收集器 Epsilon。 JEP 320: 移除 Java EE 和 CORBA 模块。 JEP 323: Lambda 参数的本地变量语法。 JDK 10JDK 10 按计划将于2018年3月20日发布。新特性有： JEP 286: 局部变量的类型推导。该特性在社区讨论了很久并做了调查，可查看 JEP 286 调查结果。 JEP 296: 将 JDK 的多个代码仓库合并到一个储存库中。 JEP 304: 垃圾收集器接口。通过引入一个干净的垃圾收集器（GC）接口，改善不同垃圾收集器的源码隔离性。 JEP 307: 向 G1 引入并行 Full GC。 JEP 310: 应用类数据共享。为改善启动和占用空间，在现有的类数据共享（“CDS”）功能上再次拓展，以允许应用类放置在共享存档中。 JEP 312: 线程局部管控。允许停止单个线程，而不是只能启用或停止所有线程。 JEP 313: 移除 Native-Header Generation Tool (javah) JEP 314: 额外的 Unicode 语言标签扩展。包括：cu (货币类型)、fw (每周第一天为星期几)、rg (区域覆盖)、tz (时区) 等。 JEP 316: 在备用内存设备上分配堆内存。允许 HotSpot 虚拟机在备用内存设备上分配 Java 对象堆。 JEP 317: 基于 Java 的 JIT 编译器（试验版本）。 JEP 319: 根证书。开源 Java SE Root CA 程序中的根证书。 JEP 322: 基于时间的版本发布模式。“Feature releases” 版本将包含新特性，“Update releases” 版本仅修复 Bug 。 JDK 9JDK 9 于2017年9月21日发布。新特性有： 模块化 —— Jigsaw 交互式命令行 —— JShell 默认的垃圾回收器 —— G1 进程操作改进 竞争锁的性能优化 分段代码缓存 优化字符串占用空间 这个版本中最引人注目的时候模块化，通过这个工作，可以构建更小的运行时环境，只需要包括Java平台中任务依赖的部分。这可以更好地适应云端的开发。 具体的特性包括： JEP 102: 改善了控制和管理操作系统进程的 API。 JEP 110: 定义了一个新的 Http 客户端 API，它实现了 HTTP/2 和 WebSocket，并且可以替代遗留的 HttpURLConnection API。该 API 将会以一个 incubator 模块的形式进行交付。 JEP 143: 提高竞争 Java 对象的监视性能。 JEP 158: 统一 JVM 的日志。 JEP 165: 通过支持运行时管理来增加对 JVM 编译器的管理。 JEP 193: 对变量处理的改进。 JEP 197: 将代码缓存划分成不同的段。 JEP 200: 采用 Java 平台模块化系统（Java Platform Module System，JPMS）对JDK进行模块化。 JEP 201: 源代码模块化。 JEP 211: 在 import 语句中 省略 deprecation 的警告。 JEP 212: 解决 lint 和 doclint 警告。 JEP 213: Project Coin 的改变 JEP 214: 移除 JDK 8 中 GC 组合器的废弃说明。 JEP 215: 在 javac 中实现了一个新的类型检测策略。 JEP 216: 正确地处理导入声明。 JEP 217: 注解流水线 2.0。 JEP 219: 定义了数据传输层安全（Datagram Transport Layer Security, DTLS）API。 JEP 220: 模块化运行时镜像。 JEP 221: 简化 Doclet API。 JEP 222: jshell - Java 中的交互式命令行。 JEP 223: 新的版本字符串模式。 JEP 224: 增强了 javadoc 工具来生成 HTML5 标记。 JEP 225: 增加了 javadoc 搜索。 JEP 226: UTF-8 属性文件资源的Bundle相关变化。 JEP 227: Unicode 7.0。 JEP 228: 增加更多可诊断的命令。 JEP 229: 将默认的秘钥库从 JKS 替换为 PKCS12。 JEP 231: 移除运行时 JRE 版本选择。 JEP 232: 增强了安全相关应用的性能。 JEP 233: 开发了一个工具来自动测试运行时编译器。 JEP 235: 增加关于 javac 生成类文件属性的 测试。 JEP 236: 定义了解析 API 来支持 Nashorn 的 ECMAScript 抽象语法树。 JEP 237: Linux/AArch64 端口相关。 JEP 238: 多版本 JAR 文件。 JEP 240: 移除 JVM 的 TI hprof 客户端。 JEP 241: 移除 jhat 工具。 JEP 243: 提供 Java 语言级的 JVM 编译接口。 JEP 244: TLS 应用层协议协商。 JEP 245: 验证 JVM 命令行标志参数。 JEP 246: 利用 CPU 指令提升 GHASH 和 RSAd 的性能。 JEP 247: 对老平台版本的编译支持。 JEP 248: G1 作为默认的垃圾回收器。 JEP 249: 基于 TLS 实现 OCSP Stapling。 JEP 250: 在类数据分享（CDS）归档中存储 interned 字符串。 JEP 251: 多方案镜像。 JEP 252: 默认使用 CLDR Locale Data。 JEP 253: 为 JavaFX UI 控制 和 CSS API 的模块化做准备。 JEP 254: 采用一个空间更加高效的 String 内部表示。 JEP 255: 合并 Xerces 2.11.0 中的更新。 JEP 256: BeanInfo 注解调整。 JEP 257: 更新 JavaFX/Media 中 GStreamer 的版本。 JEP 258: 使用 HarfBuzz 作为字体布局引擎。 JEP 259: 定义了一个高效标准的 Stack-Walking API。 JEP 260: 封装大部分的内部 API。 JEP 261: 实现模块化系统。 JEP 262: 支持 TIFF 图像 I/O。 JEP 263: 实现 Windows 和 Linux 高分辨率图像接口。 JEP 264: 平台日志 API 和 服务。 JEP 265: Java 2D 使用 Marlin Graphics Renderer。 JEP 266: 并发相关的一些更新。 JEP 267: 支持 Unicode 8.0。 JEP 268: 支持 XML 目录。 JEP 269: 增加一些集合类创建的工厂方法。 JEP 270: 为临界区预留栈的某些区域。 JEP 271: 统一 GC 日志。 JEP 272: 增加特定平台的桌面特性。 JEP 273: Deterministic Random Bit Generator (DRBG) 的实现。 JEP 274: 增强方法处理器。 JEP 275: Java 应用模块化打包。 JEP 276: 语言定义对象模型的动态链接。 JEP 277: 改善 Deprecation。 JEP 278: 为 G1 中的巨大对象增加测试。 JEP 279: 改进测试故障排除。 JEP 280: 指示字符串串联。 JEP 281: HotSpot C++ 单元测试框架。 JEP 282: Java连接器 jlink。 JEP 283: 在 Linux 上支持 GTK 3。 JEP 284: 新的 HotSpot 构建系统。 JEP 285: 自旋等待提示。 JEP 287: 实现 SHA-3 Hash 算法。 JEP 288: 禁止 SHA-1 验证。 JEP 289: 废弃 Applet API。 JEP 290: 过滤输入的序列化数据。 JEP 291: 废弃 Concurrent Mark Sweep (CMS) 垃圾收集器。 JEP 292: 在 Nashorn 中支持 ECMAScript 6 特征。 JEP 294: Linux/s390x 端口。 JEP 295: 提前编译。 JEP 297: 统一 arm32/arm64 端口。 JEP 298: 移除过时的例子。 JEP 299: 重新组织文档。 JDK 8JDK 8 于2014年3月14号发布。从 Java 8 开始开发代号已经弃用了。新特性有: Lambda 表达式 Pipelines 和 Streams Date 和 Time API Default 方法 Type 注解 Nashhorn JavaScript 引擎 并发计数器 Parallel 操作 移除 PermGen Error TLS SNI 第三个有里程碑意义的 Java 版本。其中最引人注目的便是 Lambda 表达式了，从此 Java 语言原生提供了函数式编程能力。Java 8 更加适应海量云计算的需要。 具体的特性包括： JEP 117: 移除注解处理工具（Annotation-Processing Tool，apt）。 JEP 124: 增强证书撤销检查 API。 JEP 130: 实现 SHA-224 消息摘要算法。 JEP 131: 在 64-bit Windows 中支持 PKCS#11。 JEP 112: Charset 实现改善。 JEP 129: 实现 NSA Suite B 加密算法。 JEP 105: DocTree API。 JEP 106: 扩展 javax.tools API 来支持 javadoc 的访问。 JEP 113: 在 JDK 的 Kerberos 5 中添加 MS-SFU 扩展。 JEP 114: TLS Server Name Indication (SNI) 扩展。 JEP 121: 提供更强的 Password-Based-Encryption (PBE) 算法实现。 JEP 122: 移除永久带（Permanent Generation）。 JEP 127: 改善 Locale Data Packaging，并且采用 Unicode CLDR Data。 JEP 128: Unicode BCP 47 本地匹配。 JEP 133: 支持 Unicode 6.2。 JEP 136: 增强错误验证。 JEP 153: 启动 JavaFX 应用。 JEP 177: 优化 java.text.DecimalFormat.format。 JEP 103: 并行数组排序。 JEP 135: Base64 编码和解码。 JEP 138: 基于 Autoconf 的自动构建系统。 JEP 139: 增强 javac 来提高构建速度。 JEP 142: 减少对于特定域的高速缓存的争夺。 JEP 147: 减少类元数据占用。 JEP 148: 支持小虚拟机（不超过3M）的创建。 JEP 149: 减少核心库的内存使用。 JEP 150: 新的 Date 和 Time API。 JEP 160: lambda 函数表达式。 JEP 164: 利用 CPU 指令进行 AES 加密。 JEP 166: 针对JKS、JCEKS、PKCS12秘钥存储的修改。 JEP 170: JDBC 4.2。 JEP 172: DocLint。 JEP 173: 放弃一些很少使用的 GC 组合。 JEP 101: 泛华目标类型接口。 JEP 104: 在 Java 类型上加注解。 JEP 107: 增加集合的批量数据操作。 JEP 109: 在核心库中增加 Lambda 表达式。 JEP 115: 认证加密的密码套件。 JEP 118: 在运行时访问参数名称。 JEP 119: 通过反射实现 javax.lang.model.* API。 JEP 120: 重复注解。 JEP 123: 可配置的安全随机数生成。 JEP 126: lambda 表达式和虚拟扩展方法。 JEP 140: 限制的 doPrivileged。 JEP 155: 并发库更新。 JEP 161: 紧凑版本。 JEP 162: 为模块化做准备。 JEP 171: 在 sun.misc.Unsafe 中增加三个内存排序相关的指令。 JEP 174: Nashorn JavaScript 引擎。 JEP 176: 提供调用者敏感的检测机制。 JEP 178: 静态链接的 jni 库。 JEP 179: JDK API 的文档的支持和稳定。 JEP 180: 对于频繁冲突的 HashMap 使用平衡树。 JEP 184: HTTP URL的权限。 JEP 185: 限制外部 XML 资源的获取。 JDK 7开发代号是 Dolphin（海豚），于2011年7月28日发行。新特性有： switch 语句块中允许以字符串作为分支条件； 在创建泛型对象时应用类型推断； 在一个语句块中捕获多种异常； 支持动态语言； 支持 try-with-resources； 引入 Java NIO.2 开发包； 数值类型可以用2进制字符串表示，并且可以在字符串表示中添加下划线； 钻石型语法； null 值的自动处理。 这个版本中的主要的特性是 NIO2 和 Fork/Join 并发包，Java 虚拟机的稳定性真正做到的工业级，成为一个计算平台而服务于全世界。 JDK 6开发代号为 Mustang（野马），于2006年12月11日发行。新特性有： 支持脚本语言； 引入 JDBC 4.0 API； 引入 Java Compiler API； 可插拔注解； 增加对 Native PKI(Public Key Infrastructure)、Java GSS(Generic Security Service)、Kerberos 和 LDAP(Lightweight Directory Access Protocol) 的支持； 继承 Web Services； 做了很多优化。 这个语言语法改进不多，但在虚拟机内部做了大量的改进，成为一个相当成熟稳定的版本，时至今日国内的很多公司依然以 Java6 作为主要 Java 开发版本来使用。 同年 Sun 公司做出一个伟大的决定，将 Java 开源。OpenJDK 从 Sun JDK 1.7 版本分支出去，成为今天 OpenJDK 的基础。 JDK 5开发代号为Tiger（老虎），于2004年9月30日发行。新特性包有: 引入泛型； 增强循环，可以使用迭代方式； 自动装箱与自动拆箱； 类型安全的枚举； 可变参数； 静态引入； 元数据（注解）； 引入 Instrumentation。 Sun 不再采用 J2SE, J2EE 这种命名方式，而使用 Java SE 5, Java EE 5 这样的名称。 Java 5 是第二个里程碑式的版本。Java 语言语法发生很大的变化，如注解 (Annotation)，装箱 (Autoboxing)，泛型 (Generic)，枚举 (Enum)，foreach 等被加入，提供了 java.util.concurrent 并发包。 Java 5 对于 Java 语言的推动是巨大的，特别是注解的加入，使得语言定义灵活了很多，程序员可以写出更加符合领域定义的描述性程序。 JDK 1.4开发代号为 Merlin（隼），于2004年2月06日发行（首次在JCP下发行）。新特性有: XML 处理； Java 打印服务； 引入 Logging API； 引入 Java Web Start； 引入 JDBC 3.0 API； 引入断言； 引入 Preferences API； 引入链式异常处理； 支持 IPv6； 支持正则表达式； 引入 Image I/O slot machine API。 Java 语言真正走向成熟，提供了非常完备的语言特性，如 NIO，正则表达式，XML 处理器等。 同年微软的.NET 框架发布，两者开始了为期十几年的暗自竞争。从语言特性上来说，.NET 后发先至，一直处于优势。但 Java 依赖良好的开发者生态，绝大多数大型软件公司的使用者众多和不断贡献，以及对 Linux 操作系统良好的支持，渐渐的在服务器端获得优势地位。 JDK 1.3开发代号为 Kestrel（红隼），于2000年5月08日发行。新特性有： 引入Java Sound API； jar 文件索引； 对 Java 的各个方面都做了大量优化和增强。 J2EE 中的 Servlet 规范获得了极大的成功，伴随着互联网的兴起，和浏览器直接通过 HTTP 协议交互的 Servlet，和众多的 MVC 框架，成为 Web1.0 的网红。 JDK 1.2开发代号为 Playground（操场），于1998年12月8日发行。新特性有： 引入集合（Collection）框架； 对字符串常量做内存映射； 引入 JIT（Just In Time） 编译器； 引入对打包的 Java 文件进行数字签名； 引入控制授权访问系统资源的策略工具； 引入 JFC（Java Foundation Classes），包括 Swing 1.0、拖放和 Java 2D 类库； 引入 Java 插件； 在 JDBC 中引入可滚动结果集、BLOB、CLOB、批量更新和用户自定义类型； 在 Applet 中添加声音支持。 Java 第一个里程碑式的版本。JIT（Just in time）编译器技术，使得语言的可迁移性和执行效率达到最优的平衡，同时 Collections 集合类设计优良，在企业应用开发中迅速得到了广泛使用。 Sun 公司把 Java 技术体系分成三个方向，分别是 J2SE（面向桌面和通用应用开发），J2EE（面向企业级应用开发），J2ME（面向移动终端开发）。这个分类影响非常久远，体现出主流语言设计者的思想：针对于不同的应用领域，在形态，API 集合等进行划分。 JDK 1.1于 1997年2月19日发行，新特性有： 引入JDBC（Java Database Connectivity）； 支持内部类； 引入Java Bean； 引入RMI（Remote Method Invocation）； 引入反射（仅用于内省）。 Java 语言的基本形态基本确定了，比如反射 (reflection), JavaBean, 接口和类的关系等等，一直到今天都保持一致。然而，Java 最初的一些目标，如在浏览器中执行 Applet，以及跨平台的图形界面 Awt 很快遭遇到负面的评价。 JDK 1.0开发代号为Oak（橡树），于1996年1月23发行。特点有： 提供了一个解释执行的 Java 虚拟机； Applet 能在 Mozilla 浏览器中运行。 Java 的 Applet 能在 Mozilla 浏览器中运行，被看作是未来的互联网语言。 起源Java 语言源于 1991 年 Sun 公司 James Gosling 领导的的 Ork 项目，1995 年 Sun 公司正式起名为 Java，并提出“Write once, Run anywhere”的口号。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP变化介绍]]></title>
    <url>%2F2018%2F03%2F13%2FHTTP%E5%8F%98%E5%8C%96%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[本文是对 HTTP 变化的介绍，是对以下资料的摘录： 《Hypertext Transfer Protocol》 《HTTP,HTTP2.0,SPDY,HTTPS看这篇就够了》 《HTTP/2.0 相比1.0有哪些重大改进？》 本科课件 HTTP 概览HTTP 是 Hypertext Transfer Protocol 的简称，中文是超文本传输协议。它是一个应用层协议，可以支持分布式的、协作的、具有富文本信息的系统。（定义来自维基百科） HTTP 的发展过程如下所示： 1989年，HTTP 起源于 Tim Berners-Lee 在 CERN 的工作。HTTP 的标准化发展过程是由因特网工程任务组（Internet Engineering Task Force，IETF）和万维网联盟（World Wide Web Consortium，W3C）共同推进的，主要是一系列的 RFC 标准（Requests for Comments，RFCs）。 1991年，HTTP 第一个标准文档 HTTP V0.9 发布。 1996年，Dave Raggett 领导了 HTTP 工作组（HTTP Working Group，HTTP WG）进一步完善了 HTTP 的功能，在 RFC 1945 中发布了 HTTP V1.0。 1997年，一个使用更加广泛的版本 HTTP/1.1 在 RFC 2068 中被提出。1999年发布的 RFC 2616 对上一个版本进行了更新。2014年又发布了6个规范进行了一步的升级，具体包括： RFC 7230, HTTP/1.1: Message Syntax and Routing（消息语法和路由）RFC 7231, HTTP/1.1: Semantics and Content（语义和内容）RFC 7232, HTTP/1.1: Conditional Requests（条件请求）RFC 7233, HTTP/1.1: Range Requests（范围请求）RFC 7234, HTTP/1.1: Caching（缓存）RFC 7235, HTTP/1.1: Authentication（认证） 2015年，一个新的标准 HTTP/2 在 RFC 7540 中发布，它建立在 TLS 层上，使用 ALPN 进行扩展，现在已经被很多 web 服务器和浏览器支持了。 HTTP 基本优化影响 HTTP 响应速度的因素主要有：带宽和延迟。由于带宽是外在环境，并且这些年带宽速度得到了极大提升，所以不再详细介绍。 而影响延迟的因素又包括： 浏览器阻塞（HOL blocking）：浏览器会因为一些原因阻塞请求。浏览器客户端在同一时间，针对同一域名下的请求有一定数量限制。超过限制数目的请求会被阻塞。具体如下表所示（表格来源）： 浏览器 HTTP/1.1 HTTP/1.0 IE 6,7 2 4 IE 8 6 6 Firefox 2 2 8 Firefox 3 6 6 Safari 3,4 4 4 Chrome 1,2 6 ？ Chrome 3 4 4 Chrome 4+ 6 ？ iPhone 2 4 ？ iPhone 3 6 ？ iPhone 4 4 ？ Opera 9.63,10.00alpha 4 4 Opera 10.51+ 8 ？ DNS 查询（DNS Lookup）：浏览器需要知道目标服务器的 IP 才能建立连接。将域名解析为 IP 的这个系统就是 DNS。这个通常可以利用DNS缓存结果来达到减少这个时间的目的。 建立连接（Initial connection）：HTTP 是基于 TCP 协议的，浏览器最快也要在第三次握手时才能捎带 HTTP 请求报文，达到真正的建立连接，但是这些连接无法复用会导致每次请求都经历三次握手和慢启动。三次握手在高延迟的场景下影响较明显，慢启动则对文件类大请求影响较大。 HTTP 1.1HTTP 1.1 在1999年才开始广泛应用于现在的各大浏览器网络请求中，同时 HTTP 1.1 也是当前使用最为广泛的 HTTP 协议。HTTP 1.0 的新特性有： 长连接。HTTP 1.1 支持长连接（PersistentConnection）和 请求的流水线（Pipelining）处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在 HTTP 1.1 中默认开启 Connection： keep-alive，一定程度上弥补了 HTTP 1.0 每次请求都要创建连接的缺点。 缓存处理。在 HTTP 1.0 中主要使用 header 里的 If-Modified-Since、Expires 来做为缓存判断的标准，HTTP 1.1 则引入了更多的缓存控制策略，如：Entity tag、If-Unmodified-Since、If-Match、If-None-Match等，可以基于此提供更多的缓存控制策略。 带宽优化及网络连接的使用。HTTP 1.0 中，存在一些浪费带宽的现象，如：客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP 1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由选择资源区域，便于充分利用带宽和连接。 错误通知的管理。在 HTTP 1.1 中新增了24个错误状态响应码，如：409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。 Host头处理。在 HTTP 1.0 中认为每台服务器都绑定一个唯一的IP地址，因此请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP 1.1 的请求消息和响应消息都应支持Host头域，且请求消息中如果没有 Host 头域会报告一个错误（400 Bad Request）。 缓冲区指针。实现缓冲区指针允许客户和服务器的缺省缓冲区算法可以被调用或优化。* 主机标题。HTTP 1.1 协议允许多重主机名与一个单独的IP地址相关联。这样就不用给一个驻留许多虚拟服务器的 Web 服务器配置多个IP地址了。这个主机标题可以用来确定请求应该被导向哪个虚拟服务器。 PUT和DELETE选项。这些命令允许一个远程管理者通过使用一个标准的 Web 浏览器来记入或删除一些内容。 HTTP重定向。当原始的主页不能访问或被删除时，这个特性允许一个管理者将一个用户重定向到一个备选的主页或 Web 站点。 HTTP 1.0 和 1.1 的一些问题 HTTP 1.x 在传输数据时，每次都需要重新建立连接，这增加了大量的延迟时间，在移动端更为突出。 HTTP 1.x 在传输数据时，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份，这在一定程度上无法保证数据的安全性。 HTTP 1.x 在使用时，header里携带的内容过大，在一定程度上增加了传输的成本，并且每次请求header基本不怎么变化。在移动端用户流量较大时，问题更为突出。 HTTP 1.x 虽然通过支持keep-alive来弥补多次创建连接产生的延迟，但是keep-alive使用多了同样会给服务端带来大量的性能压力，并且对于单个文件被不断请求的服务(如图片存放网站)，keep-alive可能会极大的影响性能，因为它在文件被请求之后，还长时间地保持了不必要的连接。 HTTPS为了解决传输的安全问题，Netscape 在1994年创建了 HTTPS ，并应用在浏览器中。最初，HTTPS 是与 SSL 一起使用的，后来 SSL 逐渐演变到 TLS （本质上两个是一个东西）。最新的 HTTPS 在2000年5月公布的RFC 2818正式确定下来。 简单来说，HTTPS 就是安全版的 HTTP，并且由于当今时代对安全性要求更高，Chrome 和 Firefox 都大力支持网站使用 HTTPS，苹果也在 IOS 10系统中强制 App 使用 HTTPS 来传输数据，由此可见 HTTPS 势在必行。 HTTPS 与 HTTP 的一些区别 HTTPS 协议需要到 CA 申请证书。 HTTP 是超文本传输协议，信息是明文传输，HTTPS 则是具有安全性的 SSL 加密传输协议。可进行身份认证，比 HTTP 协议安全。 HTTP 和 HTTPS 使用的是完全不同的连接方式，用的端口也不一样，HTTP 是80，HTTPS 是443。 HTTPS 由于增加了 SSL 的握手过程，会有一定的性能损失。此外，由于有较多的秘钥算法计算，需要关注服务端的 CPU 压力。推荐一个PPT《淘宝HTTPS探索》。 SPDY2012年 Google 提出了 SPDY 的方案，大家才开始从正面看待和解决老版本 HTTP 协议本身的问题，SPDY 综合了 HTTPS 和 HTTP 两者的优点于一体，主要特点如下所示： 降低延迟。针对 HTTP 高延迟的问题，SPDY优雅的采取了多路复用（multiplexing）。多路复用通过多个请求 stream 共享一个 TCP 连接的方式，解决了 HOL blocking 的问题，降低了延迟同时提高了带宽的利用率。 请求优先级（request prioritization）。多路复用带来一个新的问题是，在连接共享的基础之上有可能会导致关键请求被阻塞。SPDY 允许给每个 request 设置优先级，这样重要的请求就会优先得到响应。如:浏览器加载首页，首页的html内容应该优先展示，之后才是各种静态资源文件，脚本文件等加载，这样可以保证用户能第一时间看到网页内容。 header压缩。前面提到 HTTP1.x 的 header 很多时候都是重复多余的。选择合适的压缩算法可以减小包的大小和数量。 基于 HTTPS 的加密协议传输。大大提高了传输数据的可靠性。 服务端推送（server push）。采用了 SPDY 的网页，例如：网页有一个 sytle.css 的请求，在客户端收到 sytle.css 数据的同时，服务端会将 sytle.js 的文件推送给客户端，当客户端再次尝试获取 sytle.js 时就可以直接从缓存中获取到，不用再发请求了。 SPDY 构成图如下所示： HTTP 2.0HTTP 2.0 可以说是 SPDY 的升级版（其实原本也是基于 SPDY 设计的）。但 HTTP2.0 跟 SPDY 仍有不同的地方，主要是： HTTP 2.0 支持明文 HTTP 传输，而 SPDY 强制使用 HTTPS。 HTTP 2.0 消息头的压缩算法采用 HPACK，而 SPDY 采用的是 DEFLATE。 HTTP 2.0 与 HTTP 1.0 的速度对比如下（演示网站）： HTTP 2.0 的一些新的特性包括： 多路复用（MultiPlexing），即连接共享。 每一个 request 都是是用作连接共享机制的。一个 request 对应一个id，这样一个连接上可以有多个request，每个连接的 request 可以随机的混杂在一起，接收方可以根据 request 的 id 将 request 归属到各自不同的服务端请求里面。多路复用原理图如下所示： 新的二进制格式（Binary Format），HTTP1.x 的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认0和1的组合。基于这种考虑 HTTP 2.0 的协议解析决定采用二进制格式，实现方便且健壮。实现关键之一就是在应用层（HTTP/2）和传输层（TCP 或 UDP）之间增加一个二进制分帧层。 Header 压缩。前面提到过 HTTP1.x 的 header 带有大量信息，而且每次都要重复发送，HTTP2.0 使用 encoder 来减少需要传输的 header 大小，通讯双方各自 cache 一份 header fields 表，既避免了重复 header 的传输，又减小了需要传输的大小。 服务端推送（server push）。同SPDY一样，HTTP 2.0 也具有 server push 功能。目前，有大多数网站已经启用 HTTP 2.0 了。 更多关于 HTTP 2.0 资料如下： 《HTTP2 奇妙日常》。 HTTP 2.0 的官方网站。 《HTTP2 讲解》。 《HTTP/2 for Front-End Developers》。 《7 Tips for Faster HTTP/2 Performance》。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>Http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池的使用]]></title>
    <url>%2F2018%2F03%2F04%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[本文对 Java 中的线程池的使用进行学习。是对以下文章的摘录： JDK 源码 阿里编程规范插件提示 ExecutorExecutor 接口Java 类库中任务执行的抽象接口是 Executor。这个接口使得任务提交和任务如何被执行（包括线程使用细节、调度等）得到了解耦。该接口如下所示：123456789101112131415/* * @since 1.5 * @author Doug Lea */public interface Executor &#123; /** * 在将来某个时刻执行任务（ command ）。这个任务可以通过这些方式执行：在一个新的线程中执行、 * 在一个缓存的线程中执行、在调用者线程中执行。具体取决于 Executor 的实现方式。 * * @param command 需要运行的任务 * @throws RejectedExecutionException 如果执行器不接受任务，则抛出改异常。 * @throws NullPointerException 如果任务为 null */ void execute(Runnable command);&#125; 使用 Executor 执行任务Executor 经常被用来代替显示地创建线程。自己手工创建线程执行（不建议）：1new Thread(new RunnableTask()).start() 使用 Executor 执行：1234Executor executor = anExecutor;executor.execute(new RunnableTask1());executor.execute(new RunnableTask2());... Executor 的执行方案Executor 接口并不强制异步执行任务。一个简单的例子是，执行器可以在调用线程中立刻运行提交任务。12345class DirectExecutor implements Executor &#123; public void execute(Runnable r) &#123; r.run(); &#125;&#125;&#125; 更加典型的方案是，在其它线程而非调用者线程中执行任务。下面的 executor 为每个任务创建了一个执行线程。12345class ThreadPerTaskExecutor implements Executor &#123; public void execute(Runnable r) &#123; new Thread(r).start(); &#125;&#125;&#125; 很多 Executor 的实现对任务何时以何种方式执行都会添加一些限制。下面的执行器将提交的任务按顺序在另一个执行器中执行，成为一个组合执行器。123456789101112131415161718192021222324252627282930313233class SerialExecutor implements Executor &#123; final Queue&lt;Runnable&gt; tasks = new ArrayDeque&lt;Runnable&gt;(); final Executor executor; Runnable active; SerialExecutor(Executor executor) &#123; this.executor = executor; &#125; public synchronized void execute(final Runnable r) &#123; tasks.offer(new Runnable() &#123; public void run() &#123; try &#123; r.run(); &#125; finally &#123; // 每个任务执行完后，执行下一个任务 scheduleNext(); &#125; &#125; &#125;); // 没有任务的时候，启动此任务 if (active == null) &#123; scheduleNext(); &#125; &#125; protected synchronized void scheduleNext() &#123; // 当下一个任务存在时，执行任务 if ((active = tasks.poll()) != null) &#123; executor.execute(active); &#125; &#125;&#125;&#125; ExecutorServiceExecutorService 接口Executor 有一个扩展接口 ExecutorService。ExecutorService 能够提供方法来管理终止，也能够创建 Future 来跟踪一个或多个任务的异步执行过程。该接口如下图所示： ExecutorService 关闭ExecutorService 可以被关闭，关闭后它会拒绝新的任务。有两种关闭 ExecutorService 的方法： shutdown：该方法将会保证关闭之前提交的任务会在关闭前被执行。 shutdownNow：将会阻止任务的启动，并且尝试停止当前执行的任务。 一旦 ExecutorService 被关闭（termination），执行器将会没有正在运行的任务、没有正在等待执行的任务、没有新的任务被提交。一个没有使用的 ExecutorService 应该被关闭，从而使得资源可以被回收， 任务执行submit 方法扩展于 Executor 中的基本方法 execute(Runnable)，该方法创建和返回了一个 Future 对象，通过这个对象可以取消任务的执行或者等待任务的结束。 invokeAny 和 invokeAll 方法可以用来执行非常通用有效的批量执行。执行一批任务，等待它们中的一个或者全部执行完成。ExecutorCompletionService 可以用来实现这些方法的变体。 使用例子下面是一个网络服务的例子。该例子通过线程池中的线程来服务到达的请求，使用到了Executors中的 newFixedThreadPool 方法。12345678910111213141516171819202122232425262728class NetworkService implements Runnable &#123; private final ServerSocket serverSocket; private final ExecutorService pool; public NetworkService(int port, int poolSize) throws IOException &#123; serverSocket = new ServerSocket(port); pool = Executors.newFixedThreadPool(poolSize); &#125; public void run() &#123; // run the service try &#123; for (;;) &#123; pool.execute(new Handler(serverSocket.accept())); &#125; &#125; catch (IOException ex) &#123; pool.shutdown(); &#125; &#125; &#125; class Handler implements Runnable &#123; private final Socket socket; Handler(Socket socket) &#123; this.socket = socket; &#125; public void run() &#123; // read and service request on socket &#125; &#125;&#125; 下面的代码展示了通过两个阶段关闭 ExecutorService: 首先，调用 shutdown 来拒绝之后到达的任务。 然后，如果有必要的话，可调用 shutdownNow 来取消滞留的任务。 1234567891011121314151617void shutdownAndAwaitTermination(ExecutorService pool) &#123; pool.shutdown(); // Disable new tasks from being submitted try &#123; // Wait a while for existing tasks to terminate if (!pool.awaitTermination(60, TimeUnit.SECONDS)) &#123; pool.shutdownNow(); // Cancel currently executing tasks // Wait a while for tasks to respond to being cancelled if (!pool.awaitTermination(60, TimeUnit.SECONDS)) System.err.println(&quot;Pool did not terminate&quot;); &#125; &#125; catch (InterruptedException ie) &#123; // (Re-)Cancel if current thread also interrupted pool.shutdownNow(); // Preserve interrupt status Thread.currentThread().interrupt(); &#125;&#125;&#125; ThreadPoolExecutorThreadPoolExecutor 类提供了一个可扩展的线程池实现。 基本介绍线程池用来解决两个不同方面的问题： 由于减少了每个任务的调用开销，通常可以在执行大量异步任务的时候提高性能。 提供了资源控制和管理的。 每个 ThreadPoolExecutor 具有一些基本的统计，例如：任务执行完成的数量。 为了适应广泛的应用场景，该类提高了很多可以调整的参数以及可以扩展的钩子。此外，更简单的一种方式是使用 Executors 中的一些工厂方法，包括： newCachedThreadPool：没有边界，自带线程复用。 newFixedThreadPool：固定线程池大小。 newSingleThreadExecutor: 单线程。 这些覆盖了大部分通用的场景。 构造函数当需要手工配置这个类或者对其参数进行调整时，就需要了解其构造函数。ThreadPoolExecutor 有很多构造函数，下面是最常见的形式。1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; ... &#125; corePoolSize and maximumPoolSizeThreadPoolExecutor 将自动通过基本大小（corePoolSize）、最大大小（maximumPoolSize）来调整线程池的大小。 当有新的任务通过 execute(Runnable) 方法提交时： 如果当前运行的线程数目小于基本大小（corePoolSize），即使有其它空闲线程，也将会创建一个新的线程来处理这个请求。 如果当前运行的线程数目大于基本大小（corePoolSize），小于最大大小（maximumPoolSize），并且缓存的队列（queue）满的时候，将会创建新的线程。 设置示例： 通过设置 corePoolSize 和 maximumPoolSize 相同，你可以创建一个固定大小（fixed-size）的线程池。 通过将 maximumPoolSize 设置成一个很大的值，比如：Integer.MAX_VALUE，可以使线程池容纳任意数量的并发任务。 通常，这些参数在构造函数中被设置，但是它们也可以通过这些方法动态改变： setCorePoolSize setMaximumPoolSize keepAliveTime如果线程池中当前执行的线程数目大于 corePoolSize，那么对于多出的线程，当它们空闲的时间超过 keepAliveTime 时，它们将被终止。 这样的机制，使得当线程池不活跃的时候，可以减少资源的消耗。当线程池变得活跃的时候，新的线程会被创建。这个参数也通过 setKeepAliveTime(long TimeUnit) 方法动态改变。 通过设置这个参数为 Long.MAX_VALUE TimeUnit.NANOSECONDS，可以禁止空闲的线程被终止。 默认情况下，这个 keep-alive 策略只会在当前线程数目超过 corePoolSize 的时候才会起作用，也可以通过 allowCoreThreadTimeOut(boolean) 来控制，此时 keepAliveTime 的值不能为0. QueuingBlockingQueue 可以用来转移和持有提交的任务。它的使用时和线程池的大小相关的： 如果小于 corePoolSize 数目的线程在运行，那么 Executor 倾向于创建新的线程来执行任务，而不是将任务缓存到队列中。 如果大于等于 corePoolSize 数目的线程在运行，那么 Executor 倾向于将任务缓存到队列中，而不是创建新的线程。 如果请求达到限制无法被缓存到队列中，那么一个新的线程将会被创建，当创建的线程数将要超过 maximumPoolSize 时，新的任务将会被拒绝。 以下是一些通用的队列策略： 直接切换：工作队列一个好的默认选择可以是 SynchronousQueue，它可以将任务交给线程执行，并且不需要缓存任务。当没有线程可用的时候，尝试缓存任务到队列中将会立即失败，因此一个新的线程将会被创建。这个策略可以避免由于任务间存在内部依赖造成的死机。直接切换通常需要一个没有限制的 maximumPoolSizes，从而避免拒绝新的任务，但当处理不够及时，线程数目也会持续增加。 无界队列：使用无界队列（例如：LinkedBlockingQueue 没有预先定义队列容量），如果所有的 corePoolSize 线程都很忙碌，那么新的任务将会被保存在队列中进行等待。因此，线程数永远不会超过 corePoolSize，而 maximumPoolSize 的值在这里也不会起作用。这样的策略比较适合于每个任务都是独立执行的场景。例如，在 Web 页面服务中，队列可以用来平滑瞬时的访问高峰。 有界队列：一个有界限的队列（例如：ArrayBlockingQueue）可以防止 maximumPoolSizes 被设置为无限大时造成的资源耗尽。队列的大小和线程池大小可以互相调和：使用大的队列和小的线程池可以降低 CPU 使用率、操作系统资源占有、上下文切换的开销，但是会导致较低的吞吐量。如果任务经常被阻塞（I/O 受限），系统可能会调度更多的线程，超过你开始的限制。当使用小队列的时候，需要使用较大的线程池大小，这可以使得 CPU 更加忙碌，但是可能会由于频繁的上下文切换，导致吞吐量下降。 ThreadFactoryThreadFactory 是用来创建新的线程。下面是该接口的声明。12345678910111213/** * @since 1.5 * @author Doug Lea */public interface ThreadFactory &#123; /** * 构建线程 Thread。实现中可以设置优先权、名字、守护状态、线程组等。 * * @param r 一个可以被线程实例运行的任务 * @return 创建的线程或者 null (创建被拒绝) */ Thread newThread(Runnable r);&#125; 该接口一个简单的实现为：12345class SimpleThreadFactory implements ThreadFactory &#123; public Thread newThread(Runnable r) &#123; return new Thread(r); &#125;&#125;&#125; Executors 中的 defaultThreadFactory 方法提供了一个更加简单实用的实现，可以设置线程环境为已知值。1234567891011121314151617181920212223242526static class DefaultThreadFactory implements ThreadFactory &#123; private static final AtomicInteger poolNumber = new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; DefaultThreadFactory() &#123; SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = &quot;pool-&quot; + poolNumber.getAndIncrement() + &quot;-thread-&quot;; &#125; public Thread newThread(Runnable r) &#123; Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; &#125;&#125; Rejected tasks在以下两种情况下，新的任务将会被拒绝： Executor 被关闭。 Executor 使用有界的线程池大小和工作队列容量后，达到饱和。 任何一种情况下，都会调用 RejectedExecutionHandler 中的 rejectedExecution 方法。 预先定义的一些拒绝策略包括： 默认是 ThreadPoolExecutor.AbortPolicy，它在拒绝时会抛出一个运行时异常 RejectedExecutionException。 ThreadPoolExecutor.CallerRunsPolicy 策略是让调用者自己来运行这个任务。这实现了一个简单的反馈控制机制，来降低新任务的提交速率。 ThreadPoolExecutor.DiscardPolicy 方法直接丢弃任务。 ThreadPoolExecutor.DiscardOldestPolicy 如果 executor 没有被关闭，那么丢弃队列头上的任务，任务执行会再次尝试。 扩展例子很多基于该类的扩展都是覆盖一个或多个受保护的函数。下面例子就展示了一个子类，该之类添加了简单的暂停和恢复特性：1234567891011121314151617181920212223242526272829303132333435363738class PausableThreadPoolExecutor extends ThreadPoolExecutor &#123; private boolean isPaused; private ReentrantLock pauseLock = new ReentrantLock(); private Condition unpaused = pauseLock.newCondition(); public PausableThreadPoolExecutor(...) &#123; super(...); &#125; protected void beforeExecute(Thread t, Runnable r) &#123; super.beforeExecute(t, r); pauseLock.lock(); try &#123; while (isPaused) unpaused.await(); &#125; catch (InterruptedException ie) &#123; t.interrupt(); &#125; finally &#123; pauseLock.unlock(); &#125; &#125; public void pause() &#123; pauseLock.lock(); try &#123; isPaused = true; &#125; finally &#123; pauseLock.unlock(); &#125; &#125; public void resume() &#123; pauseLock.lock(); try &#123; isPaused = false; unpaused.signalAll(); &#125; finally &#123; pauseLock.unlock(); &#125; &#125; &#125;&#125; ExecutorsExecutors 类提供了方便的工厂方法来创建这些执行器。 newFixedThreadPool该方法创建的线程池可以重复使用固定数目的线程，使用无限制的队列。123456public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory);&#125; newSingleThreadExecutor单线程执行，使用无限制的队列。1234567public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory));&#125; newCachedThreadPool使用无限制的线程池，空线程超过60秒被回收，线程执行采用直接交付策略。123456public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;(), threadFactory);&#125; newScheduledThreadPool采用 ScheduledThreadPoolExecutor。123public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize);&#125; newWorkStealingPool采用 ForkJoinPool , 开始于 JDK 1.8。123456public static ExecutorService newWorkStealingPool(int parallelism) &#123; return new ForkJoinPool (parallelism, ForkJoinPool.defaultForkJoinWorkerThreadFactory, null, true);&#125; 阿里编程规范使用说明线程池不允许实用 Executor 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式可以更加明确线程次的运行规则，规避资源耗尽的风险。 Executor 各个方法的弊端说明： newFixedThreadPool 和 newSingleThreadPool：主要问题是堆积的请求处理队列可能会耗费非常大的内存，甚至 OOM。 newCachedThreadPool 和 newScheduledThreadPool：主要问题是线程的最大数是 Integer.MAX_VALUE，可能会创建非常多的线程数，甚至 OOM。 使用示例例子1：123// org.apache.commons.lang3.concurrent.BasicThreadFactoryScheduledExecutorService executorService = new ScheduledThreadPoolExecutor(1, new BasicThreadFactory.Builder().namingPattern(&quot;example-schedule-pool-%d&quot;).daemon(true).build()); 例子2：123456789101112// com.google.common.util.concurrent.ThreadFactoryBuilderThreadFactory namedThreadFactory = new ThreadFactoryBuilder() .setNameFormat(&quot;demo-pool-%d&quot;).build(); // Common Thread PoolExecutorService pool = new ThreadPoolExecutor(5,200, 0L,TimeUnit.MILLISECONDS, new LinkedBlockingDeque&lt;Runnable&gt;(1024),namedThreadFactory, new ThreadPoolExecutor.AbortPolicy());pool.execute(()-&gt; System.out.println(Thread.currentThread().getName()));pool.shutdown(); // gracefully shutdown 例子3：1234567891011&lt;bean id=&quot;userThreadPool&quot; class=&quot;org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor&quot;&gt; &lt;property name=&quot;corePoolSize&quot; value=&quot;10&quot; /&gt; &lt;property name=&quot;maxPoolSize&quot; value=&quot;100&quot; /&gt; &lt;property name=&quot;queueCapacity&quot; value=&quot;2000&quot; /&gt; &lt;property name=&quot;thradFactory&quot; value= thradFactory /&gt; &lt;property name=&quot;rejectedExecutionHandler&quot;&gt; &lt;ref local=&quot;rejectedExecutionHandler&quot;&gt; &lt;/property&gt;&lt;/bean&gt;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的SPI机制]]></title>
    <url>%2F2018%2F03%2F03%2FJava%E4%B8%AD%E7%9A%84SPI%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[本文对 Java 中的 SPI 机制进行学习。是对以下文章的摘录： 《Java spi机制浅谈》 《Dubbo原理解析-Dubbo内核实现之SPI简单介绍》 《Dubbo源码分析 —- 基于SPI的扩展实现机制》 具体约定当服务的提供者，提供了服务接口的一种实现之后，在 jar 包的 META-INF/services/ 目录里同时创建一个以服务接口命名的文件。该文件里就是实现该服务接口的具体实现类。而当外部程序装配这个模块的时候，就能通过该 jar 包 META-INF/services/ 里的配置文件找到具体的实现类名，并装载实例化，完成模块的注入。 基于这样一个约定就能很好的找到服务接口的实现类，而不需要再代码里制定。JDK 提供服务实现查找的一个工具类：java.util.ServiceLoader 例子1.common-loggingapache最早提供的日志的门面接口。只有接口，没有实现。具体方案由各提供商实现，发现日志提供商是通过扫描 META-INF/services/org.apache.commons.logging.LogFactory 配置文件，通过读取该文件的内容找到日志提工商实现类。只要我们的日志实现里包含了这个文件，并在文件里制定 LogFactory 工厂接口的实现类即可。 2.jdbcjdbc4.0 以前，开发人员还需要基于 Class.forName(&quot;xxx&quot;) 的方式来装载驱动。jdbc4 开始也基于 spi 的机制来发现驱动提供商了，可以通过 META-INF/services/java.sql.Driver 文件里指定实现类的方式来暴露驱动提供者。 3.自己编写简单例子假设有一个内容搜索系统，分为展示和搜索两个模块。展示和搜索基于接口编程。搜索的实现可能是基于文件系统的搜索，也可能是基于数据库的搜索。实例代码如下 以下代码托管在 java-spi-demo。 Search.java : 搜索接口12345678package search;import java.util.List;/** * @author &lt;url&gt;http://singleant.iteye.com/blog/1497259&lt;/url&gt; */public interface Search &#123; List&lt;Object&gt; search(String keyword);&#125; FileSearch.java : 文件系统的搜索实现123456789101112package search;import java.util.List;/** * @author &lt;url&gt;http://singleant.iteye.com/blog/1497259&lt;/url&gt; */public class FileSearch implements Search &#123; @Override public List&lt;Object&gt; search(String keyword) &#123; System.out.println(&quot;now use file system search. keyword:&quot; + keyword); return null; &#125;&#125; DatabaseSearch.java : 数据库的搜索实现123456789101112package search;import java.util.List;/** * @author &lt;url&gt;http://singleant.iteye.com/blog/1497259&lt;/url&gt; */public class DatabaseSearch implements Search &#123; @Override public List&lt;Object&gt; search(String keyword) &#123; System.out.println(&quot;now use database search. keyword:&quot; + keyword); return null; &#125;&#125; SearchTest.java : 测试类123456789101112131415161718package search;import java.util.Iterator;import java.util.ServiceLoader;/** * @author &lt;url&gt;http://singleant.iteye.com/blog/1497259&lt;/url&gt; */public class SearchTest &#123; public static void main(String[] args) &#123; ServiceLoader&lt;Search&gt; s = ServiceLoader.load(Search.class); Iterator&lt;Search&gt; searchIterator = s.iterator(); if (searchIterator.hasNext()) &#123; Search curSearch = searchIterator.next(); curSearch.search(&quot;test&quot;); &#125;else&#123; System.out.println(&quot;请检 META-INF 查文件路径是否正确&quot;); &#125; &#125;&#125; 当 META-INF/services/search.Search 中是 search.DatabaseSearch 输出结果是：now use database search. keyword:test 。 当 META-INF/services/search.Search 中是 search.FileSearch 输出结果是：now use file system search. keyword:test 。 可以看出SearchTest里没有任何和具体实现有关的代码，而是基于spi的机制去查找服务的实现。 4.另一个例子可以查看《Dubbo原理解析-Dubbo内核实现之SPI简单介绍》。 Dubbo 扩展Dubbo 的 SPI 机制是在标准的 jdk 的 SPI 的机制上扩展加强而来的，SPI 的实现在 dubbo 中由以下几个 annotation 来实现。 SPI 注解，，使用 SPI 注解来标识一个扩展点，该注解一般是打在接口上的，dubbo 的扩展点都是基于接口的。 Adaptive 注解 该注解主要作用在方法上，使用该注解可以根据方法的参数值来调用的具体的实现类的对应方法。 Activate 注解，该注解一般作用在实现类上，使用该注解一般是对于 Filter 类型的类，来决定是该类是否加入到 Filter 的执行器责任链中。 ExtensionLoader 是 SPI 机制实现的核心类，该类提供了以下静态方法 getExtensionLoader（Class type），该方法返回了加载此 class 的 ExtensionLoader， 通过该 ExtensionLoader 来创建对应的 type 的类的实例，该类还提供了以下方法来获取对应的加载类的实例 getAdaptiveExtension（String name） public T getExtension(String name) 具体可参考 《Dubbo源码分析 —- 基于SPI的扩展实现机制》。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SPI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Java并发编程实战》笔记]]></title>
    <url>%2F2018%2F03%2F02%2F%E3%80%8AJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%E3%80%8B%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[将之前《Java并发编程实战》笔记 pdf 版本转换为网页博客，方便查看和完善。 简介之所以在计算机中加入操作系统来实现多个程序的同时执行，主要基于以下原因：资源利用率、公平性、便利性。 线程安全性修复线程不安全的三种方式：（1）不在线程之间共享该状态变量。（2）将状态变量修改为不可变的变量。（3）在访问转态变量时使用同步。 什么是线程安全性当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替执行，并且在主调代码中不需要任何额外的同步或协同，这个类都能表现出正确的行为，那么就称这个类是线程安全的。 无状态对象一定是线程安全的。 原子性将“先检查后执行”以及“读取-修改-写入”等操作统称为复合操作：包含了一组必须以原子方式执行的操作以确保线程安全性。 在实际情况中，应尽可能地使用现有的线程安全对象（例如AtomicLong、AtomicReference）来管理类的状态。 加锁机制Java提供了一种内置的锁机制来支持原子性：同步代码块（Synchronized Block）。 Java的内置锁相当于一种互斥体（或互斥锁），这意味着最多只有一个线程能持有这种锁。 由于内置锁是可重入的，因此如果某个线程试图获得一个已经由它自己持有的锁，那么这个请求就会成功。“重入”意味着获取锁的操作粒度是“线程”，而不是“调用”。 当实现某个同步策略时，一定不要盲目地为了性能而牺牲简单性（这个可能破坏安全性）。 对象的共享可见性为了确保多个线程之间对内存写入操作的可见性，必须使用同步机制。 在没有同步的情况下，编译器、处理器以及运行时都可能对操作的执行顺序进行一些意向不到的调整。在缺乏足够同步的多线程程序中，要想对内存操作的执行顺序进行判断，几乎无法得出正确的结论。 当读取一个非volatile类型的long变量时，如果对该变量的读操作和写操作在不同的线程中执行，那么很可能会读取到某个值的高32位和另一个值的低32位。 加锁的含义不仅仅局限于互斥行为，还包括内存可见性。 volatile变量不会被缓存在寄存器或者对其他处理器不可见的地方，因此在读取volatile类型的变量时总会返回最新写入的值。 volatile变量是一种比sychronized关键字更轻量级的同步机制。但不建议过度依赖volatile变量提供的可见性。 volatile变量的正确使用方式包括：确保它们自身状态的可见性，确保它们所引用对象的状态的可见性，以及标识一些重要的程序生命周期事件的发生（例如，初始化或关闭）。 对于服务器应用程序，无论在开发阶段还是在测试阶段，当启动JVM时一定都要指定-server命令行选项。server模式的JVM将比client模式进行更多优化，因此，在开发环境（client模式的JVM）中能正确运行的代码可能会在部署环境（server模式的JVM）中运行失败。 加锁机制既可以确保可见性又可以确保原子性，而volatile变量只能确保可见性。 发布与溢出“发布（Publish）”一个对象的意思是指，使对象能够在当前作用域之外的代码中使用。 当某个不该发布的对象被发布时，这种情况就被称为逸出（Escape）。 线程封闭如果仅在单线程内访问数据，就不需要同步。这种技术被称为线程封闭（Thread Confinement）。 Ad-hoc线程封闭是指，维护线程封闭性的职责完全由程序实现来承担。 栈封闭是线程封闭的一种特例，在栈封闭中，只能通过局部变量才能访问对象。 ThreadLocal提供了get与set等访问接口或方法，这些方法为每个使用该变量的线程都存有一份独立的副本，因此get总是返回由当前执行线程在调用set时设置的最新值。 不变性不可变对象（Immutable Object）一定是线程安全的。 即使对象中所有的域都是final类型的，这个对象也仍然是可变的，因为在final类型的域中可以保存对可变对象的引用。 当满足以下条件时，对象才是不可变的：（1）对象创建以后其状态就不能修改。（2）对象的所有域都是final类型（技术上不一定都要final,如String）。（3）对象是正确创建的（在对象创建期间，this引用没有溢出）。 在Java内存中，final域还有着特殊的语义。Final可以确保初始化过程的安全性。 安全发布要正确的发布一个对象，对象的引用以及对象的状态必须同时对其他线程可见。一个正确构造的对象可以通过以下方式发布：（1）在静态初始化函数中初始化一个对象引用。（2）将对象的引用保存到volatile类型的域或者AtomicReferance对象中。（3）将对象的引用保存到某个正确构造对象的final类型中。（4）将对象的引用保存到一个由锁保护的域中。 如果对象从技术上来看是可变的，但其状态在发布后不会再改变，那么把这种对象称为“事实不可变对象（Effectively Immutable Object）”。 在并发程序中使用和共享对象时，可以使用的一些实用的策略，包括：（1）线程封闭。（2）只读共享。（3）线程安全共享（在对象内部实现同步，外部可以安全访问）。（4）保护对象（通过特定的锁来访问）。 对象的组合设计线程安全的类包含多个变量的不变性条件将带来原子性需求：这些相关的变量必须在单个原子操作中进行读取或更新。 实例封闭一些基本的容器并非线程安全的，例如ArrayList和HashMap，但类库提供了包装器工厂方法（例如Collections.synchronizedList及其类似方法），使得这些线程安全的类在多线程环境中安全地使用。 封闭机制更易于构造线程安全的类，因为当封闭类的状态时，在分析线程安全性时就无须检查整个程序。 线程安全性的委托略 在现有的线程安全类中添加功能重用能降低开发工作量、开发风险（因为现有的类都已经通过测试）以及维护成本。 客户端加锁机制与扩展类机制有许多共同点，二者都是将派生类的行为与基类的合在一起，这会破坏封装性。 当为现有的类添加一个原子操作时，有一种更好的方式：组合（Composition）。 将同步策略文档化在维护线程安全的时，文档是最强大的（同时也是最未被重发利用的）工具之一。 在文档中说明客户代码需要了解的线程安全性保证，以及代码维护人员需要了解的同步策略。 基础构件模块同步容器类如果不想在迭代期间对容器加锁，那么一种替代方法就是“克隆”容器，并在副本上进行迭代。 容器的hashCode和equals等方法也会间接地执行迭代操作，当容器作为另一个容器的元素或键值时，就会出现这种情况。所有这些间接地迭代操作都可能抛出ConcurrentModificationException。 并发容器通过并发容器来代替同步容器，可以极大地提高伸缩性并降低风险。 虽然可以用List来模拟Queue的行为，但还需要一个Queue的类，因为它能去掉List的随机访问需求，从而实现了更高效的并发。 ConcurrentHashMap使用了一种粒度更细的加锁机制来实现更大程度的共享，这种机制称为分段锁（Lock Striping）。 ConcurrentHashMap中，由于size返回的结果在计算时已经过期了吗，所以size返回的值可能是一个近似值而不是精确值。 “写入时复制（Copy-On-Write）”容器的线程安全性在于，只要正确地发布一个事实不可变对象，那么在访问该对象时就不再需要进一步的同步。仅当迭代操作远远多于修改操作时，才应该使用“写入时复制”容器。这个准则很适合事件通知系统（注册监听器）。 阻塞队列和生产者 - 消费者模式阻塞队列提供了可阻塞的put和take方法，以及支持定时的offer和poll方法。无界队列永远都不会充满，所以无界队列的put方法也永远不会阻塞。 在构建高可靠的应用程序时，有界队列是一种强大的资源管理工具：它们能抑制并防止产生过多的工作项，使应用程序在负荷过载的情况下变得更加健壮。 应该尽早地通过阻塞队列在设计中构建资源管理机制——这件事情做得越早，就越容易。 BlockingQueue的多种实现：（1）LinkedBlockingQueue和ArrayBlockingQueue是FIFO队列。（2）PriorityBlockingQueue是一种按优先级排序的队列。（3）SynchronousQueue维护一组线程，可以直接交付工作。 双端队列适用于工作密取（Work Stealing）模式。 阻塞方法与中断方法线程可能会阻塞或暂停执行，原因有多种：（1）等待I/O操作结束；（2）等待获得一个锁；（3）等待重Thread.sleep方法中醒来；（4）等待另一个线程的计算结果。 同步工具类闭锁是一种同步工具类，可以延迟线程的进度直到其到达终止状态。闭锁可以确保某些活动直到其他活动都完成后才继续执行。 CountDownLatch是一种灵活的闭锁实现，它可以使一个或多个线程等待一组事件发生。 FutureTask也可以用做闭锁。（FutureTask实现了Future语义，表示一种抽象的可生成结果的计算）。 计数信号量（Counting Semaphore）用来控制同时访问某个特定资源的操作数量，或者同时执行某个指定操作的数量。计数信号量还可以用来实现某种资源池，或者对容器施加边界。 栅栏（Barrier）类似于闭锁，它能阻塞一组线程直到某个事件的发生。栅栏与闭锁的关键区别在于，所有线程必须同时到达栅栏位置，才能继续执行。 CyclicBarrier可以使一定数量的参与方反复地在栅栏位置汇集，它在并行迭代算法中非常有用：这种算法通常将一个问题拆分成一系列相互独立的子问题。 Exchanger是一种两方（Two-Party）栅栏，各方在栅栏位置上交换数据。 构建高效且可伸缩的结果缓存略 第一部分小结（1）可变状态时至关重要的（It’s the mutable state,stupid）。（2）尽量将域声明为final类型，除非需要它们是可变的。（3）不可变对象一定是线程安全的。（4）封装有助于管理复杂性。（5）用来保护每个可变变量。（6）当保护同一个不变性条件中的所有变量时，要使用同一个锁。（7）在执行复合操作期间，要持有锁。（8）如果从多个线程中访问同一个可变变量时没有同步机制，那么程序会出问题。（9）不要故作聪明地推断出不需要使用同步的地方。（10）在设计过程中考虑线程安全，或者在文档中明确地指出它不是线程安全的。（11）将通办不成策略文档化。 任务执行TODO]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Java</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深入理解Java虚拟机》笔记]]></title>
    <url>%2F2018%2F03%2F02%2F%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[将之前《深入理解Java虚拟机》笔记 pdf 版本转换为网页博客，方便查看和完善。 走近JavaJDK与JRE把Java程序设计语言、Java虚拟机、Java API类库称为JDK（Java Development Kit）, JDK是用于支持Java程序开发的最小环境。 把Java API类库中的Java SE API子集和Java虚拟机称为JRE（Java Runtime Environment）,JRE是支持Java程序运行的标准环境。 图片来自 http://docs.oracle.com/javase/8/docs/ Java 虚拟机Sun JDK 和 OpenJDK 中所带的虚拟机是 HotSpot VM。可以参考的文档：http://docs.oracle.com/javase/8/docs/technotes/guides/vm/ Java技术展望模块化（提到OSGI）、混合语言、多核并行（希望利用GPU、APU等）。 Java内存区域与内存溢出异常概述Java 虚拟机内存自动管理利弊： 优点：不需要为每一个new操作去写配对的delete/free代码，不容易出现内存泄漏和内存溢出问题。 缺点：出现内存泄漏和溢出问题时，如果不了解虚拟机怎样使用内存，排查会比较艰难。 运行时数据区域 程序计数器程序计数器（Program Counter Register）可以看成当前线程所执行的字节码的行号指示器。各个线程的程序计数器是相互独立的互不影响。 如果执行的是Java方法，计数器记录字节码指令地址；如果执行的是Native方法，计数器值为空（Undefined）。 程序计数器区域虚拟机规范中是唯一一个没有规定任何OutOfMemoryError情况的区域。 Java虚拟机栈Java虚拟机栈（Java Virtual Machine Stacks）是线程私有的，描述的是Java方法执行的内存模型：每个方法在执行同时会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。 如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展（大部分虚拟都可以）并且扩展时无法申请到足够内存，就会抛出OutOfMemoryError异常。 Java堆Java堆（Java Heap）是被所有线程共享的一块内存区域，也是供所有类实例和数组对象分配内存的区域。 Java堆的容量可以是固定大小的，也可以随着程序执行的需求动态扩展，并在不需要过多空间时自动收缩。Java堆所使用的内存不需要保证是连续的。 如果实际所需的堆超过了自动内存管理系统能提供的最大容量，那Java虚拟机将会抛出一个OutOfMemoryError异常。 Java 控制堆和非堆参数例子：123456-vmargs -Xms128M -Xmx512M -XX:PermSize=64M -XX:MaxPermSize=128M-vmargs 说明后面是VM的参数，所以后面的其实都是JVM的参数了-Xms128m JVM初始分配的堆内存-Xmx512m JVM最大允许分配的堆内存，按需分配-XX:PermSize=64M JVM初始分配的非堆内存-XX:MaxPermSize=128M JVM最大允许分配的非堆内存，按需分配 方法区方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译后的代码等数据。方法区别名叫做Non-Heap（非堆）。 在HotSpot虚拟机上，很多人把方法区成为“永久代”（Permanent Generation）是因为HotSpot把GC分代收集扩展至方法区，用永久代实现方法区。这样做的好处是节省工作量，坏处是受到-XX:MaxPermSize的限制，更容易遇到内存溢出问题。 运行时常量池（Runtime Constant Pool）是方法区的一部分。 如果方法区的内存空间不能满足内存分配请求，那Java虚拟机将抛出一个OutOfMemoryError异常。 本地方法栈Java虚拟机实现可能会使用到传统的栈（通常称之为“C Stacks”）来支持native方法（指使用Java以外的其他语言编写的方法）的执行，这个栈就是本地方法栈（Native Method Stack）。当Java虚拟机使用其他语言（例如C语言）来实现指令集解释器时，也会使用到本地方法栈。 如果线程请求分配的栈容量超过本地方法栈允许的最大容量时，Java虚拟机将会抛出一个StackOverflowError异常。 如果本地方法栈可以动态扩展，并且扩展的动作已经尝试过，但是目前无法申请到足够的内存去完成扩展，或者在建立新的线程时没有足够的内存去创建对应的本地方法栈，那Java虚拟机将会抛出一个OutOfMemoryError异常。 该书提到直接内存（Direct Memory）,JDK1.4中加入的NIO（New Input/Output）引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，可以使用Native函数直接分配堆外内存，然后通过Java堆中DirectByteBuffer对象作为这块内存的引用进行操作。 HotSpot虚拟机对象探秘对象的创建虚拟机遇到一条new指令时： 检查这个指令的参数是否能在常量池中定位到一个类符号的引用。 检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有必须先执行相应的类加载过程。 虚拟机为新生对象分配内存。分配算法取决于垃圾收集器是否带有压缩整理功能。如果带有压缩整理功能（如Serial、ParNew等），Java堆规整，采用“指针碰撞”（Bump the Pointer）,否则（如 CMS）Java堆不规整,采用“空闲链表”Free List。 将分配到的内存空间都初始化为零值（不包括对象头）。 对对象头进行必要的设置（那个类的实例、如何找到类的元数据信息、对象的哈希吗、对象的GC分代年龄等）。 调用对象的方法。 对象的内存布局在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。 对象头：存储对象自身的运行时数据：Mark Word（在32bit和64bit虚拟机上长度分别为32bit和64bit），包含如下信息： 对象HashCode 对象GC分代年龄 锁状态标志（轻量级锁、重量级锁） 线程持有的锁（轻量级锁、重量级锁） 偏向锁相关：偏向锁、自旋锁、轻量级锁以及其他的一些锁优化策略是JDK1.加入的，这些优化使得Synchronized的性能与ReentrantLock的性能持平，在Synchronized可以满足要求的情况下，优先使用Synchronized，除非是使用一些ReentrantLock独有的功能，例如指定时间等待等。 类型指针：对象指向类元数据的指针（32bit–&gt;32bit，64bit–&gt;64bit(未开启压缩指针)，32bit(开启压缩指针)）。JVM通过这个指针来确定这个对象是哪个类的实例（根据对象确定其Class的指针）实例数据：对象真正存储的有效信息。对齐填充：HotSpot VM要求对象的大小必须是8的整数倍，若不是，需要补位对齐。 对象的访问定位对象的访问方式有使用句柄和直接指针两种。 如果使用句柄访问的话，那么Java堆中将会划分出一块区域作为句柄池，reference中存的就是句柄地址。句柄中包含了实例数据和类型数据各自的地址。 如果使用直接指针访问的的话，reference中存的直接就是对象地址，对象中放置类型数据的相关信息。 使用句柄的好处：对象被移动时只需改变句柄中地址，reference本身不需要改变。使用直接指针访问的好处：速度更快，节省了一次指针定位的时间开销。 实战：OutOfMemoryError异常除了程序计数器外，虚拟机内存的其他几个运行时区域都有发生OutOfMemoryError（简称OOM）异常的可能。 Java堆溢出产生例子：不断创建对象，并保证GC Roots到对象之间有可达路径。 解决思路：利用工具对Dump出来的堆转储快照进行分析，重点确认内存中的对象是否必要，也就是要分清是出现内存泄漏（Memory Leak）还是内存溢出（Memory Overflow）。如果是内存泄漏，就使用工具查看泄漏对象到GC Roots的引用链，确定泄漏代码位置；如果是内存溢出则检查虚拟机的堆参数（-Xmx与-Xms)。 虚拟机栈和本地方法栈溢出在HotSpot虚拟机中并不区分虚拟机栈和本地方法栈，栈容量只由-Xss参数设定，虽然-Xoss（设置本地方法栈大小）参数存在，但实际上是无效的。 实验结果表明：单个线程下，无论由于栈帧太大还是虚拟机容量太小，当内存无法分配时候，虚拟机抛出的都是StackOverflowError异常。 当持续创建线程时，会产生OOM异常。因为线程栈空间 ≈ 总内存（操作系统内存）-Xmx（最大堆容量）-MaxPermSize（最大方法区容量），所以可以通过减少“内存”（Xmx、MaxPermSize）来解决多线程创建造成的OOM异常。 方法区和运行时常量池溢出JDK1.7之后String.intern()方法不再复制实例到到永久代中，只是在常量池中记录首次出现的实例引用。所以通过String.intern()持续创建不会造成常量池OOM。 方法区用于存放Class的相关信息，如类名、访问修饰符、字段描述、方法描述等。基本思路是运行时产生大量的类去填满方法区，直到溢出。 可能出现溢出的场景：Spring、Hibernate使用CGLib对类进行增强、大量JSP或动态产生JSP文件的应用（JSP第一次运行时需要编译为Java类）、基于OSGI的应用（即使是同一个类文件，被不同的类加载器加载也会视为不同的类）等。 本机直接内存溢出DirectMemory容量可以通过-XX:MaxDirectMemorySize指定，如果不指定，则默认与Java堆最大值（-Xmx指定）一样。 由DirectMemory导致的内存溢出，一个明显的特征是在Heap Dump文件中不会看见明显的异常，如果发现OOM之后Dump文件很小，而程序中又直接或间接使用了NIO，那就可以考虑检查一下是不是这方面的原因。 垃圾收集器与内存分配策略概述GC关注三件事：哪些内存需要回收？什么时候回收？如何回收？ 了解GC和内存分配的意义：当需要排查内存溢出、内存泄漏问题时，当垃圾收集成为系统达到更高并发量的瓶颈时，就需要对这些“自动化”的技术实施必要的监控和调节。 “内存分配和回收”中讨论的内存指的是“Java堆和方法区”，因为程序计数器、Java虚拟机栈、本地方法栈这三个区域的内存分配和回收具备确定性。 对象已死吗引用计数法引用计数法（Reference Counting）：给对象添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器值为0的对象不可能再被使用。 优点：实现简单，判断效率也很高。 缺点：很难解决对象之间相互循环引用的问题。 可达性分析算法可达性分析（Reachability Analysis）:通过一系列称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索走过的路径称为引用链（Reference Chain）,从GC Roots到某个对象不可达时，则这个对象是不可用的。 在Java语言中可以作为GC Roots的对象包括以下几种： 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI（即一般说的Native方法）引用的对象。 再谈引用希望能描述这样一类对象：当内存空间还足够的时候，则能保留在内存之中；如果内存空间在进行GC后还是很紧张，则可以抛弃这些对象。很多系统的缓存功能都符合这样的场景。 JDK1.2之后，Java对引用的概念进行了扩充。 引用类型 实现 存在时间 强引用 Object obj = new Object() 只要引用还存在就存在 软引用 SoftReferencev 直到将要发生OOM时 弱引用 WeakReference 下一次GC之前 虚引用 PhantomReference 对对象毫无影响，只是为了在对象回收时受到一个通知 生存还是死亡要宣告一个对象的死亡，至少要经历两次标记过程。 第一次标记：如果从GC Roots不可达，则进行第一次标记并进行筛选，筛选的条件是此对象是否有必要执行finalize()方法，当对象没有覆盖finalize()或者已经被调用过，则没有必要再执行该方法。 第二次标记：需要执行finalize()方法的对象会被放入F-Queue中，但是不承诺会全部执行.在执行finalize()中，可以通过重新与引用链上的任何对象建立关系，从而逃脱“死亡”。稍后，GC会对F-Queue中的对象进行第二次小规模标记。 回收方法区方法区（或者Hotspot虚拟机中的永久代）主要回收两个部分的内容：废弃常量和无用的类。Java虚拟机规范说过可以不要求虚拟机在方法区实现垃圾收集，而且在方法区中进行垃圾收集的“性价比”一般比较低。 在大量使用反射、动态代理、GCLib等ByteCode框架、动态生成JSP以及OSGi这类频繁自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。 垃圾收集算法介绍几种垃圾收集算法。 算法名称 算法过程 算法说明 标记-清除（Mark-Sweep） 分为“标记”和“清除”两阶段：1. 标记出需要回收的的对象。2. 在标记完成后统一回收。 效率问题：标记和清除两个过程效率都不高。空间问题：标记清除后会产生大量不连续的内存碎片。 复制（Copying） 将可用内存按容量划分为大小相等的两块，每次只使用其中一块。 将内存缩小为原来的一般，代价太高。 标记-整理(Mark-Compact) 1. 标记出需要回收的的对象。2. 在标记完成后将存活的对象都向一端移动，然后直接清理掉边界以外的内存。 由于年老代中对象存活率较高，所以在年老代中采用这种算法。 分代收集 (Generational Collection) 把Java堆分为新生代和老年代。新生代使用“复制”算法，年老代使用“标记-清理”或者“标记-整理”算法。 现代商业虚拟机采用复制算法来回收新生代。将内存划分为一块较大的Eden空间和两块较小的Survivor空间。当回收时，将Eden和Survivor中存活的对象一次地复制到另一块Survivor上，最后清理掉Eden和刚才用过的Survivor空间。HotSpot中Eden和Survivor的比例是8:1。当Survivor空间不够用时需要依赖其他内存（这里指年老代）进行分配担保（Handle Promotion），直接进入年老代。 HotSpot的算法实现枚举根节点为了确保准确性，GC进行时需要停顿所有Java执行线程（Sun 将这件事情称为 “Stop The World”）。 虚拟机有办法得知哪些地方存着对象引用，在HotSpot的实现中，使用的是一组称为OopMap的数据结构。 安全点HotSpot没有为每条指令都生成OopMap，只是在“特定的位置”记录了这些信息，这些位置称为安全点（Safepoint）,即程序执行时只有在到达安全点时才能暂停，进行GC。 安全区域安全区域（Safe Region）可以看做是被扩展了的Safepoint。 垃圾收集器From: http://blog.csdn.net/chjttony/article/details/7883748 图中如果两个垃圾收集器直接有连线，则表明这两个垃圾收集器可以搭配使用。 Serial垃圾收集器Serial是一个单线程的收集器，它不仅仅只会使用一个CPU或一条线程去完成垃圾收集工作，并且在进行垃圾收集的同时，必须暂停其他所有的工作线程，直到垃圾收集结束。 Serial垃圾收集器虽然在收集垃圾过程中需要暂停所有其他的工作线程，但是它简单高效，对于限定单个CPU环境来说，没有线程交互的开销，可以获得最高的单线程垃圾收集效率，因此Serial垃圾收集器依然是java虚拟机运行在Client模式下默认的新生代垃圾收集器。 ParNew垃圾收集器ParNew垃圾收集器其实是Serial收集器的多线程版本，也使用复制算法，除了使用多线程进行垃圾收集之外，其余的行为和Serial收集器完全一样，ParNew垃圾收集器在垃圾收集过程中同样也要暂停所有其他的工作线程。 ParNew虽然是除了多线程外和Serial收集器几乎完全一样，但是ParNew垃圾收集器是很多java虚拟机运行在Server模式下新生代的默认垃圾收集器。 Parallel Scavenge收集器Parallel Scavenge收集器也是一个新生代垃圾收集器，同样使用复制算法，也是一个多线程的垃圾收集器，它重点关注的是程序达到一个可控制的吞吐量（Thoughput，CPU用于运行用户代码的时间/CPU总消耗时间，即吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间)），高吞吐量可以最高效率地利用CPU时间，尽快地完成程序的运算任务，主要适用于在后台运算而不需要太多交互的任务。 Parallel Scavenge是吞吐量优先的垃圾收集器，它还提供一个参数：-XX:+UseAdaptiveSizePolicy，这是个开关参数，打开之后就不需要手动指定新生代大小(-Xmn)、Eden与Survivor区的比例(-XX:SurvivorRation)、新生代晋升年老代对象年龄(-XX:PretenureSizeThreshold)等细节参数，虚拟机会根据当前系统运行情况收集性能监控信息，动态调整这些参数以达到最大吞吐量，这种方式称为GC自适应调节策略，自适应调节策略也是ParallelScavenge收集器与ParNew收集器的一个重要区别。 Serial Old收集器Serial Old是Serial垃圾收集器年老代版本，它同样是个单线程的收集器，使用标记-整理算法，这个收集器也主要是运行在Client默认的java虚拟机默认的年老代垃圾收集器。 在Server模式下，主要有两个用途： 在JDK1.5之前版本中与新生代的Parallel Scavenge收集器搭配使用。 作为年老代中使用CMS收集器的后备垃圾收集方案。 Parallel Old收集器Parallel Old收集器是Parallel Scavenge的年老代版本，使用多线程的标记-整理算法，在JDK1.6才开始提供。 在JDK1.6之前，新生代使用ParallelScavenge收集器只能搭配年老代的Serial Old收集器，只能保证新生代的吞吐量优先，无法保证整体的吞吐量，Parallel Old正是为了在年老代同样提供吞吐量优先的垃圾收集器，如果系统对吞吐量要求比较高，可以优先考虑新生代Parallel Scavenge和年老代Parallel Old收集器的搭配策略。 CMS收集器Concurrent mark sweep(CMS)收集器是一种年老代垃圾收集器，其最主要目标是获取最短垃圾回收停顿时间，和其他年老代使用标记-整理算法不同，它使用多线程的标记-清除算法。 最短的垃圾收集停顿时间可以为交互比较高的程序提高用户体验，CMS收集器是Sun HotSpot虚拟机中第一款真正意义上并发垃圾收集器，它第一次实现了让垃圾收集线程和用户线程同时工作。 G1收集器Garbage first垃圾收集器是目前垃圾收集器理论发展的最前沿成果，相比与CMS收集器，G1收集器两个最突出的改进是： 基于标记-整理算法，不产生内存碎片。 可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收。 G1收集器避免全区域垃圾收集，它把堆内存划分为大小固定的几个独立区域，并且跟踪这些区域的垃圾收集进度，同时在后台维护一个优先级列表，每次根据所允许的收集时间，优先回收垃圾最多的区域。 区域划分和优先级区域回收机制，确保G1收集器可以在有限时间获得最高的垃圾收集效率。 内存分配与回收策略对象优先在Eden分配大多数情况下，对象在新生代Eden分配。当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC。 触发JVM进行Full GC的情况及应对策略：http://blog.csdn.net/chenleixing/article/details/46706039 大对象直接进入年老代虚拟机提供了一个-XX:PretenureSizeThreshold参数，令大于这个设置值的对象直接在老年代分配。注意：这个参数只对Serial和ParNew两款收集器有效，Parallel Scavenge 收集器不认识这个参数。 长期存活的对象将进入老年代略 动态对象年龄判定略 空间分配担保略 虚拟机性能监控与故障处理工具概述研究数据包括：运行日志、异常堆栈、GC日志、线程快照（threaddump / javacore文件）、堆转储快照（heapdump / hprof文件）等。 JDK命令行工具JDK中的工具大多是jdk/lib/tools.jar类库的一层薄包装而已。借助tools.jar我们可以直接在应用程序中实现功能强大的监控分析功能，但tools.jar不是Java标准的API，如果引入这个类库，程序就只能运行与Sun Hotspot上面。 名称 主要作用 jps JVM Process Status Tool，显示指定系统内所有的HotSpot虚拟机进程。 jstat JVM Statistics Monitoring Tool，用于收集HotSpot虚拟机各方面的运行数据。 jinfo Configuration Info for Java，显示虚拟机配置信息。 jmap Memory Map for Java，生成虚拟机的内存转储快照（heapdump 文件）。 jhat JVM Heap Dump Browser，用于分析heapdump文件，它会建立一个HTTP/HTML服务器，让用户可以在浏览器上查看分析结果。 jstack Stack Trace for Java，显示虚拟机的线程快照。 JDK的可视化工具JConsole：Java监视与管理控制台JConsole可以检测到对应线程的死锁。 VisualVM：多合一故障处理工具除了JConsole中的一些基本功能外，VisualVM还可以下载插件、生成和浏览堆转储快照、分析程序性能、BTrace动态日志跟踪。 调优案例分析与实战略 类文件结构字节码（ByteCode）是构成平台无关性的基石。此外，虚拟机的另一种中立特性——语言无关性正越来越被开发者所重视。整个Class文件本质上就是一张表。 虚拟机类加载机制概述虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。 类加载的时机类的生命周期如下图所示。 虚拟机规范严格规定了有且只有5种情况必须立即对类进行“初始化”（而加载、验证、准备自然要在此之前开始）：1）使用new实例化对象、读取一个类的静态字段（被final修饰、已在编译期把结果放入常量次的静态字段除外）、调用一个类的静态方法的时候。2）反射调用的时候。3）初始化类点的时候，父类未初始化的要初始化。4）虚拟机启动时要初始化主类。5）使用JDK1.7的动态语言支持时。 类加载的过程加载在加载阶段，虚拟机需要完成以下3件事情：1）通过一个类的全称限定名来获取定义此类的二进制字节流。2）将这个字节流所代表的静态存储结构转换为方法区的运行时数据结构。3）在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。 验证验证大致会完成下面4个阶段的检验动作：1）文件格式验证：验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理。2）元数据验证：对字节码描述的信息进行语义分析，以保证其描述的信息符合Java语言规范的要求。3）字节码的验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。4）符号引用校验：发生在将符号引用转换为直接引用的时候，这个转化动作将在连接的第三阶段——解析阶段中发生。 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。注意：这里是类变量（static修饰的变量），而且初始值“通畅情况下”（非final）是0值，因为复制代码还没有编译。 解析将常量池内的符号引用替换为直接引用的过程。 初始化初始化阶段是执行类构造器 &lt;clinit&gt;() 方法的过程。&lt;clinit&gt;() 方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{} 块）中的语句合并产生的。 类加载器加载器在类层次划分、OSGi、热部署、代码加密等领域大放异彩。 下图展示的类加载器之间的这种层次关系，称为双亲委派模型。双亲委派模型要求除了顶层的启动类加载器外，其余的类加载器都应当有自己的父类加载器（一般是组合而不是继承关系）。 虚拟机字节码执行引擎概述执行引擎在执行Java代码的时候可能会有解释执行（通过解释器执行）和编译执行（通过即时逼哪一期产生本地代码执行）两种选择。 运行时栈帧结构略 类加载及执行子系统的案例与实战略 早期（编译期）优化略 晚期（运行期）优化略 Java内存模型与线程略 线程安全与锁优化略]]></content>
      <categories>
        <category>Java虚拟机</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Java</tag>
        <tag>Java虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Netty-in-Action》笔记目录]]></title>
    <url>%2F2018%2F03%2F01%2F%E3%80%8ANetty-in-Action%E3%80%8B%E7%AC%94%E8%AE%B0%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[对之前摘录的一个目录。 01 Netty — 异步和事件驱动 Java 中的网络使用 介绍 Netty Netty 的核心组件 02 你的第一个Netty应用 建立开发环境 写一个回写应用的服务器和客户端 构建和测试程序 03 Netty的组件和设计 Netty 技术和架构方面的介绍 Channel、EventLoop 和 ChannelFuture ChannelHandler 和 ChannelPipeline 启动（ Bootstrapping） 04 传输 OIO：阻塞传输 NIO：异步传输 本地传输：和 JVM 异步交互 测试你的 ChannelHandler 05 ByteBuf ByteBuf：Netty 的数据容器 API 细节 用例 内存分配 06 ChannelHandler and ChannelPipelineThis chapter covers The ChannelHandler and ChannelPipeline APIs Detecting resource leaks Exception handling 07 EventLoop and threading modelThis chapter covers Threading model overview Event loop concept and implementation Task scheduling Implementation details 08 BootstrappingThis chapter covers Bootstrapping clients and servers Bootstrapping clients from within a Channel Adding ChannelHandlers Using ChannelOptions and attributes 09 Unit testingThis chapter covers Unit testing Overview of EmbeddedChannel Testing ChannelHandlers with EmbeddedChannel 10 The codec frameworkThis chapter covers An overview of decoders, encoders and codecs Netty’s codec classes 11 Provided ChannelHandlers and codecsThis chapter covers Securing Netty applications with SSL/TLS Building Netty HTTP/HTTPS applications Handling idle connections and timeouts Decoding delimited and length-based protocols Writing big data 12 WebSocketThis chapter covers The concept of a real-time web The WebSocket protocol Building a WebSocket-based chat room server with Netty 13 Broadcasting events with UDPThis chapter covers An overview of UDP A sample broadcasting application]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Netty</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Netty-in-Action》笔记（13）]]></title>
    <url>%2F2018%2F02%2F22%2F%E3%80%8ANetty-in-Action%E3%80%8B%E7%AC%94%E8%AE%B0%EF%BC%8813%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Broadcasting events with UDPThis chapter covers An overview of UDP A sample broadcasting application UDP basicsUDP is much faster than TCP: all overhead of handshaking and message management has been eliminated. Clearly, UDP is a good fit for applications that can handle or tolerate lost messages, unlike those that handle financial transactions UDP broadcastAll of our examples so far have utilized a transmission mode called unicast, defined as the sending of messages to a single network destination identified by a unique address. UDP provides additional transmission modes for sending a message to multiple recipients: Multicast — Transmission to a defined group of hosts Broadcast — Transmission to all of the hosts on a network (or a subnet) The UDP sample application PUBLISH/SUBSCRIBEApplications like syslog are typically classified as publish/subscribe: a producer or service publishes the events, and multiple clients subscribe to receive them. Figure 13.1 presents a high-level view of the overall system, which consists of a broadcaster and one or more event monitors. The message POJO: LogEventListing 13.1 shows the details of this the POJO LogEvent. Writing the broadcasterThe primary ones we’ll be using are the message containers and Channel types listed in the following table. Figure 13.2 shows the broadcasting of three log entries, each one via a dedicated DatagramPacket. Figure 13.3 represents a high-level view of the ChannelPipeline of the LogEventBroadcaster, showing how LogEvents flow through it. The next listing shows our customized version of MessageToMessageEncoder, which performs the conversion just described. netcat is perfect for basic testing of this application; it just listens on a specified port and prints all data received to standard output. Set it to listen for UDP data on port 9999 as follows:1$ nc -l -u 9999 Writing the monitorThis program will Receive UDP DatagramPackets broadcast by the LogEventBroadcaster Decode them to LogEvent messages Write the LogEvent messages to System.out Figure 13.4 depicts the ChannelPipeline of the LogEventMonitor and shows how LogEvents will flow through it. The following listing shows LogEventDecoder. The following listing shows LogEventHandler. The following listing shows LogEventMonitor.]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Netty</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Netty-in-Action》笔记（12）]]></title>
    <url>%2F2018%2F02%2F22%2F%E3%80%8ANetty-in-Action%E3%80%8B%E7%AC%94%E8%AE%B0%EF%BC%8812%EF%BC%89%2F</url>
    <content type="text"><![CDATA[WebSocketThis chapter covers The concept of a real-time web The WebSocket protocol Building a WebSocket-based chat room server with Netty So for now we’ll accept the following non-authoritative description from Wikipedia as adequate: The real-time web is a network web using technologies and practices that enable users to receive information as soon as it is published by its authors, rather than requiring that they or their software check a source periodically for updates. Introducing WebSocketThe WebSocket protocol was designed from the ground up to provide a practical solution to the problem of bidirectional data transmission on the web, allowing client and server to transmit messages at any time and, consequently, requiring them to handle message receipt asynchronously. Our example WebSocket applicationFigure 12.1 illustrates the application logic:1 A client sends a message.2 The message is broadcast to all other connected clients. Adding WebSocket supportA mechanism known as the upgrade handshake is used to switch from standard HTTP or HTTPS protocol to WebSocket. Figure 12.2 illustrates the server logic, which, as always in Netty, will be implemented by a set of ChannelHandlers. Handling HTTP requestsThe following list shows the code for HttpRequestHandler, which extends SimpleChannelInboundHandler for FullHttpRequest messages. Notice how the implementation of channelRead0() forwards any requests for the URI /ws. This represents the first part of the chat server, which manages pure HTTP requests and responses. Next we’ll handle the WebSocket frames, which transmit the actual chat messages. WEBSOCKET FRAMESWebSockets transmit data in frames, each of which represents a part of a message. A complete message may consist of many frames. Handling WebSocket framesThe WebSocket RFC, published by the IETF, defines six frames; Netty provides a POJO implementation for each of them. The following table lists the frame types and describes their use. Our chat application will use the following frame types: CloseWebSocketFrame PingWebSocketFrame PongWebSocketFrame TextWebSocketFrame TextWebSocketFrame is the only one we actually need to handle. In conformity with the WebSocket RFC, Netty provides a WebSocketServerProtocolHandler to manage the others. The following listing shows our ChannelInboundHandler for TextWebSocketFrames, which will also track all the active WebSocket connections in its ChannelGroup. Initializing the ChannelPipelineThe following listing shows the code for the resulting ChatServerInitializer. The call to initChannel() sets up the ChannelPipeline of the newly registered Channel by installing all the required ChannelHandlers. These are summarized in the following table, along with their individual responsibilities. The state of the pipeline before the upgrade is illustrated in figure 12.3. Figure 12.4 shows the ChannelPipeline after these operations have completed. BootstrappingThe final piece of the picture is the code that bootstraps the server and installs the ChatServerInitializer. This will be handled by the ChatServer class. Testing the applicationWe’ll use the following Maven command to build and start the server:1mvn -PChatServer clean package exec:exec To use a different port, you can either edit the value in the file or override it with a System property:1mvn -PChatServer -Dport=1111 clean package exec:exec Figure 12.5 shows the UI in the Chrome browser. The figure shows two connected clients. The first is connected using the interface at the top. The second client is connected via the Chrome browser’s command line at the bottom. You’ll notice that there are messages sent from both clients, and each message is displayed to both. What about encryption?The following listing shows how this can be done by extending our ChatServerInitializer to create a SecureChatServerInitializer. The final step is to adapt the ChatServer to use the SecureChatServerInitializer so as to install the SslHandler in the pipeline. This gives us the SecureChatServer shown here.]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Netty</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Netty-in-Action》笔记（11）]]></title>
    <url>%2F2018%2F02%2F19%2F%E3%80%8ANetty-in-Action%E3%80%8B%E7%AC%94%E8%AE%B0%EF%BC%8811%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Provided ChannelHandlers and codecsThis chapter covers Securing Netty applications with SSL/TLS Building Netty HTTP/HTTPS applications Handling idle connections and timeouts Decoding delimited and length-based protocols Writing big data Securing Netty applications with SSL/TLSTo support SSL/TLS, Java provides the package javax.net.ssl, whose classes SSLContext and SSLEngine make it quite straightforward to implement decryption and encryption. Netty leverages this API by way of a ChannelHandler implementation named SslHandler, which employs an SSLEngine internally to do the actual work. Netty’s OpenSSL/SSLEngine implementationNetty also provides an SSLEngine implementation that uses the OpenSSL toolkit(www.openssl.org). This class, OpenSslEngine, offers better performance than the SSLEngine implementation supplied by the JDK. Netty applications (clients and servers) can be configured to use OpenSslEngine by default if the OpenSSL libraries are available. If not, Netty will fall back to the JDK implementation. For detailed instructions on configuring OpenSSL support, please see the Netty documentation at http://netty.io/wiki/forked-tomcat-native.html#wikih2-1. Note that the SSL API and data flow are identical whether you use the JDK’s SSLEngine or Netty’s OpenSslEngine. Figure 11.1 shows data flow using SslHandler. Listing 11.1 shows how an SslHandler is added to a ChannelPipeline using a ChannelInitializer. The SslHandler has some useful methods, as shown in the following table. Building Netty HTTP/HTTPS applicationsHTTP decoder, encoder, and codecFigures 11.2 shows the methods for HTTP requests . Figures 11.3 shows the methods for HTTP responses. The following table gives an overview of the HTTP decoders and encoders that handle and produce these messages. All types of HTTP messages (FullHttpRequest, LastHttpContent, and those shown in the above list) implement the HttpObject interface. The class HttpPipelineInitializer in the next listing shows how simple it is to add HTTP support to your application. HTTP message aggregationNetty provides an aggregator that merges message parts into FullHttpRequest and FullHttpResponse messages. This way you always see the full message contents. The following list shows how this is done. HTTP compressionNetty provides ChannelHandler implementations for compression and decompression that support both gzip and deflate encodings. HTTP request headerThe client can indicate supported encryption modes by supplying the followingheader:123GET /encrypted-area HTTP/1.1Host: www.example.comAccept-Encoding: gzip, deflate Note, however, that the server isn’t obliged to compress the data it sends. An example is shown in the following listing. Compression and dependenciesIf you’re using JDK 6 or earlier, you’ll need to add JZlib (www.jcraft.com/jzlib/) to the CLASSPATH to support compression. For Maven, add the following dependency:12345&lt;dependency&gt;&lt;groupId&gt;com.jcraft&lt;/groupId&gt;&lt;artifactId&gt;jzlib&lt;/artifactId&gt;&lt;version&gt;1.1.3&lt;/version&gt;&lt;/dependency&gt; Using HTTPSThe following listing shows that enabling HTTPS is only a matter of adding an SslHandler to the mix. WebSocketWebSockets provide a true bidirectional exchange of data between client and server. Figure 11.4 gives a general idea of the WebSocket protocol. In this scenario the communication starts as plain HTTP and upgrades to bidirectional WebSocket. As shown in the following table, WebSocketFrames can be classed as data or control frames. Secure WebSocketTo add security to WebSocket, simply insert the SslHandler as the first ChannelHandler in the pipeline. Idle connections and timeoutsDetecting idle connections and timeouts is essential to freeing resources in a timely manner. This is such a common task that Netty provides several ChannelHandler implementations just for this purpose. The following table shows these. Let’s take a closer look at IdleStateHandler, the one most used in practice. The following list shows this. Decoding delimited and length-based protocolsDelimited protocolsThe decoders listed in the following table will help you to define custom decoders that can extract frames delimited by any sequence of tokens. Figure 11.5 shows how frames are handled when delimited by the end-of-line sequence \r\n (carriage return + line feed). The following listing shows how you can use LineBasedFrameDecoder to handle the case shown in figure 11.5. Length-based protocolsThe following table lists the two decoders Netty provides for handling length-based protocols. Figure 11.6 shows the operation of a FixedLengthFrameDecoder that has been constructed with a frame length of 8 bytes. LengthFieldBasedFrameDecoder determines the frame length from the header field and extracts the specified number of bytes from the data stream. Figure 11.7 shows an example where the length field in the header is at offset 0 and has a length of 2 bytes. The following list shows the use of a constructor whose three arguments are maxFrameLength, lengthFieldOffset, and lengthFieldLength. Writing big dataThis listing shows how you can transmit a file’s contents using zero-copy by creating a DefaultFileRegion from a FileInputStream and writing it to a Channel. This example applies only to the direct transmission of a file’s contents, excluding any processing of the data by the application. In cases where you need to copy the data from the file system into user memory, you can use ChunkedWriteHandler, which provides support for writing a large data stream asynchronously without incurring high memory consumption. The key is interface ChunkedInput&lt;B&gt;, where the parameter B is the type returned by the method readChunk(). Four implementations of this interface are provided, as listed in the following table. The following list illustrates the use of ChunkedStream, the implementation most often used in practice. Serializing dataJDK serializationIf your application has to interact with peers that use ObjectOutputStream and ObjectInputStream, and compatibility is your primary concern, then JDK serialization is the right choice. The following table lists the serialization classes that Netty provides for interoperating with the JDK. Serialization with JBoss MarshallingIf you are free to make use of external dependencies, JBoss Marshalling is ideal: It’s up to three times faster than JDK Serialization and more compact. The overview on the JBoss Marshalling homepage defines it this way: JBoss Marshalling is an alternative serialization API that fixes many of the problems found in the JDK serialization API while remaining fully compatible with java.io.Serializable and its relatives, and adds several new tunable parameters and additional features, all of which are pluggable via factory configuration (externalizers, class/instance lookup tables, class resolution, and object replacement, to name a few). Netty supports JBoss Marshalling with the two decoder/encoder pairs shown in the following table. The first set is compatible with peers that use only JDK Serialization. The second, which provides maximum performance, is for use with peers that use JBoss Marshalling. The following listing shows how to use MarshallingDecoder and MarshallingEncoder. Serialization via Protocol BuffersThe following table shows the ChannelHandler implementations Netty supplies for protobuf support. Here again, using protobuf is a matter of adding the right ChannelHandler to the ChannelPipeline, as shown in the following list.]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Netty</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Netty-in-Action》笔记（10）]]></title>
    <url>%2F2018%2F02%2F18%2F%E3%80%8ANetty-in-Action%E3%80%8B%E7%AC%94%E8%AE%B0%EF%BC%8810%EF%BC%89%2F</url>
    <content type="text"><![CDATA[The codec frameworkThis chapter covers An overview of decoders, encoders and codecs Netty’s codec classes What is a codec?This conversion logic is handled by a codec, which consists of an encoder and a decoder, each of which transforms a stream of bytes from one format to another. DecodersThese classes cover two distinct use cases: Decoding bytes to messages — ByteToMessageDecoder and ReplayingDecoder Decoding one message type to another — MessageToMessageDecoder Abstract class ByteToMessageDecoderThe following table shows two most important methods in ByteToMessageDecoder API. To decode the byte stream, you’ll extend ByteToMessageDecoder. The design is illustrated in figure 10.1. This listing shows the code for ToIntegerDecoder. Reference counting in codecsonce a message has been encoded or decoded, it will automatically be released by a call to ReferenceCountUtil.release(message). If you need to keep a reference for later use you can call ReferenceCountUtil.retain(message). This increments the reference count, preventing the message from being released. Abstract class ReplayingDecoderThe full declaration of this class is1public abstract class ReplayingDecoder&lt;S&gt; extends ByteToMessageDecoder The parameter S specifies the type to be used for state management, where Void indicates that none is to be performed. The following listing shows a reimplementation of ToIntegerDecoder based on ReplayingDecoder. Please take note of these aspects of ReplayingDecoderBuffer: Not all ByteBuf operations are supported. If an unsupported method is called, an UnsupportedOperationException will be thrown. ReplayingDecoder is slightly slower than ByteToMessageDecoder Here’s a simple guideline: use ByteToMessageDecoder if it doesn’t introduce excessive complexity; otherwise, use ReplayingDecoder. More decodersThe following classes handle more complex use cases: io.netty.handler.codec.LineBasedFrameDecoder — This class, used internally by Netty, uses end-of-line control characters (\n or \r\n) to parse the message data. io.netty.handler.codec.http.HttpObjectDecoder — A decoder for HTTP data. Abstract class MessageToMessageDecoderIn this section we’ll explain how to convert between message formats using the abstract base class12public abstract class MessageToMessageDecoder&lt;I&gt; extends ChannelInboundHandlerAdapter The parameter I specifies the type of the input msg argument to decode(), which is the only method you have to implement. The following table shows the details of this method. The design of IntegerToStringDecoder is illustrated in figure 10.2. The following listing is the implementation of IntegerToStringDecoder. HttpObjectAggregatorFor a more complex example, please examine the class io.netty.handler.codec.http.HttpObjectAggregator, which extends MessageToMessageDecoder&lt;HttpObject&gt;. Class TooLongFrameExceptionNetty provides a TooLongFrameException, which is intended to be thrown by decoders if a frame exceeds a specified size limit. Listing 10.4 shows how a ByteToMessageDecoder can make use of TooLongFrameException to notify other ChannelHandlers in the ChannelPipeline about the occurrence of a frame-size overrun. EncodersAbstract class MessageToByteEncoderThe following table shows the MessageToByteEncoder API. You may have noticed that this class has only one method, while decoders have two. The reason is that decoders often need to produce a last message after the Channel has closed (hence the decodeLast() method). Figure 10.3 shows a ShortToByteEncoder. The implementation of ShortToByteEncoder is shown in the following listing. Netty provides several specializations of MessageToByteEncoder upon which you can base your own implementations. The class WebSocket08FrameEncoder provides a good practical example. You’ll find it in the package io.netty.handler.codec.http.websocketx. Abstract class MessageToMessageEncoderThe following table shows the MessageToMessageEncoder API. Figure 10.4 shows a IntegerToStringEncoder. As shown in the next listing, the encoder adds a String representation of each outbound Integer to the List. For an interesting specialized use of MessageToMessageEncoder, look at the class io.netty.handler.codec.protobuf.ProtobufEncoder, which handles data formats defined by Google’s Protocol Buffers specification. Abstract codec classesAbstract class ByteToMessageCodecThe following table shows the ByteToMessageCodec API. Any request/response protocol could be a good candidate for using the ByteToMessageCodec. Abstract class MessageToMessageCodecMessageToMessageCodec is a parameterized class, defined as follows:1public abstract class MessageToMessageCodec&lt;INBOUND_IN,OUTBOUND_IN&gt; The important methods are listed in the following table. WebSocket protocolWebSocket is a recent protocol that enables full bidirectional communications between web browsers and servers. Class CombinedChannelDuplexHandlerCombinedChannelDuplexHandler declared as12public class CombinedChannelDuplexHandler &lt;I extends ChannelInboundHandler, O extends ChannelOutboundHandler&gt; First, examine ByteToCharDecoder in the following listing. The following list shows CharToByteEncoder, which converts Characters back to bytes. Now that we have a decoder and encoder, we’ll combine them to build up a codec. This listing shows how this is done.]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Netty</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Netty-in-Action》笔记（9）]]></title>
    <url>%2F2018%2F02%2F18%2F%E3%80%8ANetty-in-Action%E3%80%8B%E7%AC%94%E8%AE%B0%EF%BC%889%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Unit testingThis chapter covers Unit testing Overview of EmbeddedChannel Testing ChannelHandlers with EmbeddedChannel Overview of EmbeddedChannelNetty provides what it calls an embedded transport for testing ChannelHandlers. This transport is a feature of a special Channel implementation, EmbeddedChannel, which provides a simple way to pass events through the pipeline. The relevant methods of EmbeddedChannel are listed in the following table. Figure 9.1 shows how data flows through the ChannelPipeline using the methods of EmbeddedChannel. Testing ChannelHandlers with EmbeddedChannelTesting inbound messagesFigure 9.2 represents a simple ByteToMessageDecoder implementation. The implementation of the decoder is shown in the following listing. This listing shows a test of the preceding code using EmbeddedChannel. Testing outbound messagesFigure 9.3 shows the logic. The next listing implements this logic, illustrated in figure 9.3. The next listing tests the code using EmbeddedChannel. Testing exception handlingIn figure 9.4 the maximum frame size has been set to 3 bytes. If the size of a frame exceeds that limit, its bytes are discarded and a TooLongFrameException is thrown. The implementation is shown in the following listing. Again, we’ll test the code using EmbeddedChannel. The try/catch block used here is a special feature of EmbeddedChannel. If one of the write* methods produces a checked Exception, it will be thrown wrapped in a RuntimeException.]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Netty</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Netty-in-Action》笔记（8）]]></title>
    <url>%2F2018%2F02%2F17%2F%E3%80%8ANetty-in-Action%E3%80%8B%E7%AC%94%E8%AE%B0%EF%BC%888%EF%BC%89%2F</url>
    <content type="text"><![CDATA[BootstrappingThis chapter covers Bootstrapping clients and servers Bootstrapping clients from within a Channel Adding ChannelHandlers Using ChannelOptions and attributes Bootstrap classesThe bootstrapping class hierarchy consists of an abstract parent class and two concrete bootstrap subclasses, as shown in figure 8.1. Why are the bootstrap classes Cloneable?You’ll sometimes need to create multiple channels that have similar or identical settings. To support this pattern without requiring a new bootstrap instance to be created and configured for each channel, AbstractBootstrap has been marked Cloneable. Calling clone() on an already configured bootstrap will return another bootstrap instance that’s immediately usable. Note that this creates only a shallow copy of the bootstrap’s EventLoopGroup, so the latter will be shared among all of the cloned channels. This is acceptable, as the cloned channels are often short-lived, a typical case being a channel created to make an HTTP request. The full declaration of AbstractBootstrap is12public abstract class AbstractBootstrap &lt;B extends AbstractBootstrap&lt;B,C&gt;,C extends Channel&gt; The subclasses are declared as follows:12public class Bootstrap extends AbstractBootstrap&lt;Bootstrap,Channel&gt; and12public class ServerBootstrap extends AbstractBootstrap&lt;ServerBootstrap,ServerChannel&gt; Bootstrapping clients and connectionless protocolsBootstrap is used in clients or in applications that use a connectionless protocol. The following table gives an overview of the class, many of whose methods are inherited from AbstractBootstrap. Bootstrapping a clientThe Bootstrap class is responsible for creating channels for clients and for applications that utilize connectionless protocols, as illustrated in figure 8.2. The code in the following listing bootstraps a client that uses the NIO TCP transport. Channel and EventLoopGroup compatibilityThe following directory listing is from the package io.netty.channel. The following listing shows Incompatible Channel and EventLoopGroup. This code will cause an IllegalStateException because it mixes incompatible transports. More on IllegalStateExceptionWhen bootstrapping, before you call bind() or connect() you must call the following methods to set up the required components. group() channel() or channnelFactory() handler() Failure to do so will cause an IllegalStateException. The handler() call is particularly important because it’s needed to configure the ChannelPipeline. Bootstrapping serversThe ServerBootstrap classThe following table lists the methods of ServerBootstrap. Bootstrapping a serverYou may have noticed that table 8.2 lists several methods not present in table 8.1:childHandler(), childAttr(), and childOption(). These calls support operations that are typical of server applications. Specifically, ServerChannel implementations are responsible for creating child Channels, which represent accepted connections. Figure 8.3 shows a ServerBootstrap creating a ServerChannel on bind(), and the ServerChannel managing a number of child Channels. The code in this listing implements the server bootstrapping shown in figure 8.3. Bootstrapping clients from a ChannelFigure 8.4 shows EventLoop shared between channels. Implementing EventLoop sharing involves setting the EventLoop by calling the group() method, as shown in the following listing. A general guideline in coding Netty applications: reuse EventLoops wherever possible to reduce the cost of thread creation. Adding multiple ChannelHandlers during a bootstrapNetty supplies a special subclass of ChannelInboundHandlerAdapter,12public abstract class ChannelInitializer&lt;C extends Channel&gt; extends ChannelInboundHandlerAdapter which defines the following method:1protected abstract void initChannel(C ch) throws Exception; The following listing defines the class ChannelInitializerImpl and registers it using the bootstrap’s childHandler(). Using Netty ChannelOptions and attributesThe next listing shows how you can use ChannelOptions to configure a Channel and an attribute to store an integer value. Bootstrapping DatagramChannelsNetty provides various DatagramChannel implementations for this purpose. The only difference is that you don’t call connect() but only bind(), as shown next. ShutdownAbove all, you need to shut down the EventLoopGroup, which will handle any pending events and tasks and subsequently release all active threads. The following listing meets the definition of a graceful shutdown. Alternatively, you can call Channel.close() explicitly on all active channels before calling EventLoopGroup.shutdownGracefully(). But in all cases, remember to shut down the EventLoopGroup itself.]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Netty</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Netty-in-Action》笔记（7）]]></title>
    <url>%2F2018%2F02%2F16%2F%E3%80%8ANetty-in-Action%E3%80%8B%E7%AC%94%E8%AE%B0%EF%BC%887%EF%BC%89%2F</url>
    <content type="text"><![CDATA[EventLoop and threading modelThis chapter covers Threading model overview Event loop concept and implementation Task scheduling Implementation details Threading model overviewThe basic thread pooling pattern can be described as: A Thread is selected from the pool’s free list and assigned to run a submitted task (an implementation of Runnable). When the task is complete, the Thread is returned to the list and becomes available for reuse. This pattern is illustrated in figure 7.1. Interface EventLoopThe corresponding programming construct is often referred to as an event loop, a term Netty adopts with interface io.netty.channel.EventLoop. The basic idea of an event loop is illustrated in the following listing, where each task is an instance of Runnable (as in figure 7.1). Netty’s EventLoop is part of a collaborative design that employs two fundamental APIs: concurrency and networking. First, the package io.netty.util.concurrent builds on the JDK package java.util.concurrent to provide thread executors. Second, the classes in the package io.netty.channel extend these in order to interface with Channel events. The resulting class hierarchy is seen in figure 7.2. In this model, an EventLoop is powered by exactly one Thread that never changes, and tasks (Runnable or Callable) can be submitted directly to EventLoop implementations for immediate or scheduled execution. Note that Netty’s EventLoop, while it extends ScheduledExecutorService, defines only one method, parent(). This method is intended to return a reference to the EventLoopGroup to which the current EventLoop implementation instance belongs.1234public interface EventLoop extends EventExecutor, EventLoopGroup &#123; @Override EventLoopGroup parent();&#125; EVENT/TASK EXECUTION ORDER Events and tasks are executed in FIFO (first-in-first-out) order. I/O and event handling in Netty 4Event-handling logic must be generic and flexible enough to handle all possible use cases. Therefore, in Netty 4 all I/O operations and events are handled by the Thread that has been assigned to the EventLoop. I/O operations in Netty 3The threading model used in previous releases guaranteed only that inbound (previously called upstream) events would be executed in the so-called I/O thread (corresponding to Netty 4’s EventLoop). All outbound (downstream) events were handled by the calling thread, which might be the I/O thread or any other. Task schedulingJDK scheduling APIBefore Java 5, task scheduling was built on java.util.Timer, which uses a background Thread and has the same limitations as standard threads. Subsequently, the JDK provided the package java.util.concurrent, which defines the interface ScheduledExecutorService. Table 7.1 shows the relevant factory methods of java.util.concurrent.Executors. The next listing shows how to use ScheduledExecutorService to run a task after a 60-second delay. Scheduling tasks using EventLoopThe ScheduledExecutorService implementation has limitations, such as the fact that extra threads are created as part of pool management. To schedule a task to be executed every 60 seconds, use scheduleAtFixedRate(), as shown next. As we noted earlier, Netty’s EventLoop extends ScheduledExecutorService (see figure 7.2), so it provides all of the methods available with the JDK implementation, including schedule() and scheduleAtFixedRate(), used in the preceding examples. To cancel or check the state of an execution, use the ScheduledFuture that’s returned for every asynchronous operation. This listing shows a simple cancellation operation. Implementation detailsThread managementFigure 7.3 shows the execution logic used by EventLoop to schedule tasks. We stated earlier the importance of not blocking the current I/O thread. We’ll say it again in another way: “Never put a long-running task in the execution queue, because it will block any other task from executing on the same thread.” If you must make blocking calls or execute long-running tasks, we advise the use of a dedicated EventExecutor. (See the sidebar “ChannelHandler execution and blocking” in section 6.2.1.) EventLoop/thread allocationFigure 7.4 displays an EventLoopGroup with a fixed size of three EventLoops (each powered by one Thread). The EventLoops (and their Threads) are allocated directly when the EventLoopGroup is created to ensure that they will be available when needed. BLOCKING TRANSPORTSThe design for other transports such as OIO (old blocking I/O) is a bit different, as illustrated in figure 7.5.]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Netty</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Netty-in-Action》笔记（6）]]></title>
    <url>%2F2018%2F02%2F14%2F%E3%80%8ANetty-in-Action%E3%80%8B%E7%AC%94%E8%AE%B0%EF%BC%886%EF%BC%89%2F</url>
    <content type="text"><![CDATA[ChannelHandler and ChannelPipelineThis chapter covers The ChannelHandler and ChannelPipeline APIs Detecting resource leaks Exception handling The ChannelHandler familyThe Channel lifecycleInterface Channel defines a simple but powerful state model that’s closely related to the ChannelInboundHandler API. The four Channel states are listed in the following table. The normal lifecycle of a Channel is shown in figure 6.1. The ChannelHandler lifecycleThe lifecycle operations defined by interface ChannelHandler, listed in the following table, are called after a ChannelHandler has been added to, or removed from, a ChannelPipeline. Netty defines the following two important subinterfaces of ChannelHandler: ChannelInboundHandler — Processes inbound data and state changes of all kinds ChannelOutboundHandler — Processes outbound data and allows interception of all operations Interface ChannelInboundHandlerThe following table lists the lifecycle methods of interface ChannelInboundHandler. These are called when data is received or when the state of the associated Channel changes. When a ChannelInboundHandler implementation overrides channelRead(), it is responsible for explicitly releasing the memory associated with pooled ByteBuf instances. Netty provides a utility method for this purpose, ReferenceCountUtil.release(), as shown next. A simpler alternative is to use SimpleChannelInboundHandler. Because SimpleChannelInboundHandler releases resources automatically, you shouldn’t store references to any messages for later use, as these will become invalid. Interface ChannelOutboundHandlerThe following table shows all of the methods defined locally by ChannelOutboundHandler(leaving out those inherited from ChannelHandler). CHANNELPROMISE VS. CHANNELFUTUREMost of the methods in ChannelOutboundHandler take a ChannelPromise argument to be notified when the operation completes. ChannelPromise is a subinterface of ChannelFuture that defines the writable methods, such as setSuccess() or setFailure(), thus making ChannelFuture immutable. ChannelHandler adaptersThe resulting class hierarchy is shown in figure 6.2. The method bodies provided in ChannelInboundHandlerAdapter and ChannelOutboundHandlerAdapter call the equivalent methods on the associated ChannelHandlerContext, thereby forwarding events to the next ChannelHandler in the pipeline. Resource managementNetty provides class ResourceLeakDetector, which will sample about 1% of your application’s buffer allocations to check for memory leaks. If a leak is detected, a log message similar to the following will be produced: 12345LEAK: ByteBuf.release() was not called before it&apos;s garbage-collected. Enable advanced leak reporting to find out where the leak occurred. To enable advanced leak reporting, specify the JVM option&apos;-Dio.netty.leakDetectionLevel=ADVANCED&apos; or call ResourceLeakDetector.setLevel(). Netty currently defines the four leak detection levels, as listed in the following table. The leak-detection level is defined by setting the following Java system property to one of the values in the table:1java -Dio.netty.leakDetectionLevel=ADVANCED This listing shows how to release the message. On the outbound side, if you handle a write() operation and discard a message, you’re responsible for releasing it. The next listing shows an implementation that discards all written data. It’s important not only to release resources but also to notify the ChannelPromise. Otherwise a situation might arise where a ChannelFutureListener has not been notified about a message that has been handled. In sum, it is the responsibility of the user to call ReferenceCountUtil.release() if a message is consumed or discarded and not passed to the next ChannelOutboundHandler in the ChannelPipeline. If the message reaches the actual transport layer, it will be released automatically when it’s written or the Channel is closed. Interface ChannelPipelineEvery new Channel that’s created is assigned a new ChannelPipeline. This association is permanent. ChannelHandlerContextA ChannelHandlerContext enables a ChannelHandler to interact with its ChannelPipeline and with other handlers. A handler can notify the next ChannelHandler in the ChannelPipeline and even dynamically modify the ChannelPipeline it belongs to. Modifying a ChannelPipelineA ChannelHandler can modify the layout of a ChannelPipeline in real time by adding, removing, or replacing other ChannelHandlers. (It can remove itself from the ChannelPipeline as well.) The relevant methods are listed in the following table. This listing shows these methods in use. ChannelHandler execution and blockingNormally each ChannelHandler in the ChannelPipeline processes events that are passed to it by its EventLoop (the I/O thread). It’s critically important not to block this thread as it would have a negative effect on the overall handling of I/O. The following table shows the ChannelPipeline operations for accessing ChannelHandlers. Firing eventsThe following table lists the inbound operations, which notify ChannelInboundHandlers of events occurring in the ChannelPipeline. The following table lists the outbound operations of the ChannelPipeline API. In summary, A ChannelPipeline holds the ChannelHandlers associated with a Channel. A ChannelPipeline can be modified dynamically by adding and removing ChannelHandlers as needed. ChannelPipeline has a rich API for invoking actions in response to inbound and outbound events. Interface ChannelHandlerContextA ChannelHandlerContext represents an association between a ChannelHandler and a ChannelPipeline and is created whenever a ChannelHandler is added to a ChannelPipeline. The methods called on a ChannelHandlerContext will start at the current associated ChannelHandler and propagate only to the next ChannelHandler in the pipeline that is capable of handling the event. The following table summarizes the ChannelHandlerContext API. When using the ChannelHandlerContext API, please keep the following points in mind: The ChannelHandlerContext associated with a ChannelHandler never changes, so it’s safe to cache a reference to it. ChannelHandlerContext methods involve a shorter event flow than do the identically named methods available on other classes. This should be exploited where possible to provide maximum performance. Using ChannelHandlerContextFigure 6.4 shows the relationships. In the following listing you acquire a reference to the Channel from a ChannelHandlerContext. Calling write() on the Channel causes a write event to flow all the way through the pipeline. The next listing shows a similar example, but writing this time to a ChannelPipeline. As you can see in figure 6.5, the flows in listings 6.6 and 6.7 are identical. It’s important to note that although the write() invoked on either the Channel or the ChannelPipeline operation propagates the event all the way through the pipeline, the movement from one handler to the next at the ChannelHandler level is invoked on the ChannelHandlerContext. If you want to propagate an event starting at a specific point in the ChannelPipeline, the following listing and figure 6.6 illustrate this use. As shown in figure 6.6, the message flows through the ChannelPipeline starting at the next ChannelHandler, bypassing all the preceding ones. Advanced uses of ChannelHandler and ChannelHandlerContextThe following list shows caching a ChannelHandlerContext. Because a ChannelHandler can belong to more than one ChannelPipeline, it can be bound to multiple ChannelHandlerContext instances. A ChannelHandler intended for this use must be annotated with @Sharable; otherwise, attempting to add it to more than one ChannelPipeline will trigger an exception. This listing shows a correct implementation of this pattern. Conversely, the code in listing 6.11 will cause problems. In summary, use @Sharable only if you’re certain that your ChannelHandler is thread-safe. Exception handlingHandling inbound exceptionsThe following listing shows a simple example that closes the Channel and prints the exception’s stack trace. To summarize, The default implementation of ChannelHandler.exceptionCaught() forwards the current exception to the next handler in the pipeline. If an exception reaches the end of the pipeline, it’s logged as unhandled. To define custom handling, you override exceptionCaught(). It’s then your decision whether to propagate the exception beyond that point. Handling outbound exceptionsNotification mechanisms: Every outbound operation returns a ChannelFuture. The ChannelFutureListeners registered with a ChannelFuture are notified of success or error when the operation completes. Almost all methods of ChannelOutboundHandler are passed an instance of ChannelPromise. As a subclass of ChannelFuture, ChannelPromise can also be assigned listeners for asynchronous notification. But ChannelPromise also has writable methods that provide for immediate notification:12ChannelPromise setSuccess();ChannelPromise setFailure(Throwable cause); The following listing uses this approach to add a ChannelFutureListener that will print the stack trace and then close the Channel. The code shown next will have the same effect as the previous listing.]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Netty</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05 ByteBuf]]></title>
    <url>%2F2018%2F02%2F12%2F05%20ByteBuf%2F</url>
    <content type="text"><![CDATA[点击查看 《Netty in Action》笔记目录。 本文是对《Netty in Action》第5章内容的笔记和翻译，主要内容包括： ByteBuf：Netty 的数据容器 API 细节 用例 内存分配 ByteBuf APINetty 数据处理的 API 暴露在两个组件上：抽象类 ByteBuf 和接口 ByteBufHolder。 ByteBuf API 的一些优点如下： 对于用户定义的缓冲区类型也是可扩展的。 通过内置的复合缓冲类型实现了透明的零拷贝。 容量会随着需求扩充（类似 JDK 中的 StringBuilder）。 在读写模式中切换不需要调用 ByteBuffer 的 flip() 方法。 读写使用不同的指示下标。 支持方法链接。 支持引用计数。 支持池化。 ByteBuf 类：Netty 的数据容器它是如何工作的 ByteBuf 维护了两个不同的下标指示：一个用于读，一个用于写。 ByteBuf 以 read 或者 write 开头的方法会将读下标往前推进，而 set 和 get 开头的方法不会。 ByteBuf 的最大容量是可以被确定的，如果写的数据超过界限，那么会触发一个异常（默认的容量限制是 Integer.MAX_VALUE）。 图5.1 展示了 ByteBuf 为空时候的状态。 ByteBuf 的使用方法Heap BufferByteBuf 最常用的使用方式是将数据存储到 JVM 的堆空间中去。通过指向一个 backing array, 这个模式可以在不使用池化技术的时候，快速地分配和回收内存。 注意： 当 hasArray() 返回 false 时，尝试访问 backing array 会触发 UnsupportedOperationException 异常。这和适用 JDK 中的 ByteBuffer 类似。 Direct BufferDirect buffer 是 ByteBuf 的另一种使用方式。JDK 1.4 版本中和 NIO 一起引入的 ByteBuffer 类可以允许 JVM 通过本地调用分配内存。这样在调用本地 I/O 操作时，可以避免在数据缓冲区和中间缓冲区之间拷贝数据内容。 ByteBuffer 的 Javadoc 明确地指出：direct buffer 的数据内容不在堆垃圾回收的管理范围内。这解释了为什么 direct buffer 适用于网络数据传输。如果你的数据存储在基于堆分配的缓冲区中，那么在发送数据到 socket 前，JVM 会在内部将你缓冲区的数据拷贝到 direct buffer 中去。 Direct buffer 主要的缺点是：它们的分配和释放的开销比 heap-based buffer 更大一点。 混合 BufferComposite buffer 集成了多个 ByteBuf。你可以按需添加和删除 ByteBuf 实例，这个特性是 JDK 中的 ByteBuffer 实现所不具备的。 警告：CompositeByteBuf 中的 ByteBuf 实例可能包括 direct 和 nondirect 分配。如果只有一个实例，那么在 CompositeByteBuf 上调用 hasArray() 会返回这个实例的 hasArray() 值；否则会返回 false。 CompositeByteBuf 在暴露通用 ByteBuf API 的时候，消除了不必要的拷贝。图5.2 展示了它的结构。 下面的清单展示了JDK 的 ByteBuffer 是如何实现这样的需求的。 下面的清单展示了使用 CompositeByteBuf 的版本。 CompositeByteBuf 可能不允许访问 backing array，所以 CompositeByteBuf 的数据访问和 direct buffer 的模式类似，如下所示。 Netty 通过使用 CompositeByteBuf 优化了 socket I/O 操作，消除了 JDK buffer 实现的性能和内存缺陷。 Byte 级别的操作随机访问下面的清单展示了对存储机制的封装，可以非常方便地通过迭代访问 ByteBuf 的内容。 值得注意的是，通过输入的 index 参数访问数据，不会修改 readerIndex 或 writerIndex 的值。这些下标可以通过调用 readerIndex(index) 或 writerIndex(index) 手工地推进。 顺序访问ByteBuf 同时有读和写两个指示下标，而 JDK 的 ByteBuffer 只有一个，因此在 JDK 中需要调用 flip() 来切换读写模式。图5.3 展示了一个 ByteBuf 被两个下标分为了三个部分。 可丢弃字节图5.4 展示了在图5.3 中展示的 buffer 上调用 discardReadBytes() 后的结果。你可以看到 discardable bytes 中的空间可以被写操作所用了。值得注意的是，在 discardReadBytes() 方法调用后，writable 端中的内容并不保证不丢失。 你可能倾向于频繁地调用 discardReadBytes() 来最大化可写的空间，但是请注意这很有可能导致内存拷贝，因为可读的字节需要被移动到 buffer 开始的地方。 可读字节下面清单展示了如何读取可读的字节。 可写字节下面清单展示了如何用随机整数填满 buffer，直到空间用完。 下标管理你可以通过 markReaderIndex()、markWriterIndex()、resetReaderIndex() 和 resetWriterIndex() 这些函数来设置和重置 ByteBuf 的读写下标。 你也可以通过调用 readerIndex(int) 或 writerIndex(int) 函数来移动下标。 图5.6 展示了 ByteBuf 在 clear() 被调用后的结果（调用前是图5.3）。 搜索操作有多个方法可以确定 ByteBuf 中需要搜索的值的位置。最简单的一个方法是 indexOf()。 下面的清单展示了如何搜索 \r。 派生 buffer一个派生 buffer 提供了 ByteBuf 持有内容的特定格式视图。这些视图可以通过下面的方法创建： duplicate() slice() slice(int, int) Unpooled.unmodifiableBuffer(…) order(ByteOrder) readSlice(int) 每个方法都返回了一个自带读、写、标记下标的 ByteBuf 实例。内部的存储是共享的，这种模式和 JDK 的 ByteBuffer 是一样的。这使得派生出来的 buffer 的创建代价不是很大，但这也意味着：如果你修改了内容，那么原来实例的数据内容也会改变，所以要谨慎。 Bytebuf 拷贝如果你需要对 buffer 进行真实的拷贝，那可以使用 copy() 或者 copy(int,int)。和派生的 buffer 不同，ByteBuf 的这个调用会返回一个独立的数据拷贝。 下面的清单展示了如何处理 slice (int, int) 方法产生的 ByteBuf 段。 接下来让我们看看 ByteBuf 的 copy 和 slice 的不同。 读写操作下表展示了常用的 get() 方法。 下表展示了常用的 set() 方法。 下面的清单展示了 get() 和 set() 方法的使用，可以看到它们没有改变读写下标。 下表展示了常用的 read() 方法 下表展示了常用的 write() 方法 下面的清单展示了这些方法的使用。 更多操作下表展示了 ByteBuf 其它一些常用的方法。 ByteBufHolder 接口ByteBufHolder 有一些方法可以访问底层数据和引用计数。下表展示了这些方法（除去那些继承于 ReferenceCounted 的方法）。 如果你想将一个消息对象的实体数据存储在 ByteBuf 中，那么 ByteBufHolder 将是一个不错的选择。 ByteBuf 分配按需：ByteBufAllocator 接口为了减少内存分配和回收的开销，Netty 提供了采用池化技术的 ByteBufAllocator。 下表展示了 ByteBufAllocator 提供的操作。 你可以通过 Channel（每个 Channel 都有一个不同的实例）或者与 ChannelHandler 绑定的 ChannelHandlerContext 来获得 ByteBufAllocator 的引用。 Netty 提供了2种 ByteBufAllocator 实现：PooledByteBufAllocator 和 UnpooledByteBufAllocator。前者会池化 ByteBuf 实例来提升性能和最小化内存分配。这个实现采用了一个高效的内存分配方法 jemalloc，这种方法当前被多个操作系统所采用。 没有池化的 bufferNetty 提供了 Unpooled 工具类，该工具类提供了静态辅助函数来创建不池化的 ByteBuf 实例。下表展示了这个类的一些重要方法。 ByteBufUtilByteBufUtil 提供了静态辅助函数来帮助操控 ByteBuf。 hexdump() boolean equals(ByteBuf, ByteBuf) 引用计数引用计数是一个用于优化内存使用和提高性能的技术：当对象没有其他对象引用它的时候，对它进行释放。Netty 在版本4中为 ByteBuf 和 ByteBufHolder 引入了引用计数，这两者都实现了 ReferenceCounted 接口。 引用计数对于池化实现（如 PooledByteBufAllocator）是非常重要的，这减少了内存分配的开销。下面清单展示了使用例子。 当尝试访问一个已经被释放的引用计数对象是时，会导致 IllegalReferenceCountException 异常。 谁负责释放？通常来说，最后访问它的人需要释放它。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Netty</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04 传输]]></title>
    <url>%2F2018%2F02%2F11%2F04%20%E4%BC%A0%E8%BE%93%2F</url>
    <content type="text"><![CDATA[点击查看 《Netty in Action》笔记目录。 本文是对《Netty in Action》第4章内容的笔记和翻译，主要内容包括： OIO：阻塞传输 NIO：异步传输 本地传输：和 JVM 异步交互 测试你的 ChannelHandler 案例学习：传输迁移不通过 Netty 使用 OIO 和 NIO我们将要展示基于 JDK API 的阻塞（OIO）和异步（NIO）应用版本。下面展示了阻塞实现版本。 下面展示了非阻塞版本。 通过 Netty 使用 OIO 和 NIO 非阻塞 Netty 版本 因为 Netty 对每一种传输实现都暴露了相同的 API，所以无论你采用哪一种传输，你的代码几乎不用修改。 传输 API传输 API 的核心是 Channel 接口，所有的 I/O 操作都会使用这个接口。Channel 类的继承关系如图4.1所示。 Channel 中组合了 ChannelPipeline 和 ChannelConfig。ChannelConfig 保存了 Channel 所有的配置，并且支持热更新。 由于 Channel 是独一无二的，所以 Channel 继承了 java.lang.Comparable 接口，从而保证对象的有序。因此，如果两个 Channel 实例返回相同的 hash 值，那 AbstractChannel 中 compareTo() 的实现将会抛出 Error。 ChannelHandler 常用于： 转换数据格式。 提供异常通知。 提供 Channel 被激活或者关闭的通知。 提供 Channel 从 EventLoop 中注册和取消注册的通知。 提供用户定义事件的通知。 拦截过滤器ChannelPipeline 实现了一个常用设计模式:拦截过滤器。UNIX 管道是这个模式的另一个典型例子：命令被链式编排，每个命令的输出会作为接下来一个命令的输入。 你同样可以在运行时按照你的需求为 ChannelPipeline 添加或删除 ChannelHandler。 除了可以使用 ChannelPipeline 和 ChannelConfig 之外，你还可以使用 Channel 的方法，下表展示了一些常用的方法。 方法名称 描述 eventLoop 返回与 Channel 绑定的 EventLoop。 pipeline 返回与 Channel 绑定的 ChannelPipeline。 isActive 如果 Channel 是激活（active）的，返回 true。 Active 的含义取决于下层的传输协议。例如, Socket 中的 active 是指与远端建立连接；Datagram 中的 active 是指 Datagram 打开。 localAddress 返回本地的 SocketAddress. remoteAddress 返回远端的 SocketAddress. write 将数据写到远端。数据会经过 ChannelPipeline，并将会进行排队，直到刷新时才会发送。 flush 将之前写的数据刷新到底层的传输协议中，例如：Socket。 writeAndFlush 先调用 write() ，然后调用 flush()。 下图展示了如何利用 Channel.writeAndFlush() 实现最常见的发送数据到远端的任务。 Netty 的 Channel 实现是线程安全的，所以你可以存储 Channel 的一个引用，并且在你需要发送数据的时候使用它，即使在多线程环境中也没有关系。 包含的传输下表展示了 Netty 中提供的传输。 名称 所在的包 描述 NIO io.netty.channel.socket.nio 以 java.nio.channels 包为基础，是一个基于 selector 的实现方案。 Epoll io.netty.channel.epoll 通过 JNI 使用 epoll() 进入非阻塞 IO。这个传输的特性只适用于 Linux，如：SO_REUSEPORT。它比 NIO 传输要快，是完全非阻塞。 OIO io.netty.channel.socket.oio 使用 java.net 包作为基础，使用阻塞流。 Local io.netty.channel.local 一个本地传输，可以被用来通过管道与 VM 交互。 Embedded io.netty.channel.embedded 一个嵌入式传输协议。通过它，你可以在虚拟的传输协议上使用 ChannelHandler。这在测试 ChannelHandler 实现时很有用。 NIO — 非阻塞 I/OSelector 背后基本的原理是：提供一个注册器，通过注册感兴趣的事件，当 Channel 状态改变的时候你可以得到通知。可能的状态改变包括： 新的 Channel 被接收到并且已经准备好。 Channel 连接已经完成。 Channel 已经准备好为读操作提供数据。 Channel 已经准备好，可以写入数据了。 下表展示了 java.nio.channels.SelectionKey 类定义的一些模式。 方法名称 描述 OP_ACCEPT 当一个新的请求被接受并且 Channel 被创建的时候，会进行通知。 OP_CONNECT 当连接建立的时候，会进行通知。 OP_READ 当可以从 Channel 中读取数据的时候，会进行通知。 OP_WRITE 当可以往 Channel 中写入更多数据的时候，会进行通知。这个事件在 socket 缓存被填满的时候发生，通常意味着数据发送的速率操过了远端的处理能力。 NIO 内部实现的细节，在所有的 Netty 用户级别的 API 中都被隐藏了。图4.2 展示了处理的数据流。 零拷贝零拷贝这个特性目前只在 NIO 和 Epoll 传输中被支持。通过它可以使你快速并高效地从一个文件系统转移数据到网络中，不需要从内核空间拷贝到用户空间，这大大提高了 FTP、HTTP 等协议的传输效率。这个特性并不是被所有的操作系统支持。确切地说，它并不适用于采用加密或压缩的文件系统，只有文件的原始数据可以被转移。但对于已经加密好的文件是可以被传输的。 Epoll — 针对 Linux 的原生非阻塞传输Netty 为 Linux 系统提供了一个使用 epoll 的 NIO API。在某种程度上，这与 Netty 本身的设计更加一致，并且比中断的实现方式开销更少。如果你的应用准备在 Linux 上使用，那么可以考虑这个版本，你会发现在高负载的情况下，它的性能表现会好于 JDK 本生的 NIO 实现。 这个传输和图4.2中展示的传输语义相同，并且它的使用是很简单的，可以参考 list 4.4。为了使用 epoll 版的 NIO，可以将 NioEventLoopGroup 替换为 EpollEventLoopGroup，将 NioServerSocketChannel.class 替换为 EpollServerSocketChannel.class。 OIO — 阻塞型 I/O 你可能会对此感到好奇：Netty 是如何通过相同的 API 来支持异步传输的 NIO？答案是 Netty 使用了 SO_TIMEOUT Socket 标志。 这个标志表明等待 I/O 操作完成的最大毫秒数。如果操作在指定的时间间隔内没有完成，那么将会抛出 SocketTimeoutException。Netty 会捕捉这个异常，并继续循环处理。 Local — 通过本地传输与 JVM 交互Netty 为同一个 JVM 上的客户端和服务端的异步交互提供了一个本地传输。 因为本地传输并没有真正的网络传输，所以它不能和其它传输协议一起协作。因此，一个客户端如果想通过这个传输来连接服务端的话（在同一个 JVM 上），服务端也必须使用这个传输。除了这个限制，它的使用和其它传输协议是一样的。 嵌入传输Netty 还提供了一个传输，可以允许你嵌入在 ChannelHandler 中嵌入一个帮助类 ChannelHandler。在这种模式下，你可以扩展 ChannelHandler 的功能，而不用内部的代码。 传输使用例子下表展示了当前版本中传输支持的协议。 Transport TCP UDP SCTP UDT NIO 支持 支持 支持 支持 Linux 上的 Epoll 支持 支持 - - OIO 支持 支持 支持 在 Linux 上开启 SCTPSCTP 需要内核支持并且需要安装一些用户库。例如，在 Ubuntu 上可以使用下面的命令：1# sudo apt-get install libsctp1 在 Fedora 上，你需要使用 yum：1# sudo yum install kernel-modules-extra.x86_64 lksctp-tools.x86_64 请阅读你的 Linux 发布版本的手册，了解如何开启 SCTP。 下面是你可能会遇到的一些用例。 基于非阻塞的代码：如果你在你的代码中不阻塞调用，或者你要限制阻塞的调用，推荐使用 NIO（在 Linux 上使用 epoll）。NIO/epoll 主要是用于处理很多并发的连接，在数量较少的时候变现的也不错，尤其是在多个连接共享线程的情况下。 基于阻塞的代码：正如我们之前提过，如果你的代码很依赖阻塞 I/O，并且你应用具有相应的设计，那么你直接从阻塞 I/O 切换到 Netty 的 NIO 传输，可能会遇到麻烦。最好不要直接重写代码来适应新的 I/O, 可以考虑一个阶段性的迁移：从 OIO 开始，迁移到 NIO（或者你使用 Linux 的话就是 epoll）。 在同一个 JVM 上进行交互：如果要在同一个 JVM 上进行交互不需要使用网络，使用本地传输再恰当不过了。这可以在使用 Netty 代码的同时消除真实网络的开销。如果你需要在真实网络上使用该服务，你只需将传输替换为 NIO 或者 OIO。 测试你的 ChannelHandler 实现：如果你想为你的 ChannelHandler 实现写单元测试，可以考虑使用嵌入传输。这可以使得你在测试实现的时候不用创建很多的模拟对象。你写的类还是会和通用的 API 事件流保持一致，保证 ChannelHandler 在真实传输上表现正确。 下表总结了我们提到过的用例。 应用需求 推荐使用的协议 非阻塞或者普通的尝试 NIO（或者在 Linux 上使用 epoll） 阻塞 OIO 在同一个 JVM 上交互 Local 测试你的 ChannelHandler 实现 Embedded]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Netty</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03 Netty的组件和设计]]></title>
    <url>%2F2018%2F02%2F10%2F03%20Netty%E7%9A%84%E7%BB%84%E4%BB%B6%E5%92%8C%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[点击查看 《Netty in Action》笔记目录。 本文是对《Netty in Action》第3章内容的笔记和翻译，主要内容包括： Netty 技术和架构方面的介绍 Channel、EventLoop 和 ChannelFuture ChannelHandler 和 ChannelPipeline 启动（ Bootstrapping） Channel、EventLoop 和 ChannelFuture下面这些可以被看做 Netty 网络模型的抽象： Channel：Sockets EventLoop：流控、多线程、并发 ChannelFuture：异步通知 Channel 接口Java 中基本的网络 I/O 操作依赖 Socket 类，如：bind()、connect()、read() 和 write()。Netty 中的 Channel 接口提供的 API 与直接操作 Sockets API 相比，大大减少了复杂度。此外，Channel 是很多专有实现的基类，这些实现包括： EmbeddedChannel LocalServerChannel NioDatagramChannel NioSctpChannel NioSocketChannel EventLoop 接口EventLoop 定义了 Netty 核心抽象：在一个连接周期中处理发生的事件。图3.1 在一个高层次展示了 Channels、EventLoops、Threads 和 EventLoopGroups 的关系。关系如下： 一个 EventLoopGroup 包括了一个或多个 EventLoop。 一个 EventLoop 在生命周期中只会绑定到一个单一的线程 Thread。 所有被 EventLoop 处理的 I/O 事件都会被它绑定的线程 Thread 处理。 一个 Channel 会在一个单一的 EventLoop 中注册它的生命周期。 一个单一的 EventLoop 可能会被分配多个 Channels。 值得注意的是：在这个设计中，一个给定 Channel 的 I/O 的操作都是由同一个线程执行的，也就是这些操作是单线程的，所以无形中消除了同步的问题。 ChannelFuture 接口Netty 中提供了 ChannelFuture，这个接口具有 addListener()方法，通过这个方法可以注册一个 ChannelFutureListener，这个监听器会在方法结束时被调用（无论执行是否成功）。 ChannelFuture 的更多介绍可以把 ChannelFuture 看做是存放结果的一个站位空间，这里的结果将会在未来的某个时刻被填满。可以确定的是：对于同一个 Channel 的所有操作都会被执行，并且执行顺序与调用的顺序一致。 ChannelHandler 和 ChannelPipelineChannelHandler 接口对于应用开发者来说，Netty 中最重要的组件是 ChannelHandler。这个组件承载了对输入输出数据的所有应用处理逻辑。 事实上，ChannelHandler 几乎可以满足所有的操作，包括：转换数据的格式、处理过程中抛出的异常等。 ChannelPipeline 接口ChannelPipeline 提供了链式 ChannelHandlers 的一个承载容器，并且定义了在这个链中传递输入输出事件的 API。当一个 Channel 被创建的时候，它会被自动绑定到它所在的 ChannelPipeline 上。 ChannelHandler 通过以下步骤安装到 ChannelPipeline 上： 在 ServerBootstrap 上注册一个 ChannelInitializer 的实现。 当 ChannelInitializer.initChannel() 函数被调用的时候，ChannelInitializer 将会在 pipeline 中安装一系列的 ChannelHandler。 然后 ChannelInitializer 从 ChannelPipeline 中把它自身删除。 图3.2 展示了从 ChannelHandler 派生出来的 ChannelInboundHandler 和 ChannelOutboundHandler。 图3.3 展示了 Netty 应用中输入和输出端数据流的区别。 输入输出处理器的更多介绍一个事件可以通过 ChannelHandlerContext 传递到链中的下一个处理器，ChannelHandlerContext 在每个方法中都会被作为一个输入参数。因为你有时候会忽略不感兴趣的事件，Netty 提供了抽象基础类 ChannelInboundHandlerAdapter 和 ChannelOutboundHandlerAdapter。每个都提供了方法实现，通过调用 ChannelHandlerContext 中的相应方法，可以简化传递到下一个处理者的操作。然后，你可以扩展类并覆盖你感兴趣的方法。 当两种类别处理器在同一个 ChannelPipeline 中混合时会发生什么？尽管输入输出 handler 都继承于 ChannelHandler，但 Netty 还是会区分 ChannelInboundHandler 和 ChannelOutboundHandler 的不同实现，并且 确保数据只在方向相同类型的 handler 之间传递。 当 ChannelHandler 被加入到 ChannelPipeline 中时，它会被分配一个 ChannelHandlerContext，这个 ChannelHandlerContext 代表了 ChannelHandler 和 ChannelPipeline 之间的绑定关系。 Netty 中发送数据的方法有两种： 直接写入到 Channel，消息会从 ChannelPipeline 的尾部开始传递。 写入到 ChannelHandler 关联的 ChannelHandlerContext，消息会从 ChannelPipeline 中的下一个handler 开始传递。 进一步了解 ChannelHandlerNetty 中有一些适配类，从而减少了常用 ChannelHandler 类的工作量。这些适配类提供了相应接口方法的默认实现。 你在写 handle 时经常会用到的适配类包括： ChannelHandlerAdapter ChannelInboundHandlerAdapter ChannelOutboundHandlerAdapter ChannelDuplexHandlerAdapter 编码和解码当你使用 Netty 发送和接收数据时，需要进行数据格式的转换。输入的消息将会被解码，也就是将输入的字节转换为另一种格式，典型的是转化为一个 Java 对象。如果数据是输出的，相反的操作将会发生：会从现在的格式编码成自己。需要这样做的原因很简单，网络传输的数据是一系列的字节。 所有 Netty 提供的编码解码（encoder/decoder）的适配类都实现于 ChannelInboundHandler 或者 ChannelOutboundHandler。 你将发现：对于输入数据，channelRead 方法或事件会被覆写。对于输入 Channel 的每条数据，这个方法都会被调用。然后会调用解码器的 decode() 方法，并将解码后的字节传输到 pipeline 中的下一个 ChannelInboundHandler。 而输出数据的模式正好相反：编码器将消息转换为字节，并将这些字节传递到下一个 ChannelOutboundHandler。 抽象类 SimpleChannelInboundHandler很常见的是，你的应用需要实现一个 handler 来接受解码的数据并且在数据上实现应用逻辑。创建这样的一个 ChannelHandler，你只需要扩展基类 SimpleChannelInboundHandler&lt;T&gt;，其中 T 是你需要处理的数据对应的 Java 类型。 这个 handler 中最重要的一个方法是 channelRead0(ChannelHandlerContext,T)。 BootstrappingNetty 的启动类可以为应用的网络层提供配置容器。 面向连接的协议请记住：严格意义上的连接（“connection”）只适用于面向连接的协议，如 TCP。在这样的协议中，可以保证连接的端之间可以按序接收到数据。 相应的，有两种类型的启动类：一个是客户端（Bootstrap），另一个是服务端（ServerBootstrap）。 下表对这两种类型的启动进行了比较。 类别 Bootstrap ServerBootstrap 网络功能 连接远程主机和端口 绑定本地端口 EventLoopGroup 的数目 1 2 启动一个客户端只需要一个 EventLoopGroup，但是服务端的 ServerBootstrap 需要两个（可以是同一个实例），这是为什么？ 服务端需要两个区分的 Channel 集合。第一个集合包括一个 ServerChannel，它代表了服务端自己用于监听（listening）的 socket，绑定到本地端口；第二个集合包括了所有创建的 Channels，用于处理输入服务端接收到的各个客户端连接。图3.4 展示了这个模型，并说明了为什么需要2个不同的 EventLoopGroups。 与 ServerChannel 相关的 EventLoopGroup 为 ServerChannel分配了一个 EventLoop，这个 EventLoop 负责为即将到来的连接请求创建 Channel。一旦接收到连接，第二个 EventLoopGroup 会为创建出来的 Channel 分配对应的 EventLoop。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Netty</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Head First 设计模式》笔记]]></title>
    <url>%2F2018%2F02%2F10%2F%E3%80%8AHead-First-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E3%80%8B%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[将之前《Head First 设计模式》笔记 pdf 版本转换为网页博客，方便查看。本文主要介绍一些基本概念。 设计原则针对接口编程针对接口编程而不是针对实现编程。“针对接口编程”这句话，可以更明确地说成“变量的声明类型应该是超类型，通常是一个抽象类或者接口或者是一个接口”。针对接口编程时利用多态特性。 多用组合，少用继承组合可以是系统具有很大的弹性，可以“在运行时动态得改变行为”。 松耦合设计为了交互对象之间的松耦合设计而努力。松耦合的设计之所以能让我们建立有弹性的OO系统，能够应对变化，是因为对象之间的互相依赖降到了最低。 观察者模式提供了一种对象设计，让主题和观察者之间松耦合。 开放-关闭原则类应该对扩展开放，对修改关闭。 我们的目标是运行类容易扩展，在不修改现有代码的情况下，就可以搭配新的行为。虽然似乎有点矛盾，但是确实有些技术可以实现。在选择需要被扩展的代码部分要小心。每个地方都采用开放-关闭原则是一种浪费，也没有必要，还会导致代码变得复杂且难以理解。比如：装饰者模式、观察者模式。 依赖倒置原则依赖倒置原则（Dependency Inversion）：要依赖抽象，不要依赖具体类。 这个原则说明了：不能让高层组件依赖低层组件，“两者”都应该依赖于抽象。比如：工厂模式。 最小知识原则最小知识原则（Least Knowledge）：当我们设计一个系统时，对任何对象都要注意它交互的类有哪些，不要让多个类耦合在一起，免得修改一部分会影响到其它部分。 反例：1return a.getB().getC(); 正例：1return a.getC(); 如果我们调用从另一个调用中返回的对象的方法，相当于向另一个对象的子部分发请求，增加了我们直接认识的对象数目。 在对象方法内，我们只应该调用属于以下范围的方法： 该对象本身 方法传递进来参数的对象 此方法创建或实例化的任何对象（方法内的局部对象） 对象的任何组件（组件：HAS-A关系） 好莱坞原则别调用（打电话给）我们，我们会调用（打电话给）你。高层组件对待低层组件的方式是“别调用我们，我们会调用你”。例如：模板方法模式。 单一责任一个类应该只有一个引起变化的原因。 如果一个类有两个改变的原因，那么这会使得将来该类的变化机率上升，而当它真的改变时，你的设计同时有两个方面将会受影响。迭代器模式就是将遍历的责任从集合类中分离出来。 设计模式策略模式策略模式：定义了算法簇，分别封装起来，让他们之间可以互相替换，此模式让算法的变化独立于使用算法的客户。 观察者模式观察者（Observer）模式定义了对象之间的一对多依赖，这样一来，当一个对象改变状态时，它的所有依赖者都会收到通知并自动更新。 装饰者模式装饰者模式：动态地将责任附加到对象上。若要扩展功能，装饰者提供了比继承更有弹性的替代方案。 装饰者一般对组件的客户是透明的，除非客户程序依赖于组件的具体类型。 装饰者会导致设计中出现许多小对象，如果过度使用，会让程序变得很复杂。 经典案例：Java I/O 工厂模式工厂方法模式：定义了一个创建对象的接口，但由子类决定要实例化的类是哪一个。工厂方法让类的实例化推迟到子类。 抽象工厂模式：提供一个接口，用于创建相关或依赖对象的家族，而不需要明确指定具体类。 创建对象的区别：工厂方法模式采用的方法是继承，抽象工厂模式通过对象组合。 单件模式单件模式（Singleton）：确保一个类只有一个实例，并提供一个全局访问点。 命令模式命令模式：将“请求”封装成对象，以便使用不同的请求、队列或者日志来参数化其他对象。命令模式也支持可撤销的操作。 应用：日程安排（Scheduler）、线程池、工作队列等。 适配器模式适配器模式：将一个类的接口，转换成客户期望的另一个接口。适配器让原本接口不兼容的类可以合作无间。 外观模式外观模式（Facade）：提供了一个统一的接口，用来访问子系统同中的一群接口。外观定义了一个高层接口，让子系统更容易使用。特点： 外观没有“封装”子系统，外观只是提供简化的接口。所以用户如果觉得有必要，依然可以使用子系统的类。 外观可以附加“聪明”的功能，让使用子系统更方便（这里的“聪明”的功能个人理解为：通过子系统也能实现的，但是外观把调用的逻辑等实现了）。 每个子系统可以创建多个外观。 外观模式允许你将客户从组件的子系统中解耦。如果客户只是使用外观，那么修改子系统的实现，只要外观不变即可。 与适配器模式的差异主要在意图上。适配器的意图是将接口转换成不同接口，而外观意图是简化接口。 模板方法模式模板方法模式：在一个方法中定义一个算法的骨架，而将一些步骤延迟到子类中。模板使得子类可以在不改变算法结构的情况下，重新定义算法中的某些步骤。 迭代器模式迭代器模式：提供一种方法顺序访问一个聚合对象中的各个元素，而又不暴露其内部的表示。 组合模式组合模式（Composite Pattern）允许你将对象组合成树型结构来表现“整体/部分”层次结构。组合能让客户以一致的方式处理个别对象以及对象组合。 状态模式状态模式：允许对象在内部状态改变时改变它的行为，对象看起来好像修改了它的类。 代理模式代理模式为另一个对象提供一个替身或占位符以控制对这个对象的访问。 使用代理模式创建代表（representative）对象，让代表对象控制某对象的访问，被代表的对象可以是远程对象、创建开销大的对象或需要安全控制的对象。 装饰者模式、适配器模式、代理模式的区别： 装饰者模式为对象增加行为，适配器会改变对象的接口，代理实现相同的接口控制对象的访问。 复合模式复合模式结合两个或以上的模式，组成一个解决方案，解决一再发生的一般性问题。 例如：MVC用了观察者模式、策略模式和组合模式。 桥接模式桥接模式（Bridge Pattern）不只改变你的实现，也改变你的抽象。 抽象和实现可以独立扩展，不会影响到对方。适合使用在需要跨越多个平台的图形和窗口系统上。缺点是增加了复杂度。 生成器模式生成器模式（Builder Pattern）封装一个产品的构造过程，并允许按步骤构造。 责任链模式当你想要让一个以上的对象有机会能够处理某个请求的时候，就使用责任链模式（Chain of Responsibility Pattern）。 经常被使用在窗口系统中，处理鼠标和键盘子类的事件。 蝇量模式如果想让某个类的一个实例能用来提供许多“虚拟实例”，就使用蝇量模式（Flyweight Pattern）。 减少运行时对象实例的个数，节省内存。但是单个的逻辑实例将无法拥有独立而不同的行为。 解释器模式使用解释器模式（Interpreter Pattern）为语言创建解释器。 当你需要实现一个简单的语言时可以使用解释器。当语法的规则数目太大时，这个模式可能会变得非常繁杂。 中介者模式使用中介者模式（Mediator Pattern）来集中相关对象之间复杂的沟通和控制方式。 中介者常常被用来协调相关的GUI组件。中介者模式的缺点是，如果设计不当，中介者对象本身会变得过于复杂。 备忘录模式当你需要让对象返回之前的状态时（例如，你的用户请求“撤销”），就使用备忘录模式（MementoPattern）。 在Java中，可以考虑使用序列化（serialization）机制存储系统的状态。 原型模式当创建给定类的实例的过程很昂贵或很复杂时，就使用原型模式（Prototype Pattern）。 当一个复杂的类层次中，当系统必须从其中的许多类型创建新对象时，可以考虑原型。但是对象的复制有时相当复杂。 访问者模式当你想要为一个对象的组合增加新的能力，且封装并不重要时，就使用访问者模式（Visitor Pattern）。 当采用访问者模式的时候，就会打破组合类的封装。因为游走的功能牵涉其中，所以对组合结构的改变就更加困难。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Java8实战》笔记]]></title>
    <url>%2F2018%2F02%2F10%2F%E3%80%8AJava8%E5%AE%9E%E6%88%98%E3%80%8B%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[将之前《Java8实战》笔记 pdf 版本转换为网页博客，方便查看。本文主要体现《Java8实战》书籍的主体结构，具体细节可以翻书查阅。 为什么要关心Java 8Java怎么还在变流处理尽管流水线实际上是一个序列，但不同加工站的运行一般是并行的。 可以在一个更高的抽象层次上写Java 8程序了：思路变成了把这样的流变成了那样的流（就像写数据库查询语句时的那种思路），而不是一次只处理一个项目。 Java 8可以透明地把输入的不相关部分拿到几个CPU内核上分别执行你的Stream操作流水线——这是几乎免费的并行，用不着费劲搞Thread了。 用行为参数化把代码传递给方法Java 8 增加了把方法（你的代码）作为参数传递给另一个方法的能力，把这一概念称为行为参数化。 并行与共享的可变数据没有共享的可变数据，将方法和函数即代码传递给其他方法的能力是我们平常所说的函数式编程范式的基石。 Java中的函数方法和Lambda作为一等公民Java8 的方法引用 :: 语法（把这个方法作为值）。例如：File::isHidden 。Lambda（或匿名函数），例如：（int x）-&gt; x+1 。 流我们把 for-each 循环一个个去迭代元素称为外部迭代，有了 Stream API 数据处理全是在库内进行的，这种思想叫作内部迭代。 函数式编程中的函数的主要意思是“把函数作为一等值”，不过它也常常隐含着第二层意思，即“执行时在元素之间无互动”。 默认方法如何改变已发布的接口而不破坏已有的实现呢？为了解决这个问题，Java 8中加入了接口的默认方法。加入默认方法后，Java有了某种形式的多重继承，Java 8用一些限制来避免出现类似C++中凑名昭著的菱形继承问题。 通过行为参数化传递代码行为参数化就是可以帮你处理频繁变更的需求的一种软件开发模式。 匿名类的不足之处：占用了很多空间，显得很笨重；用起来可能会让人费解。 场景：Comparator排序，用Runnable执行一个代码块，以及GUI事件处理。 Lambda表达式基本语法：12（parameters）-&gt; expression // 表达式（parameters）-&gt; &#123; statements; &#125; // 语句 在需要函数接口的地方可以使用Lambda表达式。 函数式接口就是只定义一个抽象方法的接口。哪怕有很多默认方法，只要接口只定义了一个抽象方法，它就任然是一个函数式接口。 @FunctionalInterface 这个注解表示该接口会设计成一个函数式接口。不是必须的，类似于@Override。 任何函数式接口都不允许抛出受检查异常（checked exception）。如果你需要Lambda表达式来抛出异常，有两种办法：定义自己的函数式接口，并声明受检查异常；或者把Lambda包在一个 try/catch 块中。 引入流Stream API 可以让你写出这样的代码： 声明性——更简洁，更易读 可复合——更灵活 可并行——性能更好 Java 8引入流的理由：Streams库的内部迭代可以自动选择一种适合你硬件的数据表示和并行实现。 Java 8需要一个类似于Collection却没有迭代器的接口，与是就有了Stream! 和迭代器类似，流只能遍历一次。 使用流 筛选和切片filter、distinct、limit(n)、skip(n) 映射map、flatMap 查找和匹配allMatch、anyMatch、noneMatch、findFirst、findAny 归约reduce 构建流由值创建流、由数组创建流、由文件创建流、由函数生成流（创建无限流）函数生成流：iterate、generate 用流收集数据Collectors 类提供工厂方法创建收集器，提供了三大功能： 将元素规约和汇总为一个值 元素分组 元素分区 并行数据处理与性能Java 7引入了一个叫作“分支/合并”的框架，让并行处理数据操作更加稳定，更不易出错。 parallel、sequential 调用会影响整个流水线。 优化性能时，你应该始终遵循三个黄金规则：测量，测量，测量。 很重要的的一点是要保证在内核中并行执行工作的时间比在内核之间传输数据的时间长。总而言之，很多情况下不可能或不方便进行并行化。 记住要避免共享可变状态，确保并行Stream得到正确的结果。 留意装箱。自动装箱和拆箱操作会大大降低性能。 对于较少的数据量，选择并行流几乎从来都不是一个好的决定。 “分支/合并”框架的目的是以递归方式将可以并行的任务拆分成更小的任务，然后将每个子任务的结果合并起来生成结果。它是ExecutorService接口的一个实现，它把子任务分配给线程池（称为 ForkJoinPool ）中的工作线程。 “分支/合并”框架工程用一种称为工作窃取（work stealing）的技术来解决这个问题。每个线程池都为分配给它的任务保存一个双向链式队列，完成任务的线程可以从其他线程任务队列的尾端“偷走”一个任务。 Spliterator（可分迭代器）是Java 8中加入的另一个新接口，可以让你控制划分数据结构的策略。 重构、测试和调试如果你使用了匿名类，尽量使用Lambda表达式替换它们，但是要注意二者间语义的微妙差别，比如关键字 this，以及变量隐藏。 尽量使用Stream API替换迭代式的集合处理。 尽量将复杂的Lambda表达式抽象到普通方法中。 Lambda表达式会让栈跟踪的分析变得更为复杂。 流提供的 peek 方法在分析Stream流水线时，能将中间变量的值输出到日志中，是非常有用的工具。 默认方法Java 8允许在接口内声明静态方法；Java 8引入了默认方法，通过默认方法你可以指定接口方法的默认实现。 引入默认方法的目的：它让类可以自动地继承接口的一个默认实现。 抽象类与抽象接口的区别： 一个类只能继承一个抽象类，但一个类可以实现多个接口。 一个抽象类可以通过实例变量（字段）保存一个通用状态，而接口是不能有实例变量的。 默认方法的使用模式：可选方法和行为的多继承。 多个接口默认方法冲突的解决机制（继承菱形问题）： 首先，类或父类中显示声明的方法，其优先级高于所有的默认方法。 如果用第一条无法判断，方法签名又没有区别，那么选择提供最具体实现的默认方法的接口。 最后，如果冲突依旧无法解决，你就只能在你的类中覆盖默认方法，显示地指定在你的类中使用哪一个接口中的方法。 用Optional取代nullJava 8 中引入了一个新的类 java.util.Optional&lt;T&gt;，对存在或缺失的变量进行建模。 可以使用 Optional 中的 empty、of、ofNullable 创建 Optional 对象。 Optional 类支持多种方法，比如：map、flatMap、filter，它们在概念上与Stream类中对应的方法十分相似。 CompletableFuture 组合式异步编程同步API中调用方在被调用方运行的过程中会等待，异步API会直接返回。 如果你进行的是计算密集型的操作，并且没有I/O，那么推荐使用Stream接口，因为实现简单，同时效率也可能是最高的（如果所有的线程都是计算密集型的，那么没有必要创建比处理器核数更多的线程）。反之，如果你并行的工作单元还涉及等待I/O的操作（包括网络连接等待），那么使用 CompletableFuture 灵活性更好。 CompletableFuture 类还提供了异常管理的机制，让你有机会抛出/管理异步任务执行中发生的异常。 如果异步任务之间相互独立，或者它们之间某一些的结果是另一些的输入，你可以将这些异步构造或者合并一个。 你可以为 CompletableFuture 注册一个回调函数；你可以决定在什么时候结束程序的运行，是等待由 CompletableFuture 对象构成的列表中所有对象都执行完毕，还是只要其中任何一个首先完成就中止程序的运行。 新的日期和时间APIJava 8之前老版的 java.util.Date 类以及其他用于建模日期时间的类有很多不一致设计上的缺陷，包括易变性以及糟糕的偏移值、默认值和命名。 新的日期和时间API中，日期—时间对象是不可变的。 新类包括：LocalDate、LocalTime、Instant、Duration以及Period。 函数式的思考从长远看，减少共享的可变数据能帮你降低维护和调试程序的代价。 如果一个函数使用相同的参数值调用，总是返回相同的结果，那么它是引用透明的。 相对于Java语言中传统的递归，“尾-递”（递归调用发生在方法的最后）可能是一种更好的方式，它开启了一扇门，让我们有机会最终使用编译器进行优化。 函数式编程的技巧高阶函数接受至少一个或多个函数作为输入参数，或者返回另一个函数的函数。Java中典型的高阶函数包括 comparing、andThen、compose。 科里化是一种将具备2个参数的函数f转换为使用一个参数的函数g，并且这个函数的返回值也是一个函数，它会作为新函数的一个参数。例如：1f ( x,y ) = ( g ( x ) ) ( y ) 持久化数据结构在其被修改之前会对自己前一个版本的内容进行备份。 遵守“引用透明性”原则的函数，其计算结构可以进行缓存。 面向对象和函数式编程的混合：Java 8 和 Scala 的比较Java 8 和Scala都是整合了面向对象编程和函数式编程特性的语言，它们都运行于JVM之上，在很多时候可以互相操作。 结论以及Java的未来TODO 附录附录A 其他语言特性的更新重复注解（repeated annotation）、类型注解（type annotation）、通用目标类型推断（generalized target-type inference）。 附录B 类库的更新略 附录C 如何以并发的方式在同一个流上执行多种操作略 附录D Lambda表达式和JVM字节码略]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Java</tag>
        <tag>Java8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02 你的第一个Netty应用]]></title>
    <url>%2F2018%2F02%2F09%2F02%20%E4%BD%A0%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AANetty%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[点击查看 《Netty in Action》笔记目录。 本文是对《Netty in Action》第2章内容的笔记和翻译，主要内容包括： 建立开发环境 写一个回写应用的服务器和客户端 构建和测试程序 搭建开发环境 下载和安装 JDK 下载和安装 IDE 下载和安装 Apache Maven 配置工具集 Netty 客户端和服务器概览图2.1在一个较高的层次展示了将要写的回写客户端和服务端程序。 Echo 程序服务端所有的 Netty 应用服务端都需要以下要素： 至少一个 ChannelHandler：这个组件实现了服务端对接收到的客户端数据的处理，是业务的处理逻辑。 Bootstrapping ：这是配置服务端的启动的代码。它至少会绑定服务端的某个端口，从而监听连接的请求。 ChannelHandlers 和业务逻辑你需要实现 ChannelInboundHandler 接口。这个接口定义了输入事件的响应行为方法。这个简单的应用程序只需要实现这个接口的较少方法，所以继承 ChannelInboundHandlerAdapter 就足够了，这个类可以提供 ChannelInboundHandler 的一个默认实现。 我们将会对以下这些方法感兴趣： channelRead() ：每个数据输入的时候都会调用。 channelReadComplete() ：通知 handler 最近一次 channelRead() 调用处理的是最后一条数据。 exceptionCaught() ：在读数据过程如果抛出异常，则会调用这个方法。 当捕获异常时会发生什么?每个 Channel 都会有一个关联的 ChannelPipeline（它持有了一个链式的 ChannelHandler 实例）。默认情况下, 一个 handler 会将方法调用传递给链中的下一个 hander。因此，如果 exceptionCaught() 在链中没有被实现，那么捕捉的异常会传递到 ChannelPipeline 的末端，并会被日志记录下来。基于这个原因，你的应用至少要提供一个实现了 exceptionCaught() 的 ChannelHandler。 启动服务端服务的启动包括以下几个方面： 绑定服务端将要监听的端口，并且接受将要到来的连接请求。 配置 Channels 来通知 EchoServerHandler 实例即将到来的输入数据。 代码的主要组成部分包括： EchoServerHandler 实现了基本的业务逻辑。 main() 函数负责启动服务器。 在启动过程中需要经历以下步骤： 创建一个 ServerBootstrap 实例来启动和绑定服务。 创建一个 NioEventLoopGroup 实例来进行事件处理，这些事件包括：接受新的连接、读写数据等。 确定本地需要绑定的 InetSocketAddress。 为每个新的 Channel 分配一个 EchoServerHandler 实例。 调用 ServerBootstrap.bind() 来绑定服务。 Echo 程序客户端Echo 客户端将会做以下这些事情： 连接服务端。 发送一条或多条消息。 对于每条消息，等待服务器端发回同样的消息。 关闭连接。 通过 ChannelHandlers 实现客户端逻辑和服务端相同，客户端将会有 ChannelInboundHandler 来处理数据。在这个类中，你将要扩展 SimpleChannelInboundHandler 来处理所有需要的任务，具体如清单2.3所示。这需要覆盖以下的这些方法： channelActive()：当与服务端的连接建立后会被调用。 channelRead0()：当从服务端收到数据后会被调用。 exceptionCaught()：当处理过程中发生异常时会被调用。 需要注意的是，服务器端发送过来的数据可能被分成多个小块。也就是说，如果服务端发送5个字节，那么并不能保证所有的5个字节都被一次收到。 SimpleChannelInboundHandler 对比 ChannelInboundHandler两个方面的考量：业务逻辑是怎么样的、Netty 是如何管理资源的。在客户端，当 channelRead0() 完成的时候, 你将接收并处理完毕输入的数据。当这个方法返回的时候，SimpleChannelInboundHandler 帮助我们释放用于存储消息的 ByteBuf 内存引用。在 EchoServerHandler 中，你还需要将接收到的数据回显给发送端， 并且异步的 write() 在 channelRead() 返回的时候还不一定可以完成（如列表 2.1 所示）。因此，EchoServerHandler 扩展了 ChannelInboundHandlerAdapter, 后者并没有在方法返回的时候释放消息所占用的资源。当 EchoServerHandler 类的 channelReadComplete() 方法中的 writeAndFlush() 被调用后，消息将会被释放（如列表2.1所示）。 启动客户端 你可以在客户端和服务端之间使用不同的传输传输协议。例如，在服务端使用 NIO，在客户端使用 OIO。 客户端和服务端创建的要点总结如下： 创建 Bootstrap 实例来初始化客户端。 创建 NioEventLoopGroup 实例来进行事件处理，这些事件包括：接受新的连接、读写数据等。 创建 InetSocketAddress 来帮助服务端建立来连接。 当连接建立的时候，在流水线中安装 EchoClientHandler。 在所有的事情建立完毕后，将会调用 Bootstrap.connect() 来连接远端。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Netty</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01 Netty — 异步和事件驱动]]></title>
    <url>%2F2018%2F02%2F08%2F01%20Netty%20%E2%80%94%20%E5%BC%82%E6%AD%A5%E5%92%8C%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[点击查看 《Netty in Action》笔记目录。 本文是对《Netty in Action》第1章内容的笔记和翻译，主要内容包括： Java 中的网络使用 介绍 Netty Netty 的核心组件 Netty 是一个基于异步的、事件驱动的网络应用开发框架，可以为频繁的开发和维护提供方便，并为客户端和服务端提供高性能的协议。 Netty 不仅仅是一个网络框架，它的整体架构和设计思想和它的技术内容一样重要. 为此，我们将要讨论以下一些要点： 将关注点隔离（将业务逻辑和网络逻辑进行解耦） 模块化和可重用性 第一需求是系统可以被测试 Java 中的网络编程Java 中传统的网络代码实现如下所示： 上面代码背后的处理模型如下所示： 上面模型的缺点是： 浪费资源：在任何一个时刻，都可能由于等待输入或输出的阻塞，造成很多线程休眠。 很难支持大量数目的线程，因为任何一个线程都需要分配栈内存，而计算机内存是有限的。 线程间的上下文切换会严重影响性能。 Java NIO本地 Socket 库早就已经包含了非阻塞的调用方式。通过这些方法，我们可以对网络资源的使用进行更加多的控制。 通过使用 setsockopt()，你可以配置 Socket，使得当没有数据的时候，读写调用可以马上返回。 你可以注册一系列的非阻塞 Socket，并通过系统的事件通知 API 来了解读写的数据是否已经准备好。 2002年的时候，Java 组织在 JDK 1.4 版本中的 java.nio 包中引入了非阻塞的 IO（non-blocking I/O）。 新 IO 还是非阻塞 IO ?NIO 一开始是 New Input/Output 的缩写, 但是 Java API 已经存在很长的时间了，它已经不再被认为是新的 API 了。很多使用者认为 NIO 带表了非阻塞 IO（non-blocking I/O），而原来的阻塞 IO（blocking I/O）则被认为是 OIO 或 old input/output。 Selectorsjava.nio.channels.Selector 类是 Java 非阻塞 IO 实现的核心，它使用了事件驱动 API 来表明哪些非阻塞 sockets 已经准备好可以进行 I/O 了。下图展示了：在这样的模型下，一个单线程可以处理多个并发的连接。 和阻塞型 IO 模型相比，这样的模型提供了更好的资源管理： 连接可以被更少的线程支持，因此在内存管理和上下文切换上有更少的开销。 当本任务没有 IO 处理的时候，线程可以重新绑定到其它任务上。 Netty 介绍直接使用相对原生的 API，会增加开发的复杂度，并要求开发者具备很高的开发技能，但这样的人才还是很紧缺的。因此，需要采用一个面向对象的基本思想： 隐藏复杂的实现，提供简单的抽象. table th:first-of-type { width: 15%; } Netty 的特性总结: 类别 Netty 特性 设计 对多种传输类型统一了 API，包括阻塞和非阻塞。简单但高效的线程模型。支持无连接数据报套接字。逻辑组件的连接，支持组件重用。 易用性 完善的 Javadoc 以及大量使用实例。只需要依赖 JDK 1.6+。（一些可选的特性依赖 JDK 1.7+ 或者一些额外的依赖) 性能 和 Java 本身的 API 相比，具备更高的吞吐量和更低的延时。通过池化和重用，减少了资源的消耗。最小化内存拷贝。 鲁棒性 不会由于连接的快、慢、负载较大而导致 OutOfMemoryError。在高速网络场景中，消除了 NIO 应用程序典型的不公平读写比。 安全性 支持 SSL/TLS 、StartTLS。在 Applet 或者 OSGI 等资源受限环境中也可以使用。 社区驱动 发布频繁和活跃。 异步和事件驱动的优点： 非阻塞的网络调用，使得我们从等待操作完成的过程中解放出来。基于这个特性的异步 IO 使得我们可以实现：异步方法立即返回，当完成的时候可以立刻或者稍后通知我们。 Selector 允许我们通过更少的线程来监控更多的连接和事件。 Netty 的核心组件在这一节，我们要讨论 Netty 主要的构建模块： Channels Callbacks Futures Events 和 Handlers 这些构建模块代表了不同类型的构建要素: 资源、逻辑和通知。应用程序将会通过这些模块来访问网络和数据。 ChannelsChannel 是 Java NIO 的基本构成。它表示： 与实体间打开的一个连接。这些实体包括：一个硬件设备、一个文件、一个网络 socket、或者一个程序组件，它们可以进行不同的 I/O 操作，例如：读写操作。 Channel 可以被打开、关闭、建立连接、取消连接。 CallbacksCallback 是一个回调方法, 本质上是指向其它方法的一个引用。通过回调可以实现：在合适时，调用指向的函数。 Netty 内部使用 callbacks 来处理事件。当 callback 被触发，事件可以被对应的 ChannelHandler 接口实现来处理。下面的图片展示了这样的一个例子：当一个新的连接建立后，ChannelHandler 会回调 channelActive() 方法，该方法将会把消息打印出来。 FuturesFuture 提供了另一种通知机制来让应用知道操作已经完成。 JDK 中提供了 java.util.concurrent.Future 接口，但是提供的实现实现只能允许你：手工判断操作是否完成、或者阻塞到操作完成。这样的机制不是很方面，所以 Netty 提供了自己的实现 ChannelFuture，它可以实现异步操作的执行。 ChannelFuture 提供了一个额外的方法，可以允许我们注册一个或多个 ChannelFutureListener 实例。这些监听者的回调函数 operationComplete() 会在方法完成时被调用。 Netty 的每个输出 I/O 操作会返回一个 ChannelFuture，也就是说，这些输出操作是非阻塞的，会立即返回。 下例中 ChannelFuture 作为 I/O 操作返回的一部分。其中 connect() 将会没有阻塞立即返回，而调用的方法会在后台完成。 下例展示了如何使用 ChannelFutureListener。 ChannelFutureListener 是一个更加完善的 callback。事实上，callbacks 和 Futures 是互补的，它们是 Netty 的一个重要组成部分。 Events and handlersNetty 使用不同的事件来告知我们：状态的改变、操作处于哪个阶段。 对应的行为可能包括： 日志 数据传输 流控 应用逻辑 Netty 是一个网络框架，所以事件可以根据它们在输入还是输出流进行区分。 输入数据或者输入相关状态改变的事件包括： 连接的有效和无效 数据读取 用户事件 错误事件 输出事件是相关操作的返回结果，它将会在未来的某个时刻被调用，包括： 打开或者关闭一个远程连接。 在一个 socket 中写入或者刷新数据。 目前，你可以把每个 handler 实例看做是针对特定的事件（event）的一个回调（callback）。 结合以上要素Futures、Callbacks、HandlersNetty 的异步编程模型是基于 Futures 和 callbacks 建立的, 而将事件分发到对应的处理 handler 这样的操作是封装在 Netty 内部较深层次的。总而言之，这些元素提供了一个处理环境：可以使得应用的业务逻辑和网络的具体操作进行解耦。这是 Netty 设计的根本目标。 只要提供 callbacks 或者使用操作返回的 Futures，就可以实现在程序运行时拦截操作和转移输入输出数据。这使得链接操作变得非常容易和高效，并能促进写可重用、泛化程度更高的代码。 Selectors、Events、Event Loops在内部，EventLoop 被绑定到每个 Channel 上，来处理所有的事件（events），包括： 重新注册感兴趣的事件 分发事件到 ChannelHandlers 调度下一步的响应 EventLoop 本身只被一个线程驱动，处理所绑定的 Channel 的所有 I/O 事件，并且这种关系在 EventLoop 的生命周期中不会改变。 这个简单和强大的设计可以消除你对同步 ChannelHandlers 的担心。]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Netty</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 9，OSGi和模块化的未来（2）]]></title>
    <url>%2F2018%2F02%2F06%2FJava-9%EF%BC%8COSGi%E5%92%8C%E6%A8%A1%E5%9D%97%E5%8C%96%E7%9A%84%E6%9C%AA%E6%9D%A5%EF%BC%882%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Java 9 中一个重要的新特性就是模块化。它的实现机制是什么那？它和已有的模块框架OSGi有什么差异那？为了回答这些问题，本人在网上找到了一篇比较好的介绍文章，为了加深理解，对文章进行了翻译。由于原文分为2个部分，所以翻译对应也分为2篇： 1）《Java 9，OSGi和模块化的未来（1）》是对《Java 9, OSGi and the Future of Modularity (Part 1)》的翻译，文章日期为2016年9月22日。介绍的内容包括：背景、高层次比较、复杂性、依赖粒度对比、模块导出对比、模块导入对比、反射和服务。 2）《Java 9，OSGi和模块化的未来（2）》是对《Java 9, OSGi and the Future of Modularity (Part 2)》的翻译，文章日期为2016年10月4日。介绍的内容包括：动态性、二者协同工作、未来发展、结论。 本文是对原文第二部分的翻译。 引言关键点 Java 9 在2017年发布，其中一个重要的特性就是新的模块化系统，被称作Java平台模块系统（Java Platform Module System，JPMS）。本文将介绍它与Java已有的模块标准化机制OSGi的关系，以及对OSGi的影响。 自1.0版本以来Java平台已经增长了20倍，整个平台存在着模块化的需求。为了解决这个问题，进行了很多不成功的尝试。与之相对的是，OSGi已经提供了16年的应用模块化服务。 OSGi和JPMS在实现细节上差别很大。如果将JPMS作为模块化的一般解决方案，会存在一些重大的缺陷，并且缺少OSGi的一些特性。 JMPS的目标是比OSGi更简单和更容易，但是对一个非模块化的产品进行模块化设计本身就是一件很复杂的事情，JMPS看起来好像还没有实现这个目标。 JMPS在对Java平台本身的模块化方面做得非常好，这意味着我们可以在运行时只加载和任务相关的Java平台组件。对于应用模块化，OSGi有很多的优点。我们已经证明这两者可以很好地结合在一起。 这篇文章是“Java 9, OSGi and the Future of Modularity”文章系列的第二部分。第一部分请查看《Java 9, OSGi and the Future of Modularity (Part 1)》。 本文将继续深入了解OSGi和JPMS（Java Platform Module System），其中JPMS会作为Java 9的一个组成部分。在上篇文章中，我们在一个较高的层次比较了这两个模块化系统，讨论了它们是如何解决模块间的隔离性的。我们研究了依赖关系是如何建立的，并且我们探讨了一些关于反射的问题。本文作为第二个部分，将探讨版本管理、模块动态加载以及二者潜在的协同工作可能性。 版本管理版本管理是所有软件交付的一个关键点。API和实现都会改变，所以无论何时我们依赖它们，我们都隐含地依赖于它们在某个时间点的存在。任何模块系统必须能够处理这个现实，通常用显式的版本来指明依赖关系。 然而并非所有的改变都具有同样的破坏性。如果我们使用了版本为1.0.0的模块的来构建和测试我们的软件，那么当我们部署版本1.0.1或1.0.5时，我们有可能可以继续工作，但是如果部署的是版本2.0.0或版本5.2.10，那么不能工作的可能性较大。这表明模块系统需要了解并支持兼容性范围。 OSGi一直支持这些概念。Bundle在导出包时标注了版本号。在导入包的时候指明了版本范围，通常使用闭开区间来表示这个范围，例如“[1.0.0, 2.0.0)” 表示版本介于1.0.0和2.0.0之间，不包括2.0.0。OSGi使用语义版本控制，与流行的语义版本规范完全一致（尽管OSGi早于那些规范）。大致来说，版本号的第一段是主版本号，表示功能和API的重大变化，第二段是次版本号，表示功能的增强，第三段表示增加了一些补丁。 OSGi的开发者不需要推理或显式地声明这些版本范围。和 import 一样，版本范围可以在构建时期根据依赖情况自动构建。例如，如果我们仅需要使用一个API包，那么我们可以提供一个比较宽的区间，如“[1.0.0, 2.0.0)”，这个区间包含了最小和最大版本号之间的所有版本。但是如果我们是提供一个服务接口的实现，那么我们需要使用较窄的区间来导入依赖，例如“[1.0.0, 1.1.0)”，意味着包含1.0.0和这个区间内的，但是不包含1.1.0。这里的不同点在于，一个支持1.0.0的服务提供者无法支持1.1.0，因为增加的版本号表明有新的功能被添加了进来，而提供者无法自动提供新的功能。另一方面，一个服务消费者，可以方便地使用1.1.0和1.2.0等版本号，因为它可以忽略新增加的功能。 除了生成导入范围外，OSGi构建工具（bnd）还可以帮助获得导出包的正确版本。版本号是包的一个属性，它可以直接写在包中（通过在 package-info.java 文件中添加 @Version 注解）。当包中的内容改变的时候，一件很重要的事就是修改这个版本号，例如：当我们在服务接口中增加了一个方法时，我们需要将版本号从1.0.0增加到1.1.0。构建工具检查版本号是否准确地反映了所做更改的性质。例如，当我们添加了方法而忘记修改版本号的时候，构建将会失败，或者我们只是将版本号增加为1.0.1的时候也会如此。 最终，OSGi具有这样的灵活性：可以在单个应用程序中同时部署模块的多个版本。这种情况会在这样的场景出现：通过传递依赖我们引用了一些通用库的不同版本，如 slf4j 或 Guava。还有一些限制是：我们不能直接在单个模块中导入包的多个版本，但是在真正需要的时候，具备这样的能力还是很有用的。 与之相对的是，JPMS对版本控制基本没有任何支持。 在 module-info.java 中没有办法为一个模块指明版本。在 module-info.class 文件中存在一个版本属性，但是它并不是来自于 Java 代码，目前还不清楚它在实际中该如何使用。依赖声明同样没有版本：JPMS模块只能通过名字来 require 其它模块，无法指明版本，当然更无法指明版本的范围。这些特性需要由外部工具添加，但这种方法是受限的，因为 module-info.java 源文件是不可扩展的，并且在该文件内也无法使用 Java 注解。 JPMS的需求规定：在运行时选择兼容的版本不在支持范围内。这意味着其它工具将不得不做这项工作，但没有合适的元数据它们无法完成这项工作。将版本元数据存储在与基本模块元数据相同的描述符中是很自然的，但这是不可能的。 正如我们提到的一样，JPMS中禁止在运行时同时包含一个模块的多个版本。此外，它禁止多个模块导出相同的包，甚至禁止重复的私有包。因此，无论其它工具使用什么方法来构建一个有效的模块集合，都需要找到一个解决转递依赖冲突的方法。在很多案例中，一个简单的“方法”是：在多个模块共同存在的场景下，禁止一些模块的使用。 动态性OSGi基于类加载的隔离实现方案有一个不错的用处：可以支持模块在运行时被动态加载、更新和卸载。这在企业环境中似乎并不重要，事实上大多数OSGi企业在部署中都不会使用动态更新。的确，OSGi没有要求你一定要使用动态更新！ 但是动态更新在其它环境中是非常有用的，比如物联网。在数千台甚至数百万台设备上，通过缓慢或断断续续的网络更新软件是一件让人头痛的事情。OSGi是少数技术之一，可以在任何平台上直接支持使用最少数据量进行即时更新：我们只需要发送实际更改的模块。 最初在2000年，电信运营商在家庭网关和路由器上使用OSGi构建智能家居解决方案的主要原因之一是：能够在不进行固件更新的情况下管理软件。固件更新不吸引人的原因有很多：下载固件更新通常需要下载兆字节的软件到潜在的数百万设备上；固件是针对设备设计的，因此你可能会有许多不同的更新来创建和管理部署；测试固件更新需要大量的、耗时的、昂贵的压力测试，每次都要对每个设备执行这个测试。OSGi显著简化了这个过程；更新可以应用在模块中，并快速安装在运行的网关和路由器上，不需要重启；同样的模块可以在所有设备上使用（通常是底层硬件设备的抽象），重要的是，单元测试可以在更小的软件集上执行，节省大量的时间、精力和金钱。一个具体的例子是 Qivicon，它是一个由德国电信公司成立的行业联盟。Qivicon 提供家庭网关，包括：基于OSGi的软件栈，后端基础设施、应用程序开发工具以及维护和支持。通过使用OSGi来搭建基础生态系统的方法，使得Qivicon的合作伙伴能更快地将智能家居产品推向市场。 Qivicon 合作伙伴不断整合新设备和开发新的创新增值服务。这需要复杂的设备管理和软件供应能力，以确保针对特定设备平台的软件组件的依赖性和兼容性管理。通过利用现有的工业标准（如 TR-069 和 OMA-DM），这些功能已经被写入OSGi标准规范中了。 此外，动态行为不仅仅体现在软件更新上。 OSGi服务注册表本质上是动态的。服务可以注册和卸载，与之绑定的相关组件也会在收到事件通知。服务允许真实世界不断变化的状态被表示和通知。即使在相对稳定的企业应用领域，这也是相关的。例如，OSGi服务可以表示外部数据输入是否可用，或者是REST服务的负载均衡IP地址，甚至是金融市场的开放时间。每个消费服务的组件可以决定服务不可用时的反应行为：可以继续，或者注销自身提供的服务。因此，状态的变化被可靠地传播到任何有影响的地方。 协同工作与未来发展JPMS会在Java 9中发布。目前有非常多的应用程序是用OSGi写的，同时还有很多代码正在被书写。这些代码是安全的吗？它们是否需要在JPMS平台上重新被改写？ 首先需要明确地是：OSGi应用可以不用修改代码继续在Java 9上运行，因为它没有使用不被支持和内部的Java API。对于其他的Java应用代码也是如此。OSGi只使用了被支持的Java API，并且Oracle承诺Java 9不会使这些应用奔溃。你在使用Java 9时遇到的问题可能是来自一些使用了JDK内部类型的类库，因为这些类型在Java 9中无法被访问，除非通过特殊的配置标志进行访问。OSGi的用户将能更好地应对这个改变，因为它们的模块具有显式的依赖列表。通常，Java应用会在类路径上放置多个Jar包，与它们相比，基于OSGi的应用对于平台依赖的范围会更加清晰。 一个最基本兼容模式是，OSGi框架和bundle会存在于JPMS的“未命名”模块中。OSGi还会继续提供所有已经存在的隔离性特性，包括它功能强大的服务注册和动态加载能力。你对OSGi的投资是安全的，而且OSGi仍然是新项目的一个好选择。 但我们希望能比这做得更好。当OSGi运行在已经模块了的Java 9平台上时，我们应该能够充分利用平台中的模块。例如，可以为一个OSGi bundle声明它依赖的平台模块，这意味着一个OSGi bundle可以直接依赖一个JPMS模块。OSGi框架应该关注那些运行时的依赖，并且工具应该能够根据这些依赖准备运行时环境。 此时事情已经看起来很不错了。在我2015年11月的一篇博客中，我对这个概念进行了验证性描述，在JPMS上构建并运行了OSGi程序。我详细介绍了如何让OSGi bundle在基础平台的JPMS模块中声明依赖。我展示了OSGi是如何拒绝这样的一个bundle：它依赖的JPMS模块不在平台中。我没有在运行时提供一个工具原型，但是通过所有描述的部分已经可以构建这样的一个工具了。 图3描绘了未来两个机制可以如何一起工作。我们可以看到：Bundle A 导入了包 javax.activation，这个包来自JPMS中导出的 javax.activation 模块。交互层知道平台中包含了这个模块，会运行OSGi来处理它。当Bundle A迁移到Java 9上时，并不需要做任何改变。Bundle B使用了 java.net.http 包，这个包来自JPMS的 java.httpclient 模块，但是它无法在OSGi中Import-Package部分进行声明，因为它是以 java. 开头的（需要注意的是，所有的 bundle 和 moudle 都隐含地依赖 java.base）。 因此，我们提出了一个新的OSGi头部，称作“Require-PlatformModule”，它用来表示对JPMS中模块的依赖。这样当Bundle B没有包含 java.httpclient module 模块的时候，OSGi框架能够在Bundle B中“快速失败”。这同时还可以使得工具能够为应用构建一个完整的运行时环境，这个环境是JPMS中的 modules 和OSGi中的 bundles 的最小集合。 再次声明，这个工作是一个非官方的概念证明。最终，OSGi如何和JPMS进行交互将由规范来处理。 结论JPMS，通过Jigsaw原型项目，对Java平台本身的模块化工作是非常出色的。通过这个工作，可以构建更小的运行时环境，只需要包括Java平台中任务依赖的部分。 然而作为应用的模块化规范，JPMS存在严重的缺陷。缺少对版本控制的支持是一个令人震惊的遗漏，而且在没有外部工具提供额外元数据的情况下，很难在构建应用程序的过程中实现版本管理。整个模块（whole-module）依赖声明形式将会导致获得更多的传递依赖项，这将削弱它们迁移到更小平台的能力。无法通过反射来获得未导出模块中的类型，这样将会无法使用Java生态系统中已有的一些框架。 这些设计对于JDK本身来说可能是合适的：这增加了平台的健壮性和安全性，同时没有破坏所有Java应用的向后兼容性。但是它们的做法只是一种折中，对于应用的模块化来说，这个设计很不友好。 所以OSGi的未来看起来是光明的：通过将OSGi和整理过的模块化Java平台相结合，我们可以使这两个生态都获得更好的发展。OSGi已经具有了16年的经验，并且遇到和解决了JPMS还没有考虑过的问题。OSGi的开发工具和运行时生态是广泛和深入的。在一个长期有效、独立的标准机构的支持下，它的未来是得到保障的。你还在等什么那？]]></content>
      <categories>
        <category>模块化</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>模块化</tag>
        <tag>翻译</tag>
        <tag>OSGi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 9，OSGi和模块化的未来（1）]]></title>
    <url>%2F2018%2F02%2F05%2FJava-9%EF%BC%8COSGi%E5%92%8C%E6%A8%A1%E5%9D%97%E5%8C%96%E7%9A%84%E6%9C%AA%E6%9D%A5%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Java 9 中一个重要的新特性就是模块化。它的实现机制是什么那？它和已有的模块框架OSGi有什么差异那？为了回答这些问题，本人在网上找到了一篇比较好的介绍文章，为了加深理解，对文章进行了翻译。由于原文分为2个部分，所以翻译对应也分为2篇： 1）《Java 9，OSGi和模块化的未来（1）》是对《Java 9, OSGi and the Future of Modularity (Part 1)》的翻译，文章日期为2016年9月22日。介绍的内容包括：背景、高层次比较、复杂性、依赖粒度对比、模块导出对比、模块导入对比、反射和服务。 2）《Java 9，OSGi和模块化的未来（2）》是对《Java 9, OSGi and the Future of Modularity (Part 2)》的翻译，文章日期为2016年10月4日。介绍的内容包括：动态性、二者协同工作、未来发展、结论。 本文是对原文第一部分的翻译。 引言关键点 Java 9 在2017年发布，其中一个重要的特性就是新的模块化系统，被称作Java平台模块系统（Java Platform Module System，JPMS）。本文将介绍它与Java已有的模块标准化机制OSGi的关系，以及对OSGi的影响。 自1.0版本以来Java平台已经增长了20倍，整个平台存在着模块化的需求。为了解决这个问题，进行了很多不成功的尝试。与之相对的是，OSGi已经提供了16年的应用模块化服务。 OSGi和JPMS在实现细节上差别很大。如果将JPMS作为模块化的一般解决方案，会存在一些重大的缺陷，并且缺少OSGi的一些特性。 JMPS的目标是比OSGi更简单和更容易，但是对一个非模块化的产品进行模块化设计本身就是一件很复杂的事情，JMPS看起来好像还没有实现这个目标。 JMPS在对Java平台本身的模块化方面做得非常好，这意味着我们可以在运行时只加载和任务相关的Java平台组件。对于应用模块化，OSGi有很多的优点。我们已经证明这两者可以很好地结合在一起。 这篇文章是“Java 9, OSGi and the Future of Modularity”文章系列的第一部分。第二部分请查看《Java 9, OSGi and the Future of Modularity (Part 2)》。 当Java 9发布的时候，其中一个重要的特性就是模块化：Java平台模块系统（Java Platform Module System，JPMS）。虽然JPMS的具体细节还不是很清楚，但我们已经对其基本内容有了一定的了解。 从2000年开始，Java中的模块系统就以各种形式存在了。其中一个比较著名的模块化系统叫做OSGi，这是一个独立于供应商的行业标准，由OSGi联盟制定。OSGi联盟由领先的软件供应商、电信公司和其他组织组成，包括：Adobe、Bosch、Huawei、IBM、Liferay、NTT、Oracle、Paremus、Software AG。它几乎能够支持所有的Java EE应用服务器、最流行的IDE、web应用（eBay、Salesforce.com、Liferay），并且它也被政府和军方使用（the U.S. Air Force、Federal Aviation Administration）。 OSGi适用于IoT（物联网）。一开始，OSGi是为嵌入式系统设计的。在几年前，这些系统的内存和CPU资源都是很有限的。现在，这些设备具备更多的资源，这为构建复杂的应用系统提供了机会，并且催生一大批企业和个人对软件和硬件进行着贡献，形成了一个生态。这样的生态系统存在于多个市场，包括：智能家居联网、车联网、智慧城市、工业4.0（IIoT）。此外，网关常用于传感器与设备、设备与后端系统的互联。应用和服务可以在本地网关运行，也可以在云端运行。 OSGi提供了很多规范，从而使得构建开放物联网生态的基本特性能够实现。这些特性包括：设备管理、软件配置、对设备的底层通信协议进行抽象。一些公司，包括：AT&amp;T、Bosch、NTT、Deutsche Telekom、General Electric、Hitachi、Miele、Schneider Electric等，在构建IoT解决方案的时候，可以通过使用OSGi技术获得更好的收益，而这也有段时间了。通过OSGi和IoT，现在已经是万物互联的社会了。 当然，OSGi使用者比较关注的是：Java 9中的模块化系统会对OSGi造成什么影响，包括短期和长期。 由于技术、政治、经济等原因，Java生态中存在了两个模块系统。在这篇文章中，我们避开了政治的原因，从技术的角度进行了比较。我们描绘了一个JPMS和OSGi一起工作的场景，在这个场景中，它们有各自擅长的领域和机会。 需要注意的是，本文使用了截至2016年8月能够获得的公开信息，有些细节可能在规范最终出来之前还会更改。 背景Java平台从1990年代开始迅速发展。从下载大小来看，JDK 1.1的大小在 10Mb 之内，而 Mac OS X 平台下载的JDK 8u77 达到了227M。安装空间和内存需求也相应需要增加。Java平台扩大是由增加新特性驱动的，这些特性的大部分都是受欢迎和有用的。但是，平台中的每个新功能都会给不需要它的用户造成膨胀，并且没有人会使用到全部的特性。此外，为了使Java具备向后的兼容性，其中一些特征在废弃之后仍会被保留。 很多年来，Java平台变大并不是一个大问题。Java是最受欢迎的企业级平台，并且它的竞争对手（微软的 .NET）也和Java有着相似的发展轨迹。但是，现在Java面临了不同的挑战。IoT的发展使得空间占用被重新关注了起来，并且一些新的灵活的平台和语言（如Node.js、Go）也是非常厉害的竞争对手。 此外，安全同样是一个大问题：为了避免来自Java的攻击，有安全意识的组织会从用户桌面完全删除它。如果JVM内部和用户空间的应用代码有更好的隔离性，那么很多攻击可能就不会发生。 很长一段时间来，大家都很明确的是：需要对Java平台进行一些模块化工作。在2000年代中期，有过一些努力，但是都没被采用，包括JSR 294和它的“superpackages”、JSR 277的“Java Module System”。最终，一个称为 Jigsaw 的原型项目出现了。这本来打算在2011年的Java 7中发布的，但是后来推迟到了Java 8，接着又被推迟到了Java 9。作为一个原型工程，Jigsaw 为 JPMS 规范提供了实践参考。 与此同时，OSGi已经发展和改进了16年。OSGi是应用模块化的标准，由于它不是Java平台本身的一部分，所以它不能影响平台本身的模块化。但是另一方面，许多应用程序都得益于它在JVM级别之上提供的模块化模型。 高层次比较JPMS和OSGi之间在细节上有很多不同点，但是它们之间最大的区别在于：实现隔离的方法。 对于任何一个模块化系统，隔离性都是最基本的特性。必须有一些方法来保护每个模块不受同一应用程序中其它运行模块的干扰。隔离并不是一个二元概念（隔离或不隔离），OSGi和JPMS都不能阻止一个模块干这些“坏事”：耗尽JVM中的可用内存、启动数千个线程、通过忙循环挂起CPU。将模块运行在OS独立的处理器中可以提供一些隔离保护，但是即使这样也不是万无一失的，一些人仍旧可以使OS奔溃或者擦除磁盘中的数据。 OSGi和JPMS提供的都是代码级别的隔离，这意味着一个模块不能随意访问另一个模块内部的类型，除非有另一个模块的显示允许。 OSGi通过类加载器来实现它的隔离性。每个模块（OSGi中的术语是“bundle”）有它自己的类加载器，这些类加载器知道如何加载bundle中的类型。此外，也可将类加载的请求委托给依赖的bundle。OSGi的系统是高度优化的，例如：OSGi直到bundle真正需要被使用的时候才会创建类加载器；并且事实上每个类加载器只需要加载部分类型，这也意味着加载速度可以有所提高。 这个系统有一个很大的优点是，多个bundle可以包含重复的包和类型，并且这些元素不会相互干扰。实际的效果是：可以同时在一个虚拟机上运行包或库的多个版本。当使用构建工具（例如 Maven）时，这个模块化机制有助于处理复杂的传递依赖。在很多企业级Java应用中，几乎不可能实现应用的每个依赖里面使用的都是同一个版本的类库。 例如，我们看一下JitWatch库。JitWatch 依赖 slf4j-api 1.7.7、logback-classic 1.1.2，但是 logback-classic 1.1.2 依赖 slf4j-api 1.7.6，与 JitWatch 直接依赖的版本发生了冲突。JitWatch 同样传递依赖 jansi 的1.6和1.9版本，并且如果我们包括测试域的依赖，我们还会依赖另一个1.6版本的slf4j-api。这种混乱状况非常常见，传统的Java并没有真正有效的解决办法，除了在依赖树上逐渐添加“excludes”，直到我们可以奇迹般地让一堆依赖工作。但不幸的是，JPMS对此还没有确切的解决方案，等Java 9发布后我们就可以看到是否如此。 正是这个缺点阻止了OSGi被用来模块化JDK本身。JDK的很多部分都有一个隐含的假设就是：任何一个JDK类型都可以从JDK的其它部分中加载进来。因此，如果使用类似OSGi的模型的话，很多事情都无法完成。为了解决这个问题，同时为了可以轻松地从使用 Class.forName 的代码迁移过来，JPMS并没有全部选用类加载机制来实现模块的隔离。当你启动了一个应用，并且使用了“modulepath”下的一些模块，那么这些模块会被同一个类加载器加载。JPMS引入了一个新的访问机制来实现这个目标。 这个隔离栅栏在OSGi中被称为可见性。在OSGi中，我们不能加载模块内部的类，因为这在外部是不可见的。这也意味着，我模块的类加载器只能看到我自己模块内的类型、以及从其它模块明确引入的类型。如果我尝试从你的模块中加载一个类，我的模块是无法看见那些类型的，看起来好像那些类并不存在一样。如果我无论如何一定要加载那些类的话，会得到 NoClassDefFoundError 或者 ClassNotFoundException 。 在JPMS中，每个类型可以看到其它任何类型，因为它们都在一个类加载器中。但JPMS增加了额外的检查，从而确保尝试加载的类有正确的访问权限。其它模块中的内部类型实际上是私有的，即使被声明为 public。我们如果强制要加载的话，会得到 IllegalAccessError 和 IllegalAccessException。加载其它模块中的私有类型和默认类型也会得到同样的错误，并且调用 setAccessible 这样的函数是没有作用的。这改变了Java中public的语义，原先意味着任何地方都可以访问，现在意味着只有在模块内部或者声明了require的地方才可见。 JPMS这种做法的缺陷是：不能实现多个模块都加载重叠的内容。这意味着，如果两个模块都包含一个私有（没有导出）的包 org.example.util，那么这些模块不能在模块路径下被同时加载，这会导致 LayerInstantiationException。虽然我们可以在自己的应用中创建类加载器来绕过这个限制，但是OSGi已经为我们实现了。 这完全是通过设计，来使得JPMS可以对JDK内部进行模块化。但是这样造成的影响是，你不能让内部实现细节冲突的模块一起工作。 复杂性关于OSGi，大家经常抱怨的一点是：它增加了开发复杂度。这有一些道理，但是提出这些抱怨的人可能没有完全弄清状况。 模块化并不是一个神奇到只要在发布前一刻添加上去就能使用的技术。它是一个必须贯穿于设计和开发的所有阶段的理念和原则。如果开发者较早采用OSGi，或者在开发前就已经考虑了模块化设计，那这会有很多益处。并且他们会发现，OSGi实际上非常简单，尤其是还可以使用先进的OSGi工具，这些工具可以帮助开发者自动生成元数据，并可以在运行前检查出一致性方面的错误。 另一方面，那些想要在现有大型项目中使用OSGi的人之所以遭受痛苦，是因为那些代码很少有良好的模块化设计，这会导致迁移工作很困难。如果没有强制性的模块化开发原则，那么很容易导致这样的情况：为了开发方便而破除封装性。一个BEA WebLogic的开发人员告诉我，在BEA被Oracle收购之前：“我们一直以为我们的产品是模块化设计的，但是当我们开始使用OSGi时，我们改变了之前的看法。” 除了非模块化的应用之外，非模块化的库也阻碍了OSGi的使用。一些非常流行的Java库都基于类加载机制和全局可见性的假设，而这些假设在模块化结构中不能成立。OSGi为了能够使用这样的类库做了很多工作，而这也是OSGi显得复杂的原因之一。事实上，我们需要一些复杂的技术来处理混乱的局面，因为真正复杂的是现实世界。 在JPMS下也会出现同样的问题，可能更多，我们很快就会看到。如果你所在的组织之前曾尝试采用OSGi，但是因为迁移的工作量而放弃，那么你们如果打算迁移到JPMS的话，工作量至少会同样多。你只需看看Oracle对JDK进行模块化的经验：工作量是如此之大，以至于Jigsaw从Java 7被推迟到Java 8，之后又被推迟到了Java 9，即使Java 9已经延迟一年发布了。 Jigsaw是以简洁性为目标开始的，但是JPMS规范已经变得越来越复杂：模块与类加载器的相互作用、分层与配置、再次导出依赖、弱模块、静态依赖、规范的导出、动态导出、跨层的读可继承性、多个Jar包的多个模块、自动化模块、未命名模块，等等。这些所有的特性都被添加到规范中去了，因为它们需要被清晰地说明。OSGi也发生了相似的过程，只是领先了16年而已。 依赖：包 vs 模块隔离只是完成了模块化难题的一半，另一半是：模块需要一起协同工作。在构建了模块之间的隔离之后，我们还需要引进一个可以控制的交流机制。这个可以在类型级别静态实现，也可以通过对象动态实现。 静态依赖是指那些在构建时期就能被知道和控制的部分。如果需要穿过模块的边界访问一个类型，那么模块需要提供一种提供类型可见性和访问控制的方法。这包括两个方面：模块需要选择性地暴露一些它们封装的类型，并且它们需要明确指出需要使用其它模块中的哪些类型。 导出：Exports在OSGi和JPMS中。暴露类型的粒度都是基于Java包的。在OSGi中，我们使用 Export-Package 声明，它可以确切表明哪些包是可以被其它模块可见的。示例如下：12Export-Package: org.example.foo; version=1.0.1, org.example.bar; version=2.1.0 这个声明在 META-INF/MANIFEST.MF 文件中。在早期，一些OSGi开发者需要手动地配置这些声明，但是逐渐地，我们更喜欢使用构建工具来生成。目前最流行的模式是在Java源代码中使用注解。在Java 5中 package-info.java 被引入，并且允许包级别的注解和文档，所以在OSGi中我们可以有以下写法：12@org.osgi.annotation.versioning.Version(&quot;1.0.1&quot;) package org.example.foo; 这是一个有用的模式，因为导出包的意图可以直接在该包中表示。版本号也可以在这里声明，而且当包中内容发生变动时，也很容易在附件进行修改。 在JPMS中，包导出声明是在 module-info.java 文件中，举例如下：1234module A &#123; exports org.example.foo; exports org.example.bar;&#125; 需要注意的是：在JPMS中，模块和包都无法标注版本号。这部分内容我们之后会再次讨论。 导入：Imports/RequiresOSGi和JPMS在模块导出的部分很相似，但是它们在导入或者依赖其它模块的部分差异很大。 在OSGi中，导入包和导出包是互补的。我们使用 Import-Package 声明来导入包，例如：12Import-Package: org.example.foo; version=&apos;[1,2)&apos;, org.example.bar; version=&apos;[2.0,2.1)&apos; 导入的规则是：OSGi的bundle需要导入每个依赖的包，除了以 java.* 开始的包（例如，java.util）。具体来说，如果bundle中的代码依赖了类型 org.slf4j.Logger (并且bundle中没有包括 org.slf4j 包)，那么这个包需要在导入列表中标明。同样，如果你依赖 org.w3c.dom.Element，那么你必须导入 org.w3c.dom。但是如果你需要依赖 java.math.BigInteger 的话，你不需要导入 java.math，因为 java.* 的包是由 JVM 的 bootstrap 类加载器加载的。 OSGi存在并行机制来导入所有的模块，被称作 Require-Bundle，但是这个在OSGi规范中已经废弃了，存在也只是为了支持一些非常稀少的边缘案例。Import-Package 机制的最大优点是：可以在不影响下游模块的情况下，实现模块的重构和重命名。图1和图2对此进行了说明。 在图1中，模块A被重构为两个模块，A和A’，但是模块B没有受到这个操作的影响，因为它依赖的是包。在图2中，我们对A进行了同样的操作，但是现在B奔溃了，因为它可能使用的包在A中不再存在了（这里说“可能”是因为我们无法知道B使用了A中哪些部分，因为我们只说明了依赖的模块，这就是问题所在）。 Import-Package 声明手动书写很麻烦，所以我们并没有这么做。OSGi工具可以通过检查bundle中编译类型的依赖来生成它。这是非常可靠的，比开发人员自己声明运行时依赖要可靠得多。当然，开发者还是需要管理它们的构建依赖，这通常可以通过Maven进行管理（或者你可以自己选择构建工具）。在构建期间，如果你在类路径上放置了很多依赖，这并不会造成特别大的问题：最糟糕的情况也只是编译失败，而这仅会对开发者造成影响，并且很容易被修复。另一方面，在运行时如果有太多依赖的话会降低模块的可移植性，因为所有的这些依赖都需要被移植，这可能会与移植环境中其它模块的依赖形成冲突。 这引出了OSGi和JPMS之间的另一个重要哲学差异。在OSGi中，我们总是意识到构建时期的依赖和运行时的依赖常常会不同。例如，通常我们需要构建API和运行API的具体实现。进一步，开发者通常会构建老版本的API来保持兼容，而我们在运行时会选择最新的实现版本。即使是非OSGi的开发者也会对此非常熟悉：通常构建的时候会支持低版本的JDK，但还是会鼓励使用者运行高版本的JDK，因为高版本中会有一些安全补丁，并对运行能力有所增强。 另一方面，JPMS则采取了不同的做法。JPMS的目标是实现“所有阶段的保真度”, 所以“模块系统应该在编译时、运行时以及在开发或部署的每个阶段中，都以完全相同的方式工作”（摘自 JPMS Requirements）。因此运行时依赖是以整个模块为粒度定义的，因为这样能够和它们编译时期的定义保持一致。示例如下：123module B &#123; require A;&#125; 这个 require 声明和OSGi中被废弃的 Require-Bundle 有着相同的效果：模块A中所有被导出的包都可以在模块B中使用。这也导致了它和 Require-Bundle 有着相同的问题，从模块依赖声明当中没有办法得知：对A中内容进行重构是否安全。所以，通常来说这样做并不安全。 我们发现在依赖关系的树形结构中，使用 require 的声明会比使用 imports 的声明具有更大的出度（节点出去的边数）：每个模块需要关注比实际需要的更多的依赖。这些问题是真实并且重要的。Eclipse的插件开发者尤其受到了它们的影响，因为历史原因，Eclipse bundles 往往使用 require 而不是 import。我们觉得JPMS采用这种方案是很不幸的一件事情。有趣的是，尽管编译/运行时保真是JPMS的基本目标，但是JPMS最近的一些改变显著地降低了保真度。当前早期的一个版本允许require声明使用静态修饰符，这意味着依赖在编译时强制性的，但是在运行时是可选的。相反的是，export 声明可以被动态修饰符修饰，这意味着导出的包在编译时期是无法访问的，但是在运行时期是可以访问的（通过反射）。这些特性会导致这样的情况：在编译时期可以成功地创建编译和链接模块，但是在运行时期会抛出 IllegalAccessError / Exception 。 反射和服务Java的生态系统非常巨大，包含一系列用于各种目的的框架，如依赖注入、模拟对象、远程调用、对象映射等等。这些框架中的大部分都使用了反射来实例化和管理用户代码中的对象。例如，Java 持久化框架（JPA），它是Java EE规范中的一部分：作为一个 O/R 映射器，它需要从用户的代码中加载和实例化领域类，从而使得这些实例能够匹配从数据库中加载到的记录。另一个例子是，Spring 框架中会加载和实例化一些接口的实现类 “bean”。 这会对模块化系统带来问题，包括OSGi和JPMS。理想情况下，一个领域或对象类应该被隐藏在模块中：如果它被暴露了，那么它成了一个公共的API，如果有消费者依赖它的话，可能会对它造成影响，而我们希望能够按照意愿灵活地改变我们的内部类。另一方面，可以通过反射来访问一些没有被模块导出的类型，这对于一些框架是非常有用的。 由于OSGi是基于类加载机制设计的，模块可以获得那些没有导出包和类型的模块的可见性，只要它知道类型的完全限定名和需要访问的模块（注意，多个模块可以包含任意的类型名）。Java开发中，反射思想的长期运用会破坏隔离性，因为即使是私有的域也可以通过 setAccessible 方法来修改可见性。 通过这种功能，OSGi通常可以提供模块的实现，但是不需要导出。此外，它们可能包含一些内部类型的声明，而这些类型可能是由框架加载。例如，一个使用JPA来说进行持久化的模块，可以通过 persistence.xml 文件来引用领域类型，JPA实现模块会在需要使用的时候加载引用的类型。 最大的用例在于实现服务组件。OSGi规范中有一章内容是声明性服务（Declarative Services，DS）,它定义了一个模块如何声明组件（那些生命周期由框架管理的类）。组件可以在OSGi注册中心中绑定服务，并且可以为它们自己提供服务。例如：1234567891011@Component public class CartMgrComponent implements CartManager &#123; @Reference UserAdmin users; @Override public Cart getOrCreateCart(String user) &#123; // ... &#125; &#125; 在这个例子中，CartMgrComponent 是一个提供 CartManager 服务的组件。它指向一个服务 UserAdmin，这个类的声明周期由DS框架管理。当 UserAdmin 服务可用的时候，CartMgrComponent 将会被创建，并且会发布一个 CartManager 服务，这个服务可能也会被其它模块中的组件通过相似的方法引用。 这个框架可以运行是因为它能够加载 CartMgrComponent 类，这个类通过使用 @Component 注解来表明它是一个组件。定义组件和服务是OSGi应用设计和编程的主要方式。 在JPMS中，只有在导出包内的类型可以被访问，即使使用反射也还是如此。即使模块中没有导出的类型是可见的（你可以通过调用 Class.forName 来获得一个类对象），但是它们还是还是无法在模块外部被访问。当框架调用 newInstance 来实例化对象的时候，将会抛出一个 IllegalAccessException。这视乎削减了框架的很多可能性，但是还是有一些可以采用的方法。 第一种方法是提供个人类型来作为服务，这可以通过 java.util.ServiceLoader 来加载。ServiceLoader 从Java 6开始就已经成为平台标准的一部分了，并且在Java 9中会被更新来支持进行模块间的工作。ServiceLoader 可以访问没有导出的包，只要模块提供者包含一个提供声明。不幸的是，ServiceLoader 是原生的，而且无法为当前的一些框架（比如，DS 或 Spring）提供灵活性。 第二种方法是通过使用“合格”的包导出。这是只对单个命名模块访问的导出，而不是所有模块都能访问。例如，你可以导出类所在的包给Spring 框架。但是，这样的方式会在JPA中的某些方面遇到失败，因为JPA是一个规范，而不是一个单一的模块，它可以由多个不同的模块实现，比如：Hibernate、EclipseLink、等等。 第三种方法是“动态”导出，这样包可以被任何人访问，但是只能通过反射的方式，在编译时期是无法访问的。这是JPMS很新的一个特性，而且它还有所争议。这是最接近OSGi允许策略的方法，但是对于那些可能会被反射加载的类型，还需要为它们所在的每个包都添加 dynamic 导出来获得访问权限。对于OSGi用户而言，这就像是一种不必要的并发症。 下一篇本文是文章的第一部分。下一篇将介绍OSGi和JPMS中的这些主题：版本、动态加载、未来二者协同工作的可能性。]]></content>
      <categories>
        <category>模块化</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>模块化</tag>
        <tag>翻译</tag>
        <tag>OSGi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSGi博客笔记]]></title>
    <url>%2F2018%2F02%2F02%2FOSGi%E5%8D%9A%E5%AE%A2%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本文是对killko一些博客的笔记，可以在《不可错过的OSGi入门学习资源》中找到，包括： 《走近Java模块化系统OSGi》 《创建OSGi Hello World工程》 《OSGi中Bundle间的耦合：Export/Import Package与服务》 《动态的OSGi服务》 《初次接触OSGI Blueprint》 《OSGi的配置管理：ConfigAdmin》 此外，还参考了： 《osgi确实面临鸡肋之嫌》 阅读前建议先阅读 《OSGi入门教程》 或者《OSGi入门教程》笔记 走近Java模块化系统OSGiOSGi是什么 OSGi作为Java的模块化规范，其目标（也是软件设计的目标）是复用、内聚、耦合。 被神化的“动态性”、“热插拔”的特性，是OSGi规范带来的一种可能，需要配合好的设计才能达到，并不是一定会有的。 OSGi是不是一个应用层面的框架（如spring、structs等），而是设计层面规范，类似面向对象的设计。所以，不要问“怎么将spring和OSGI集成？”这样的问题。 OSGi的目的是进行模块化，模块（bundle）的物理形式是Jar包。 OSGi的课程主要是让你去设计应用的，是形而上需要个人领悟的，不是去学一套应用框架那种。 OSGi frameworkOSGi规范定义了一个OSGi framework平台，它是运行在JVM上的应用，负责管理模块bundle。 bundle生命周期bundle需要关注它的生命周期。 install：框架通过classloader（类加载器）来装载bundle里的类和资源。 resolve：检查bundle依赖的package是否可用。 start：运行activator里的start方法，方法运行完毕后进入”ACTIVE”状态，至此bundle可用正式使用了。 bundle的隔离 模块以Jar包形式存在，Jar包的物理边界也是模块的物理边界。 在OSGi规范下，得显式地说明模块之间的依赖关系。OSGi是利用JVM的classloader和它的父委托模型（PDM:Parent Delegation Mode）来实现这点的。 每个bundle都分别用一个classloader来加载里面的类，所以不同bundle之间的类，在默认情况下，是互不可见的。 如果没有额外处理，一个bundle里的类要访问另一个bundle里的类时，通常会出现ClassNotFound的异常。 bundle之间的耦合方式一：import/export package的机制 OSGi通过import/export package的机制来控制bundle间有限地耦合。 Export/Import package是通过bundle里的META-INF/manifest.mf文件里指定的。 方式二：OSGi service方式(更松散的耦合) OSGi framework实现服务的注册、查找和使用。该服务是实现某种接口的bean实例。 该服务是实现某种接口的bean实例，所以本质上osgi service就是一个bean。 通常会把接口定义在bundle A里，接口的实现则在bundle B里，并将接口实现实例化后注册成osgi service，bundle C可以引用这个service。bundle A需export接口定义所在的package，而bundle B和C则需import这个package。bundle B和C之间就不需用export/import package来耦合了，实现了B和C之间的解耦。 OSGi应用中，会有大量的osgi service存在，可以说osgi service是osgi规范中最重要的机制，没有之一。 其它机制OSGi规范还提供了Event、配置管理（ConfigAdmin）、声明式服务（Declarative Service）、Service Tracker、Blueprint等等运行时机制，方便我们构建模块化的应用系统。 创建OSGi Hello World工程本节内容参考了《创建OSGi Hello World工程》，需要注意的是，这篇文章中maven配置文件pom.xml中的&lt;name/&gt;标签需要进行修改，不能以冒号分隔，示例如下：1&lt;name&gt;osgi-demo&lt;/name&gt; 模块构建1.创建Maven项目。2.在包中创建 OSGI Activator。 123456789101112131415161718package mindw.osgi.demo;import org.osgi.framework.BundleActivator;import org.osgi.framework.BundleContext;public class MyActivator implements BundleActivator &#123; @Override public void start(BundleContext context) throws Exception &#123; System.out.println(&quot;Hello world!&quot;); &#125; @Override public void stop(BundleContext context) throws Exception &#123; System.out.println(&quot;Stop bundle!&quot;); &#125;&#125; 3.配置pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot; xmlns:pom=&quot;http://maven.apache.org/POM/4.0.0&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;groupId&gt;mindw.osgi&lt;/groupId&gt; &lt;artifactId&gt;demo&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;version&gt;0.1&lt;/version&gt; &lt;name&gt;osgi-demo&lt;/name&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;$&#123;project.build.sourceEncoding&#125;&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;/manifest&gt; &lt;manifestEntries&gt; &lt;Class-Path&gt;$&#123;project.build.finalName&#125;.jar&lt;/Class-Path&gt; &lt;Built-By&gt;Ponder&lt;/Built-By&gt; &lt;Bundle-ManifestVersion&gt;2&lt;/Bundle-ManifestVersion&gt; &lt;Bundle-Name&gt;$&#123;project.groupId&#125;.$&#123;project.ArtifactId&#125;&lt;/Bundle-Name&gt; &lt;Bundle-SymbolicName&gt;$&#123;project.name&#125;&lt;/Bundle-SymbolicName&gt; &lt;Bundle-Version&gt;$&#123;project.version&#125;&lt;/Bundle-Version&gt; &lt;Bundle-Vendor&gt;$&#123;project.groupId&#125;&lt;/Bundle-Vendor&gt; &lt;Bundle-Activator&gt;$&#123;project.groupId&#125;.$&#123;project.ArtifactId&#125;.MyActivator&lt;/Bundle-Activator&gt; &lt;Export-Package&gt;$&#123;project.groupId&#125;.$&#123;project.ArtifactId&#125;;version=&quot;0.1&quot;&lt;/Export-Package&gt; &lt;Import-Package&gt;org.osgi.framework&lt;/Import-Package&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.osgi&lt;/groupId&gt; &lt;artifactId&gt;org.osgi.core&lt;/artifactId&gt; &lt;version&gt;4.2.0&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 4打包生成 demo-0.1.jar。 servicemix安装为了使用模块，需要一个支持模块化运行的环境，参考文章的作者使用了servicemix。 servicemix介绍 Apache ServiceMix是一个灵活、开源的集成容器。 它可以将Apache ActiveMQ、Camel、CXF和Karaf集成为一个强大的运行平台。 你可以通过它来建立自己的集成解决方案。 它提供了一个由OSGi支持的完整、企业级的ESB（企业服务总线）。 安装 去servicemix官网下载zip压缩文件。（版本都可，5.4.0版本86M左右，7.0.1版本113M左右）。 解压压缩包即可。 模块使用（生命周期变化） 将demo-0.1.jar放入servicemix的deploy目录下，本人放在 apache-servicemix-5.4.0\deploy 中。 进入 apache-servicemix-5.4.0\bin 目录，运行 servicemix.bat。可以看到以下界面。”Hello world!”表示模块已经加载。 使用list命令，可以查看模块状态。可以看到模块ID为220,状态为 Active。 输入stop 220，可以看到”Stop bundle!”,然后再输入list，可以看到当前模块处于Resolved状态。 输入uninstall 220，模块就被卸载了，再输入list就看不到模块信息了。 conrtrol + d 可以结束servicemix容器运行。 Package与服务该部分可以参考《OSGi中Bundle间的耦合：Export/Import Package与服务》。 注册服务在BundleActivator的start函数中可以通过BundleContext注册服务。123456789101112public class MyActivator implements BundleActivator &#123; @Override public void start(BundleContext context) throws Exception &#123; Dictionary&lt;String, String&gt; props = new Hashtable&lt;String, String&gt;(); props.put(&quot;ServiceName&quot;, &quot;Calculation&quot;); context.registerService(ICalculation.class.getName(), new Calculation(), props); System.out.println(&quot;Service registered!&quot;); &#125; ...&#125; 引用服务在BundleActivator的start函数中可以通过BundleContext获得服务。123456789101112131415public class MyActivator implements BundleActivator &#123; @Override public void start(BundleContext context) throws Exception &#123; ServiceReference[] refs = context.getServiceReferences(ICalculation.class.getName(), &quot;(ServiceName=Calculation)&quot;); System.out.println(&quot;demo3:&quot;+ICalculation.class.getName()); if(refs!=null &amp;&amp; refs.length&gt;0)&#123; ICalculation service=(ICalculation)context.getService(refs[0]); System.out.println(&quot;1+1=&quot;+service.add(1, 1)); System.out.println(&quot;2-1=&quot;+service.sub(2, 1)); System.out.println(&quot;2*3=&quot;+service.sub(2, 3)); &#125; &#125; ...&#125; 依赖疑问在开发中，Demo2中提供服务（包含接口定义），Demo3中使用服务（不包含接口，但依赖接口），但是编译器环境中OSGi模块依赖不能解析，如何表明依赖？翻看作者代码后，发现只要正常添加maven依赖即可，打包的时候不用包含进去。 动态的OSGi服务该部分可以参考《动态的OSGi服务》。包括： OSGI服务的动态性 Service Listener Service Tracker 初次接触OSGI Blueprint该部分可以参考《初次接触OSGI Blueprint》。包括： Blueprint简介 Blueprint的入门例子：OSGI服务的注册 Blueprint的入门例子：OSGI服务的引用 OSGI blueprint的机制原理 OSGi的配置管理：ConfigAdmin该部分可以参考《OSGi的配置管理：ConfigAdmin》。包括： 动态的OSGI配置 利用blueprint来实现ConfigAdmin OSGi还有用武之地吗？ 正面观点，可以参考《简单了解osgi》。 反面观点，可以参考《osgi确实面临鸡肋之嫌》。 本人在网上搜索博客的时候，发现OSGi近几年的博客介绍很少，关注度不高，而且学习的OSGi中文网站2015年后也不怎么更新文章了。在分布式微服务流行的现在，OSGi的确有些尴尬，但是个人感觉对于一些复杂的单体应用，OSGi还是有用武之地的，比如Java 9学习了OSGi，增加了模块化功能并重构了Java库。此外，OSGi解决模块依赖的方法和基于接口和模块的设计理念还是很有价值的。 接下来将对反面观点进行一下介绍。 明显不足OSGi的关注不是很高，该文作者也谈了它本身的一些不足：相对来说适合单体应用（但单体应用也可以通过容器的等帮助部署），不适合分布式。具体如下所示。 关于隔离与奔溃OSGi最终基于jvm，无法对bundle对应的服务实现计算资源的隔离，一个服务的故障依然会导致整个jvm crush,这使得在一个运行时的osgi上部署模块级服务只获得了模块部署和启停隔离。 关于扩展能力服务明确依赖的好处，但是没办法实现计算节点的线性扩展，在当前分布式，微服务，网络计算的趋势下，使得osgi只适合构建单一服务节点的内部应用，但是其分离的bundle的部署负担对于微服务架构来说，有点用大炮打蚊子的臭味。 推荐的应用架构方式目标 采用“进程间构建的分布式应用”和“进程内的单一应用”分开来进行架构设计。 对于进程间构建的分布式应用，采取基于soa的理念进行容器模式的服务部署模式，服务交互基于远程服务交互相关协议，采用可忍受网络失败的架构设计原则。 对于进程内的应用，如果需要模块级的独立生命周期热部署和模块管理，可以考虑采用OSGi。 容器更方便但是，容器内基于本地进程间通信的模块交付方式不仅能提供同样的独立生命热部署和模块管理，而且具备随时脱离出去部署成单独容器级服务应用的能力，加速进程间的服务交付提供的整体管理和监视环境基础。 OSGi比较适合嵌入式 OSGi还有用武之地吗？当然我前述都是以构建分布式企业和面向互联网这类应用为前提来讨论的，对于嵌入式的jvm应用，比如著名的osgi案例宝马的车载系统，osgi依然是最好的原则，不过我怀疑基于andriod系统的机制构建类似应用，osgi的采用依然值得商榷。因此，osgi确实面临鸡肋之嫌。]]></content>
      <categories>
        <category>模块化</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Java</tag>
        <tag>模块化</tag>
        <tag>OSGi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《OSGi入门教程》笔记]]></title>
    <url>%2F2018%2F01%2F31%2F%E3%80%8AOSGi%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%E3%80%8B%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本文是对《OSGi入门教程》课程的笔记。 OSGi基础概念基本概念OSGi的一些定义 Open Services Gateway initative 开发服务网关协议 是指Java的动态模块化系统的一系列规范。（OSGi联盟，osgi.org） OSGi Alliance 组织 以及该组织指制定的一个基于Java语言的服务规范。(Wiki) Java 平台的模块层。(《OSGi in Action》) OSGi生态 模块化将大型系统分解为多个模块，通过设置模块的边界来改善系统的可维护性和封装性。 Java模块化的局限性可见性控制不够 通过Package来组织和划分代码，可见范围可以分为Private、Package、Protected、Public这几类。 存在的问题：如果是Public的话，任何人都可以访问，希望可以进一步控制（一种方案可以是通过一些模式进行模拟实现，另一种可以是OSGi）。 Jar包灾难 ClassPath中的Jar包在运行时没有明确地模块边界。 多个版本的Jar同时存在时，加载具有不缺定性。Jar Hell（Jar包灾难）。 部署和管理缺少支持 模块的动态更、系统动态演化。 插件化开发。 OSGi三层架构模块层：定义了OSGi中的模块Bundle。 Bundle是一个具有额外元数据的Jar包。 Bundle定义了包含的包的可见性（对外暴露哪些模块）。 Bundle定义了所依赖的包。 生命周期层：提供运行时管理和框架访问接口。 提供对模块生命周期的操作（install,update,start,stop…），使得程序外部可以动态管理和演化系统。 定义了运行时上下文的接口，bundle本身可以和OSGi框架进行交互，从而实现内部自我管理。 服务层：关注模块间的交互。 服务层是JVM中的SOA（面向服务的架构）。 服务是动态的，促使你使用基于接口编程。 OSGi服务是Java Interface，服务调用是Java对象方法调用（Lightweight Tech,轻量级技术）。 OSGi介绍补充OSGi严格的模块化特性的最大优势 基于接口编程，完全隐藏实现（促进你从架构上思考）。 动态新（对扩展开发，即使是运行时）。 OSGi传播的阻力 最初面向的嵌入式领域，容易被误解为只是嵌入式技术。 有些人觉得OSGi复杂，人为属于重量级。 Lib支持不够：很多Lib不能再OSGi环境下运行。 企业中的OSGi 企业应用特点：持久化数据、数据量大、访问并发等。 需要模块化：前端/事务/持久化分离、运行多个服务器上、需要协作化开发。 存在问题：企业开发中其它框架会使用TCCL（SPI模式）、反射，这些技术在OSGi类加载机制下会有问题。 小节 OSGi提供了更粗粒度的模块化特征，可以解决Java模块化的局限性。 OSGi中声明式和基于元数据的方法是非侵入式的。 生命周期层定义了模块动态且可控的生命周期模型，简化了系统管理。 服务层鼓励采用基于接口编程的方法，从而将接口与实现进行分类。 OSGi模块层模块化与面向对象的关系 都是“关注点分离”（分治）思想的体现，但关注的粒度不一样。 在实现特定功能时，需要设计类以及类之间的关系，此时需要面向对象的原则和模式。 当把相关的类在逻辑上组织在一起的时候，需要关注系统模块和模块间的关系。 模块化的意义 解决Java模块化的局限：可见性控制不够、Jar包灾难、部署和管理缺少支持。 通过显示定义能力（Export-Package）和依赖（Import-Package）,可以优化设计，让系统更加“高内聚低耦合”（软件开发的终极目标）。 促进协同开发，提高开发效率。 Bundle基本概念 Bundle是一个包含代码、资源、元数据，以Jar的形式存在的模块化单元。 Jar文件的边界也是模块的边界。Jar包是bundle中代码的物理容器。 Mainifest.mf文件保存了模块的元数据。 元数据定义 元数据信息定义在/META-INF/MANIFEST.MF中，OSGi R5规范定义了28个标记。 元数据有三类标记：可读信息、Bundle标识（Identification）、代码可见性。 依赖解析OSGi类查找顺序 如果类所在包以“java.”开头，委托给父类加载器。 如果类所在的包在导入包中，委托给导出该包的Bundle。 在Bundle自身的类路径上查找。 多个提供者的选取规则 已解析的（resolved）的bundle优先级高，未解析的（installed）bundle优先级低。 相同优先级多个匹配时，版本高者优先，版本相同则先安装的优先。 uses子句使用 使用uses子句来解决类空间不一致的问题。 uses约束是可传递的。 谨慎使用uses,会大大限制解析的灵活性。 使用场景如下。 导出包中的类，其方法签名中包含了其Import-Package中的类。 导出包中的类，继承了其Import-Packeage中的类。 OSGi生命周期层基本概念生命周期管理 通过外部或内部对应用进行操作，完成对应用的“生命周期管理”过程。 对于非模块应用，这些操作是以整个应用为对象。 对于模块化应用，可以有更细粒度（针对某个模块）的生命周期管理。 生命周期层的作用 在应用外部，该层精确定义了对bundle生命周期的相关操作。 在应用内部，该层定义了bundle访问其执行上下文的方式，为bundle提供了一种与OSGi框架交互的途径。 对生命周期的操作允许你动态地改变运行于框架汇中的bundle组成，并以此来管理和演化应用程序。 生命周期层状态转移 使用生命周期层 BundleActivator是生命周期层的基础设施,如下所示。 1234public interface BundleActivator&#123; public void start(BundleContext context) throws Exception; public void stop(BundleContext context) throws Exception;&#125; bundle属于active时，BundleContext才有意义，即start方法被调用和stop方法被调用的两个时间点之间。 BundleContext包含部署和生命周期管理相关接口、与bundle间服务交互相关的接口。 Bundle定义了一系列API,用于管理已安装的bundle的生命周期。 Bundle的更新两阶段更新 两阶段更新：先update,再显示refresh。 为什么两阶段？对外输出后，其它模块会使用旧版本，需要刷新，可参考《bundle动态更新》。 刷新流程 从bundle开始计算受影响的bundle有向图。 处于ACTIVE状态的bundle被停止并被切换至RESOLVED状态。 处于RESOLVED状态的bundle，切换至INSTALLED状态，这些bundle的依赖关系不再被解析。 处于UNINSTALLED状态的bundle会从图中移除，同时也会被彻底地从框架中移除（GC）。 其它bundle如果在框架重启前处于ACTIVE状态，重启框架会对这些bundle及其依赖的bundle进行解析。 所有工作完成后，框架会触发一个FrameworkEvent.PACKAGES_REFRESHED事件。 小节 BundleActivator是bundle的入口，与Java应用中的main函数类似。 BundleContext为应用提供执行时操作OSGi框架的方法。 Bundle代表了一个已安装到框架中的bundle,允许对其执行状态进行操作。 OSGi服务层基本概念什么是服务 为别人完成的工作（经典定义）。 指提供者及其使用者之间的一个契约。服务可以被替代，能够发布和查找。 使用者不关心具体实现，只关心约定的契约。 面向服务的设计 降低服务提供者和使用者之间的耦合，更容易重用组件。 更强调抽象接口而不是具体实现。 清晰描述依赖关系（可以通过附加元数据描述）。 支持服务的多个实现方案以及动态替换。 OSGi服务OSGi服务模型 拥有一个集中的服务注册中心，遵循发布-查询-绑定模型。 提供者bundle可以将POJOs（Plain Ordinary Java Object）发布为服务。 使用者bundle可以找到并绑定服务。 OSGi服务注册、更新与注销 服务注册对象是私有的，不能被别的bundle共享，它们与发布服务的bundle的生命周期是绑定的。 不推荐使用具体类名进行服务注册。 当一个bundle停止时，任何没有被移除的服务都会被框架自动移除。 服务排序：先按service.ranking由大到小排序，然后再按service.id由小到大排序。 按属性查询：使用LDAP过滤字符串（LDAP，Lightweight Directory Access Protocol，轻量目录访问协议）。 服务使用1234// 注册中心会增加一个使用计数。A serviceA = (A)bundleContext.getService(reference); // 完成服务时应该通知注册中心。bundleContext.ungetService(reference); 服务监听服务可以监听的事件包括：REGISTERED（注册）、MODIFIED（更改）、UNREGISTERING（注销）。 OSGi开发环境略，点击可查看原文。]]></content>
      <categories>
        <category>模块化</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Java</tag>
        <tag>模块化</tag>
        <tag>OSGi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018年Java开发者应该学习的9个方面]]></title>
    <url>%2F2018%2F01%2F24%2F2018%E5%B9%B4Java%E5%BC%80%E5%8F%91%E8%80%85%E5%BA%94%E8%AF%A5%E5%AD%A6%E4%B9%A0%E7%9A%849%E4%B8%AA%E6%96%B9%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;翻译了一篇国外学习建议的文章，希望读者可以受到启发。点击查看原文。文中涉及到的书籍和课程链接是国外购买的网址。 前言&emsp;&emsp;想要新年一开始就有个好计划吗？这里有一些建议可以使你成为一个更好的Java开发者，包括Java性能调优、Spring Security 5.0等方面。&emsp;&emsp;首先，祝你们新的一年快乐。每当新的一年开始，我们都会制定计划、建立目标或者思考一些解决方法。&emsp;&emsp;成为一个Java开发者和《Java blog》的作者之后，我经常收到全世界Java开发者的一些咨询：如何可以提升他们的能力。&emsp;&emsp;之前，我分享过我的一篇文章《10 tips to become a better programmer》（《10条关于如何成为更好的开发者的建议》），文章中每条建议现在看来都还未过时，但是既然是新的一年了，我还是觉得写一些建议给那些愿意提高自己的Java开发者，从而帮助他们增加Java编程的知识和职业生涯中的个人价值。&emsp;&emsp;不废话了，让我们看看是哪9条建议吧。你可以参考这些建议，然后确定适合自己的n个小目标。 学习Java性能调优&emsp;&emsp;在过去的几年里，我访谈了50多位高级Java开发人员，通过交谈发现，这些人员最缺少的知识之一就是对于Java虚拟机内部机制、GC原理和Java性能调优的了解。 &emsp;&emsp;随着你经验的增长，你将成为一个具有5到6年经验的高级Java开发人员，此时，你应该具备对Java基本原理的宏观理解，并能知晓各个实现的细节。&emsp;&emsp;如果你不能够优化你的应用，具体来说是你无法弄清楚知晓应用为什么跑的那么慢？它的瓶颈在哪里？如何进行优化？那你需要阅读一些关于Java虚拟机原理和新性能调优方面的书籍。例如：Scott Oaks的名著《Java Performance the Definitive Guide》（Java权威性能手册）。&emsp;&emsp;这本书我这几年都在读，只要一有空就会打开来看看，今年还准备再读一次。&emsp;&emsp;如果你比较喜欢在线课程的话，我建议你可以看一下在Pluarlsight网站上的《Understanding the Java Virtual Machine 》课程，这个课程解释了内存管理、类加载、安全机制、反射等内容。 每天编程2小时&emsp;&emsp;去年我注意到的另外一件事是：随着你经验的增加，你会花很多的时间在沟通协调、回复邮件、解决问题纠纷、指导工作上面，通常来说你已经成了一个项目经理。&emsp;&emsp;除了这些事情，你忘记了程序员最重要的一个技能，就是编程。&emsp;&emsp;如果你觉得你写的代码还不够，那你得想个办法每天写点代码。或者至少写点东西，让它成为你项目的一部分，或者是一个开源的框架，或者是一个开发包，或者是一个开发工具，等等。&emsp;&emsp;万事开头难，我建以你克服阻力，开始阅读和重构代码来获得快乐。在过程中，你会得到享受并且也会开始写些代码。&emsp;&emsp;你也可以阅读《Cracking the Coding Interview, 150 Programming Questions》。这不仅可以让你做好面试准备，也可以提高多数据结构、算法和编程逻辑的理解。 每个月都对Java应用做一次优化&emsp;&emsp;这个方法需要和第一个方法（读一些Java虚拟机和性能调优方面好的书籍）相结合。光读书是不够的，你需要将学到的知识应用到你的项目中去。&emsp;&emsp;我建议你至少每个月都对Java应用进行一次优化，并且要花足够的时间去分析和理解优化的结果。&emsp;&emsp;例如，如果你的程序最近奔溃过，你可以将Java堆状况导出，然后分析：哪个对象占用的内存最大？在你的项目中是否存在内存泄露？&emsp;&emsp;现象的原因是啥？当有超过10万个客户端链接你的服务是会发生什么？如果你可以回答这些问题，那么你干的不错。如果你需要一些关于解决内存和CPU问题的指导，那么我建议你可以看一下Richard Warburton写的《Understanding and Solving Java Memory Problems》。 参加编码挑战&emsp;&emsp;这个建议和第二个建议（每天编程2小时）相关。事实上，有时你在当前的工作中无法获得足够的挑战。&emsp;&emsp;如果渴望编程挑战，那么参加相关编程挑战的比赛就再好不过了。&emsp;&emsp;网上有很多编程网站可以给你锻炼和测试的机会，其中比较推荐的是TopCoder。&emsp;&emsp;如果你在寻找一些困难的编程挑战，那么你可以查看我之前写的一个关于在线编程网站的列表。 学习Java网络编程&emsp;&emsp;我交流过程中发现的一点是：Java开发者需要提高他们的socket编程能力和网络基础。&emsp;&emsp;我从网络编程问题列表中挑选了一些问题进行询问，但是很多开发者很多问题都没有回答好。&emsp;&emsp;他们中的一些甚至还需要去了解TCP和UDP的差别。这个问题我认为对于有2到5年的Java开发者来说已经太基础了，甚至没有问的必要。&emsp;&emsp;如果你觉得你没有获得足够的机会去学习网络编程，或者你是一个和JSP、Servlet、JSF打交道的Java Web开发者，那么我建议你至少看一下Java网络、NIO、socket编程方面的一本好书。&emsp;&emsp;一本值得推荐的书是《TCP/IP Sockets in Java, Second Edition, Practical Guide for Programmers》。这本书易读、有趣，是一个学习socket编程基础的好途径。 Java 9&emsp;&emsp;2017年有一些重大的发布，其中之一就是JDK 9。2018年，我第一件事就是准备研究一下JDK 9。如果你想要了解Java 9的一些新特性，包括：Jigsaw、Reactive Streams、API改进等等，那么《Java 9 MasterClass》课程是个不错的开始。 Spring 5.0&emsp;&emsp;Java业界另一个比较大的发布是Spring Framework 5.0。Spring 5.0带来了很多振奋人心的新特性，包括：响应式函数编程模型，采用了Java 8 和 9 的新特性等。&emsp;&emsp;在2018年，Spring 5.0的发展将会提速，这也是值得每个Java开发者需要学习的原因。如果你需要一些指导，那么《Spring 5.0: Beginner to Guru》课程将是不错的选择。 Spring Security 5.0&emsp;&emsp;2017年另一个有趣的发布是Spring Security 5.0，这也是我在2018年将要学习的一个内容。Spring Security 5.0是一个重要的发布版本，开发人员重写了很多模块，并且修复了上百个bug。其中比较有意思的一个部分是OAuth 2.0模块。遗憾的是，目前没有特别多的资料来学习Spring Security 5.0。值得庆幸的是，Eugen 更新了他的课程《Learn Spring Security》，包含了版本5.0以及OAuth 2.0模块。 单元测试&emsp;&emsp;如果你想在2018年更上一层楼，那么你需要继续提高你的单元测试技巧。这里的测试不仅仅是指单元测试，而且包括通常说的自动化测试，当然也包括集成测试。你可以学习JUnit5以及一些其它比较高级的单元测试库，例如：Mockito、 PowerMock、Cucumber、Robot 等，从而使你的测试能力提高一个等级。Mockito功能非常强大，可以通过模拟依赖帮助你对一个复杂的对象进行测试。如果你刚刚接触单元测试并且希望在2018年进行学习，那么Udemy 的课程《JUnit and Mockito Crash Course》是个不错的选择。 总结&emsp;&emsp;这只是我的一些建议。如果你从事Java开发有些年头了，那么你可以参考这些要点制定自己的目标。比如，你还可以添加Android、Docker、Spark等条目，因为这些对于Java开发者也很重要。&emsp;&emsp;我之所以将这些目标制定的简单并容易实现，是因为我个人认为巨大的进步是有一点一点的小进步堆积而成的。设置小目标表比大目标更容易实现，往往一些大目标在制定的时候就已经注定无法实现。&emsp;&emsp;所以，你还在等什么那？写下你新年的目标并和我们分享。等这一年结束，你可以再过来看看，告诉我们多少目标你已经达成。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>翻译</tag>
        <tag>建议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018人工智能标准化白皮书摘要]]></title>
    <url>%2F2018%2F01%2F22%2F2018%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A0%87%E5%87%86%E5%8C%96%E7%99%BD%E7%9A%AE%E4%B9%A6%E6%91%98%E8%A6%81%2F</url>
    <content type="text"><![CDATA[本文对白皮书进行一点摘要，留作纪念。白皮书下载链接。 引言 &emsp;&emsp;1月18日下午，2018人工智能标准化论坛在京召开，本次论坛发布了《人工智能标准化白皮书（2018版）》。白皮书通过梳理人工智能技术、应用和产业演进情况，分析人工智能的技术热点、行业动态和未来趋势，从支撑人工智能产业整体发展的角度出发，研究制定了能够适应和引导人工智能产业发展的标准体系，进而提出近期急需研制的基础和关键标准项目，呼吁社会各界共同加强人工智能领域的技术研究、产业投入、标准建设与服务应用，共同推动人工智能及其产业发展。 部分内容 2017 年，我国出台了《新一代人工智能发展规划》（国发〔2017〕35 号）、《促进新一代人工智能产业发展三年行动计划（2018-2020 年）》（工信部科〔2017〕315 号）等政策文件。 标准化工作对人工智能及其产业发展具有基础性、支撑性、引领性的作用，既是推动产业创新发展的关键抓手，也是产业竞争的制高点。 本白皮书的意义在于与业界分享人工智能领域的研究成果和实践经验，呼吁社会各界共同加强人工智能领域的技术研究、产业投入、标准建设与服务应用，共同推动人工智能及其产业发展。 从数量、投资等角度来看，自然语言处理、机器人、计算机视觉成为了人工智能最为热门的三个产业方向。 本白皮书认为，人工智能是利用数字计算机或者数字计算机控制的机器模拟、延伸和扩展人的智能，感知环境、获取知识并使用知识获得最佳结果的理论、方法、技术及应用系统。 人工智能相关技术和标准介绍：略。 10个应用案例 案例名称 应用领域 应用场景 案例提供者 城市大脑在城市公共资源优化配置的创新实践与应用 城市治理 交通态势评价与信号灯控制优化、城市事件感知与智能处理、公共出行与运营车辆调度、社会治理与公共安全 阿里云计算有限公司 医疗 AI 影像的成功应用 医疗影像 临床医疗影像辅助诊断 腾讯互联网加（深圳）有限公司 语音评测在英语听说考试的成功应用 教育考试 中考、高考中的英语听说测试 科大讯飞股份有限公司 智能供应链设计系统 制造领域 供应链路径优化 华为技术有限公司 百度机器翻译 机器翻译 不同语种间的转换 百度网络技术有限公司 小i机器人智能客服机器人系统 智能人机交互 自动客服、呼叫中心、智能人机交互 上海智臻智能网络科技股份有限公司（小 i 机器人） 重点人群身份识别系统 社会公共安全 交通枢纽、商场、医院等公共场所 重庆凯泽科技股份有限公司 智能网络视频云服务平台 互联网传媒产业 视频识别、视频推荐、社交传播、视频营销 北京爱奇艺科技有限公司 中移动人证比对实名认证 用户实名化，自动人证对比人证 大规模人脸识别，人证对比，OCR 识别 商汤科技开发有限公司 COSMOPlat 工业互联网平台-人工智能与制造业融合创新 工业制造领域 智能制造、智能产品 海尔工业智能研究院 一些截图人工智能发展历史 人工智能参考框架 人工智能产品 人工智能标准体系结构]]></content>
      <categories>
        <category>人工智能</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>人工智能</tag>
        <tag>标准化</tag>
        <tag>白皮书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[volatile如何实现可见性]]></title>
    <url>%2F2018%2F01%2F12%2Fvolatile%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%8F%AF%E8%A7%81%E6%80%A7%2F</url>
    <content type="text"><![CDATA[引言&emsp;&emsp;在描述volatile变量有什么作用的时候，经常会提到volatile可以使线程看到最新的变量值。但是进一步问到为什么能看到最新值的时候，会说volatile会使得线程的缓存无效，写会直接更新主内存中的值，读也会直接从主内存中读。本来这样的解释也就可以了，但是最近在解释同学的一个问题的时候还是觉得自己没搞清楚。问题如下： “Java原子类中，CAS操作可以使得主内存中的值是最新值，那为什么还要把value声明为volatile？” &emsp;&emsp;这个可以用之前的线程缓存无效来回答（目前是这么认为的），但是这个线程缓存到底是什么那？和Java栈又是什么关系那？是如何实现缓存无效的那？这些问题实际上在《深入理解Java虚拟机》中的12.3Java内存模型这一节中有了描述，这里再把这些内容描述一下，只是为了加深一下印象。 内存模型&emsp;&emsp;与C/C++等语言直接使用操作系统的内存模型不同，Java虚拟机规范中定义了一种Java内存模型（Java Memory Model， JMM），该模型是基于各个平台之上的一个规范定义。这样可以屏蔽操作系统带来的差异，使得Java具有更好地移植性。Java内存模型结构如下图所示： &emsp;&emsp;其中，线程的工作内存中保存了从主内存中拷贝的变量副本，线程操作的变量作都是从工作内存中获取的，而且各个线程的工作内存互不影响，这就构成了对主内存的一个“缓存”。所以如果线程中的缓存如果没有及时刷新的话，就会读取旧的数据。也就是说，一个线程对共享变量操作后，其它线程不一定能够及时获取到，对其它线程是“不可见的”。 工作内存&emsp;&emsp;之前提到了工作内存，那么工作内存到底是什么那？和Java栈又是什么关系那？《深入理解Java虚拟机》书中给出了一个说明：&emsp;&emsp;Java内存模型中的主内存、工作内存和Java内存区域中的Java堆、栈、方法区不是同一个层次的内存划分，这两者基本上没有基本的关系。如果要勉强进行对应，工作内存可以对应虚拟机栈中的部分区域，从更低层次来说，由于虚拟机主动实现或者是系统本身的机制，可能会让工作内存优先存储于寄存器和高速缓存中，这样可以提供访问速度（工作内存是程序主要访问读写的地方）。 线程读取变量过程&emsp;&emsp;下面描述来自此文章。&emsp;&emsp;线程读取主内存变量过程如下图所示： &emsp;&emsp;其中部分原子操作规则如下： read,load必须连续执行，但是不保证原子性。 store,write必须连续执行，但是不保证原子性。 不能丢失变量最后一次assign操作的副本，即遍历最后一次assign的副本必须要回写到MainMemory中。 volatile特殊规则&emsp;&emsp;volatile可以实现工作内存缓存无效主要是因为它具有一些特殊的规则。 在use之前必须使用load，根据上面的read,load必须连续执行可以推出：如果要使用（use）变量的话，必须从主内存中获取（read和load）。 assign只能在store之前使用，根据上面的store,write必须连续执行可以推出：如果要更新（assign）变量的话，必须写回到主内存中（store,write）。 &emsp;&emsp;通过这两条规则，可以使得volatile声明的变量能够避免工作内存中缓存的影响，相当于直接读写主内存。当然volatile还有其它的一些规则，这里不再列出。 总结&emsp;&emsp;通过这些介绍，可以回答开题的一些问题。&emsp;&emsp;Q：这个线程缓存到底是什么那？&emsp;&emsp;A：工作内存，具体实现硬件取决于操作系统和硬件，可以是高速缓存或者寄存器。&emsp;&emsp;Q：和Java栈又是什么关系那？&emsp;&emsp;A：没有基本的关系。如果要勉强进行对应，工作内存可以对应虚拟机栈中的部分区域。&emsp;&emsp;Q: 是如何实现缓存无效的那？&emsp;&emsp;A：通过volatile的语义规则，可以使得线程一定要读取或更新内存中的值。（面试中面试官曾说通过设置Cache中的缓存行无效实现，这个回答前提应该是工作内存是通过Cache实现，该回答了进一步描述了语义规则如何通过硬件实现）。&emsp;&emsp;“你看了，但是你没看进去”。的确，有些问题深究之后才发现其实不是很懂，还是要精益求精，凡事多问问为什么。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>volatile</tag>
        <tag>内存模型</tag>
        <tag>可见性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[天气查询应用]]></title>
    <url>%2F2018%2F01%2F10%2F%E5%A4%A9%E6%B0%94%E6%9F%A5%E8%AF%A2%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[引言&emsp;&emsp;项目中的文件说明如下（项目地址）： /doc 文件夹中包含项目截图和以下将要描述的文档(PDF文档 )。 weather-web 项目： 天气Web服务。 weather-weixin 项目：查询天气微信小程序（微信扫描下图可以查看）。 项目中一些关键Key已经去除，开发者可以自行添加，如有问题可以留言或者邮件联系。 欢迎 fork 和 star ~ 背景意义&emsp;&emsp;设计该服务，主要有以下几个原因： 目前的一些天气API（高德、百度等）都只有3天的预报，不能提供长期预报。 第三方API有调用次数限制、认证情况比较麻烦。 不足&emsp;&emsp;该服务存在以下缺陷： 依赖第三方网站，第三方网站的网页结构变化后需要重新修改代码。 第三方服务器崩溃或者提供反爬技术的话，该服务失效。 声明&emsp;&emsp;本服务只是为了学习交流使用。 服务结构&emsp;&emsp;如果开发者需要基于该服务项目进行开发的话，需要了解该服务的一些结构。该服务（weather-web项目）的总体结构如下图所示。 &emsp;&emsp;其中，淡粉色部分表示支持查询的接口，淡紫色部分表示第三方的接口或网站，淡绿色部分是项目中主要的几个类。使用该服务，需要注意一下几个方面： 如果是按经纬度查询，则需要利用第三方API（腾讯的API）将经纬度转换为对应的城市名称。 因为最后是根据查询城市的拼音找到解析数据的网页的，所以需要事先爬取城市名称和拼音的关系，最后统一转换为按拼音查询。 为了减少频繁爬取第三方数据，该服务按天粒度进行更新，每次查询的时候会比对天气日期，如果过期才会重新爬取，否则则会返回缓存中的数据。为了服务的快速，服务所有数据都在内存中，并没有落盘。 服务接口访问接口&emsp;&emsp;访问接口如下表所示，接口中中文部分表示需要提供的参数。开发者在部署服务后，最终的访问接口是：协议（http 或 https）+ 主机地址 + 接口。 功能 接口 按经纬度进行查询 /weather/?latitude=纬度&amp;longitude=经度 按城市名称中文（或拼音）进行查询 /weather/城市名称或拼音 返回结果&emsp;&emsp;返回的结果是Json格式，包含30天天气基本情况，具体如下所示： { "queryName": "泰州", // 查询的城市名字，如果无数据返回空 "date": "2018-01-06", // 第一天数据日期，缓存可以判断是否过期 "weatherItems": [ // 天气情况数组，30天 { "date": "01月06日", // 日期 "dayKind": "今天", // 星期几，前三天是今天明天后天 "weather": "雪", // 天气描述 "weatherImg": "b15.png", // 天气用什么图片表示 "minTemperature": "-6", // 最低温度 "maxTemperature": "4", // 最高温度 "wind": "东北风 3级" // 风力描述 }, ... ] } 基于该服务的小程序&emsp;&emsp;基于该服务可以构建一些天气查询应用。为了演示该服务，写了一个小程序。下图就是小程序项目（weather-weixin）的演示效果图。小程序启动时可以根据经纬度给出一个当前位置的天气情况，之后可以根据查询关键字更新数据。 项目实际部署运行Web服务 如果要支持经纬度查询，则需要配置WeatherWebConfig.txt中的腾讯地图API KEY。 由于小程序使用https，所以如果要运行小程序，则需要将域名指向Web服务主机，申请证书，并配置src/main/resources下的application.properties文件。 运行小程序 project.config.json中填入你申请的appid。 pages\index\index.js内容中开头部分的baseUrl替换成：Web服务地址的部署地址+”weather/”。]]></content>
      <categories>
        <category>小程序</category>
      </categories>
      <tags>
        <tag>小程序</tag>
        <tag>Web服务</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信小程序模块组件开发]]></title>
    <url>%2F2018%2F01%2F09%2F%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%A8%A1%E5%9D%97%E7%BB%84%E4%BB%B6%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[背景&emsp;&emsp;之前进行Android手机的开发，在开发中都用到了一些第三方的组件，非常方便。现在开始尝试小程序的开发，也希望利用一些组件进行开发，甚至说希望自己提供一些组件，那这就需要对微信小程序组件的提供方式有所了解，所以结合一个开源的组件，对微信小程序的模块化的设计进行了描述，可以为之后组件的设计提供参考依据，也当做一个简单的学习笔记。 代码构成&emsp;&emsp;微信小程序中涉及到4种文件，分别是JSON、WXML、WXSS、JS。其中JSON是进行小程序进行配置，控制页面的路径、表现等情况，WXML类似HTML，是描述页面结构，进行展示的地方，WXSS和CSS类似，是用来描述页面展示的样式，JS是逻辑处理的地方，响应一些点击事件、页面状态变化等操作，并存有一些页面使用的变量。具体如下表所示： 文件名 主要作用 对应网页开发文件 JSON 页面配置 JSON WXML 页面展示结构 HTML WXSS 页面展示样式 CSS JS 页面交互控制 JS 模块化接口如何关联&emsp;&emsp;在Android开发中，组件都是放在一个库中，通过在依赖管理工具中进行声明就可以在项目中使用。在小程序中，一个组件可以放在一个文件夹中，文件夹名称可以取为组件的名称，然后在组件内部提供对应的文件，包括WXML、WSXX、JS文件。&emsp;&emsp;组件设计的关键在于这些组件和被其他组件引用。下图展示了其他文件夹中的页面如何使用组件。可以看到WXML、WSXX、JS这三种文件都有自己的引入方式。通过这些文件的引入，实际上也就实现了组件的引入。 WXML引用&emsp;&emsp;以下摘自微信文档。 &emsp;&emsp;WXML 提供两种文件引用方式 import 和 include。&emsp;&emsp;1. import&emsp;&emsp;import 可以在该文件中使用目标文件定义的 template，如：在 item.wxml 中定义了一个叫 item 的 template：12&lt;!-- item.wxml --&gt; &lt;template name=&quot;item&quot;&gt;&lt;text&gt;&#123;&#123;text&#125;&#125;&lt;/text&gt;&lt;/template&gt; 在 index.wxml 中引用了 item.wxml，就可以使用item 模板：12&lt;import src=&quot;item.wxml&quot;/&gt; &lt;template is=&quot;item&quot; data=&quot;&#123;&#123;text: &apos;forbar&apos;&#125;&#125;&quot;/&gt; &emsp;&emsp;import 有作用域的概念，即只会 import 目标文件中定义的 template，而不会 import 目标文件 import 的 template。如：C import B，B import A，在C中可以使用B定义的 template，在B中可以使用A定义的 template，但是C不能使用A定义的 template。&emsp;&emsp;2. include&emsp;&emsp; include 可以将目标文件除了 &lt;template/&gt; 、 &lt;wxs/&gt; 外的整个代码引入，相当于是拷贝到 include 位置，如：12345678910&lt;!-- index.wxml --&gt;&lt;include src=&quot;header.wxml&quot;/&gt;&lt;view&gt; body &lt;/view&gt;&lt;include src=&quot;footer.wxml&quot;/&gt;&lt;!-- header.wxml --&gt;&lt;view&gt; header &lt;/view&gt;&lt;!-- footer.wxml --&gt;&lt;view&gt; footer &lt;/view&gt; WXSS导入&emsp;&emsp;以下摘自微信文档。 &emsp;&emsp;使用@import语句可以导入外联样式表，@import后跟需要导入的外联样式表的相对路径，用;表示语句结束。示例代码如下：12345678910/** common.wxss **/.small-p &#123; padding:5px;&#125;/** app.wxss **/@import &quot;common.wxss&quot;;.middle-p &#123; padding:15px;&#125; JS模块化&emsp;&emsp;以下摘自微信文档。 &emsp;&emsp;可以将一些公共的代码抽离成为一个单独的 js 文件，作为一个模块。模块只有通过module.exports或者exports才能对外暴露接口。需要注意的是：&emsp;&emsp;1.exports是module.exports的一个引用，因此在模块里边随意更改exports的指向会造成未知的错误。所以更推荐开发者采用module.exports来暴露模块接口，除非你已经清晰知道这两者的关系。&emsp;&emsp;2. 小程序目前不支持直接引入node_modules, 开发者需要使用到node_modules时候建议拷贝出相关的代码到小程序的目录中。 1234567891011// common.jsfunction sayHello(name) &#123; console.log(`Hello $&#123;name&#125; !`)&#125;function sayGoodbye(name) &#123; console.log(`Goodbye $&#123;name&#125; !`)&#125;module.exports.sayHello = sayHelloexports.sayGoodbye = sayGoodbye &emsp;&emsp;在需要使用这些模块的文件中，使用 require(path) 将公共代码引入123456789var common = require(&apos;common.js&apos;)Page(&#123; helloMINA: function() &#123; common.sayHello(&apos;MINA&apos;) &#125;, goodbyeMINA: function() &#123; common.sayGoodbye(&apos;MINA&apos;) &#125;&#125; 组件开发&emsp;&emsp;模块开发者先可以按照普通页面进行撰写，然后可以按照上一章中所述将模块导出，但是还有个问题就是组件使用者有时候需要植入自己的代码，所以组件开发者应该提供一个回调机制。引入回调机制后的整个组件的设计如下图所示： &emsp;&emsp;组件可以应该提供一些转发函数的框架，以一个搜索框框架。为例具体如下所示： 1234567891011121314// 组件WxSearch.jsfunction wxSearchKeyTap(e, that, callBack) &#123; //执行一些逻辑 //回调 callBack(e.target.dataset.key);&#125;// 开发者的jsvar WxSearch = require(&apos;../../wxSearch/wxSearch.js&apos;);wxSearchKeyTap: function (e) &#123; WxSearch.wxSearchKeyTap(e, this, function (key)&#123; // 被回调 &#125;);&#125;]]></content>
      <categories>
        <category>小程序</category>
      </categories>
      <tags>
        <tag>小程序</tag>
        <tag>模块化</tag>
      </tags>
  </entry>
</search>
